title,company,url,text
Senior Data Scientist,EPAM Systems,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-epam-systems-1527314351?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=1&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click," Scroll down to learn more about the position’s responsibilities and requirements.   Identifying the business problems   Finding the right data and methods to address them   Building and validating analytical models   Presenting the findings in a clear and informative way   Convert large volumes of structured and unstructured customer data using advanced analytical solutions   Use and fit different mathematical and econometric models, develop descriptive and predictive models that deliver better decisions   Turn analyzed data into actionable insights and business value   Create high-quality data visualizations   Communicate effectively with different departments and roles (product managers, engineers) to discuss complex data-driven findings and technical matters   Educate and train others on Data Science related matters   Estimate, plan and coordinate the delivery of moderate sized projects   Evaluate and select Data Science tools and libraries   Minimum 5+ years of experience   Aptitude for problem solving   Data focused applied mathematics (statistical analysis, machine learning)   Good communication / presentation skills   RDBMS/SQL knowledge   Programming experience (Python preferred)   Data analysis tools and libraries such as Python (NumPy / SciPy / scikit-learn / pandas / matplotlib), R, SAS, SPSS, MATLAB, etc   Big Data stack; Spark / MLlib   Proficiency with at least one of the Cloud providers   Experience with Data Science solutions productionalization   Bachelor’s/Master’s Degree in Computer Science, Math, Applied Statistics or a related field   A few years of experience in data mining, statistics or machine learning   Data visualization skills   NLP/text mining   Extended Healthcare with Prescription Drugs, Dental and Vision Insurance (Company Paid)   Life and AD&D Insurance (Company Paid)   Employee Assistance Program (Company Paid)   Unlimited access to LinkedIn learning solutions   Long-Term Disability   Registered Retirement Savings Plan (RRSP) with company match   Paid Time Off   Critical Illness Insurance   Employee Discounts"
Data Scientist II,TD,https://ca.linkedin.com/jobs/view/data-scientist-ii-at-td-1554467503?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=2&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Interpret Model Risk Management Model Development Reporting   Understand the Inputs/features that were used to build models and tools, with plain language explanations and impact of each input   Preliminary assessment of Risk (using Compliance Framework Risk Dimensions)   Solid understanding of bias/fairness testing methodology/approach select for the model/tool by the business and determine if viable in concert with Model Risk Management .  Validation of approach used to test for bias is critical given the numerous types of bias testing that exist, it is difficult for a non-data scientist to opine on appropriateness of the method(s) used. Work with business and MRM as required to propose required modifications to the methodology   Guide business in the development of FAIR Assessment Report (bias and fairness) Ensure completeness of documentation Assess results of Bias and fairness testing Determine whether there is any statistically significant  disparate/discriminatory  impact of the model Determine next steps and controls including conditions   Ongoing/period monitoring plan and documentation requirements Possibility of re-performing bias/fairness testing on a sample basis (risk based) With a data scientist on board a consistent determination of reasonable frequency for monitoring of model output for changes in bias/fairness from the initial assessment.  This is possible due to a solid understanding of the technical variations of modelling in conjunction with the use case (context). Better opine on what is a reasonable amount of deviation in disparate outcomes and resulting need for Compliance engagement or not   Advise and validate  capabilities required to perform new Compliance role:  advisory and analytical testing capabilities   Advise on specific competencies required to  build advisory capabilities   Support discussing  options to build analytical testing capabilities   Assist in development of playbook and guidelines to assess preliminary risks and Compliance and Legal model lifecycle requirements (1B guidance)   Assist in development of playbook and guidelines for Compliance Officers   Support Training and deliverables associated with enhancing advisory capabilities and require specific skills and oversight capabilities   Support Development of Compliance Monitoring and Testing capabilities   Support role out activities and ongoing engagement of training and awareness activities associated with 1B's, Data Analytics community and Compliance Units"
Sr. Data Scientist,Precima,https://ca.linkedin.com/jobs/view/sr-data-scientist-at-precima-1538164726?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=3&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Master’s Degree in statistics, operations research, mathematics, economics, econometrics, engineering, or computer science   Experience in econometric modelling   B2B and retail industry experience;   Expert proficiency in developing original statistical and econometric models to support clients in B2B, Retail and CPG areas.   Expert proficiency in implementing models in #1 using Python or R.   Working knowledge of C++/C# and SQL. Collaborating & Teamwork   Inspiring & Motivating Others to High Performance   Championing Innovation & Change   Holding Others Accountable   Focusing on Customer   Driving for Results   Travel as required"
Machine Learning Engineer / Data Scientist,SoundHound Inc.,https://ca.linkedin.com/jobs/view/machine-learning-engineer-data-scientist-at-soundhound-inc-1451519485?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=4&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"SoundHound: music app featuring search, discovery, and play with LiveLyrics   Hound: newly released app featuring unprecedented speech recognition and natural language understanding   Houndify: platform enabling developers to add voice enabled conversational interface to anything   Develop high-performance, data-driven systems in a distributed infrastructure   Build machine learning models for analysis of queries using NLP, Deep Learning   Develop scalable components for query intent classification, entity detection, dialog understanding, slot filling and domain detection   Leverage massive datasets for modeling, recommendations, ad targeting and insight generation   Build and maintain knowledge graph of content from diverse data sources, and perform data mining to serve high volume of requests   Background and passion for machine learning, AI, and/or statistical modeling   Experience in one or more of the following areas: classification systems, ranking systems, recommender systems, predictive modeling, and/or artificial intelligence   Strong coding experience preferably in Java, Scala, or Python   A desire to bring data-driven decision-making and analytics to improve our products   BS/MS in Computer Science or equivalent   Prior experience with Natural Language Processing   Understanding of deep learning algorithms and workflows   Experience with Deep Learning / Neural Network frameworks such as Caffe, Tensorflow, PyTorch, etc.   Experience with analytical tools supporting data analysis (eg. Tableau)"
Data Scientist,Rubikloud Technologies,https://ca.linkedin.com/jobs/view/data-scientist-at-rubikloud-technologies-1598304388?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=5&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Masters/PhD degree or equivalent in Computer Science, Engineering, Mathematics or related field   Proficiency with various machine learning & statistical techniques   Proficiency in Python or other data manipulation or analysis languages; software development experience is a plus   Experience working with relational data via SQL; experience with big data technologies such as Spark and Hadoop a plus   Ability to work in *nix environments"
Data Scientist,Veeva Systems,https://ca.linkedin.com/jobs/view/data-scientist-at-veeva-systems-1557987149?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=6&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner   Design, develop and assess highly innovative models for adaptive predictive learning, suggestion ranking, anomaly detection, and more   Collaborate with Engineering to help implement machine learning algorithms and “productize"" data science capabilities   Build and run analysis of models and algorithms in order to assess performance and identify the best algorithms to integrate into Andi   Ensure models and algorithms support our customers and help them drive towards more intelligent and effective engagement with their customers   Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning and retrieval processes) on large, unstructured data sets to identify trends and figures   Work closely with the data warehouse product team to ensure architecture is effectively developed to support algorithms embedded in Andi   M.S. or Ph.D. in Machine Learning, Applied Statistics, Mathematics, Computer Science, or other quantitative disciplines with at least 2 years of experience; In lieu of a PhD, 6+ years of relevant post-collegiate work experience   Advanced in-depth specialization in mathematical analysis methods, machine learning, statistical analyses, and predictive modeling (regression, decision trees, clustering, neural networks, text mining, etc.)   Good understanding and experience in data analysis techniques such as: classification, clustering, feature analysis, deep learning, fuzzy matching, sentiment analysis, A/B testing, active/adaptive learning and reinforcement learning   Advanced knowledge of neural networks or reinforcement learning    Expertise in using R or Python to manipulate large data sets and develop statistical models, with the ability to accurately determine cause and effect relationships   Good SQL skills   Intellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions, even in situations with non-standard problems   Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to Engineering and customers   Experience with commercial aspects of the Life Sciences industry, including Field Sales or Field Medical, especially in GTM strategy   Experience with Veeva CRM data sets or other commercial Life Sciences data   Experience working in an agile software development environment   Experience working with Software as a Service and/or enterprise products   Experience with AWS    Hands on experience building models with deep learning frameworks (Tensorflow or similar)   Experience with Data Visualization and dashboarding tools such as Tableau or Qlik"
Data Scientist,BMO Financial Group,https://ca.linkedin.com/jobs/view/data-scientist-at-bmo-financial-group-1548155552?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=7&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click," Use case identification:    Expand on the currently identified use cases by partnering with the existing model development groups and the business partners and identify other types of models/applications where ML and AI can add value. This will cover areas such as credit risk, economic capital, AML and market risk.    Structure above identified use cases, define operating model, manage delivery and provide    Data collection and manipulation    Collect data for model development purposes by identifying new candidate variables and predictive variables.    Analyze and summarize data to identify outliers and assess data quality.    Perform data imputation using advanced statistical techniques (multiple imputation, machine learning estimations).    Transform and prepare the data for developing AI models.    Predictive models development    Fully understand the existing version of the models where applicable, their limitations and all the underlying assumptions made.    Use the prepared data to build machine learning predictive models using advanced regression techniques such as random forests, neural networks, boosted trees, deep learning, logistic regressions, NLP etc…    Rank and compare the candidate models to select the best fitting models.    Use statistical tests to ensure the stability and robustness of the candidate models.    Identify new opportunities to apply machine learning in the current model development process.    Reasonableness assessment    Ensure that the models developed make business and intuitive sense by participating in sessions with the model owners, lines of businesses and including their feedback in the model.    Design a process to explain the output of the models on a consistent basis to understand why the models are producing these decisions.    Documentation    Document the process along the way by capturing the details around all assumptions made.    Keep record and detailed notes about the thought process. The models developed will serve as a proof of concept for future ML & AI models in credit risk.    Master or PhD candidate in Engineering, Statistics, Mathematics, Computer Science or related quantitative field.    5-10 years of experience in AML, risk management and machine learning and AI techniques    Familiarity with risk management processes and methodologies, ideally AML    Familiarity with Bank credit instruments and product structures    Familiarity with systems management and data architecture principles    Experience with statistical model development and data mining    Proven experience using SAS, R or Python to build machine learning models    Strong theoretical knowledge of machine learning techniques and advanced regression methods and data imputation techniques    Well-developed relationship management skills.    Excellent influencing and negotiation skills    Strong problem solving skills and capacity to turnaround analysis in short period of time    Comfortable in a challenging environment with tight timelines    Excellent written and verbal communication skills    Capacity to cope with a high degree of ambiguity and change    Ability to work both independently and as part of cross-functional teams    Prior industry experience or academic projects with machine learning and advanced programming is preferred.    High-level of competency with MS Office suite of tools"
Data Scientist,Restaurant Brands International,https://ca.linkedin.com/jobs/view/data-scientist-at-restaurant-brands-international-1537565430?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=8&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"The Data Scientist will play a key role in enhancing our advanced analytics and machine learning capabilities within the organization   Responsible for the building, training, scoring and monitoring of machine learning models to be used for loyalty offer generation   Develop best in class offer generation tools that allows for individual customer targeting and optimize based on all available data; look for areas of data enhancement and improvement   Work with digital development teams to ensure that the tools and data available is best in class; work with IT teams to ensure data quality   Work closely with various stakeholders to understand business needs and develop solutions through machine learning or other advanced analytics/predictive modeling techniques   MS/PHD or equivalent in Computer Science, Engineering, Statistics, Mathematics, or related technical field   Experience in developing machine-learning algorithms, statistical and mathematical optimization models, and simulation and visualization tools   Strong understanding of regression modeling, time series analysis, cluster analysis, machine-learning concepts such as supervised and unsupervised learning, classification, random forest, neural nets, etc.   Ability to identify predictive attributes of data sets and perform feature engineering to improve machine learning results   Able to model out the expected cost and expected opportunity of recommendations   Experience with manipulating big data sets via SQL able to process, filter and present large quantities of data   Experience in one or more programming languages (e.g. Python, R, Scala, etc.)   Experience with Loyalty Programs an asset   Experience with Databricks, Tableau and AutoML tools an asset"
data scientist,Randstad Canada,https://ca.linkedin.com/jobs/view/data-scientist-at-randstad-canada-1583113269?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=9&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,
Data Scientist,ASSURANCE IQ,https://ca.linkedin.com/jobs/view/data-scientist-at-assurance-iq-1545323736?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=10&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Proficiency in either Python or R, and expertise in SQL.    Experience working with AWS or another cloud-based computing platform.    Experience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.    Experience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.   Excellent communication ability – you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.    Business Acumen – you are always eager to understand how the business works, and more specifically, how your work impacts the business.    Enthusiastic yet humble – you are excited about the work you do, but you are also humble enough to embrace feedback – you don’t need to be the smartest person in the room.    Experience retraining a model within a few days or update a model within one day.    Capable of performing an in-depth analysis and summarizing findings in one day.    Comfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights. "
Data Scientist,Workbridge Associates,https://ca.linkedin.com/jobs/view/data-scientist-at-workbridge-associates-1502269960?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=11&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Python   R   TensorFlow   Numpy   Predictive systems   Recommendation Systems   Optimization Methods   Fraud detection   Hadoop, Scala, or Spark   AWS or Azure   PostgreSQL or MSSQL   Jenkins   Masters Degree or higher in related field   100% Data Science   80% Hands On   10% Guiding/mentoring junior analysts    10% Discussing your findings to internal/external stakeholders    Competitive Salary: Up to $135K/year, DOE   Medical, Dental, Vision Insurance   RRSP matching   2-3 Days work from home   Flexible work hours   Casual work environment   Sponsored work-related conferences   Team-building events   Workbridge Toronto - OSD"
Data Scientist - Toronto,BrainStation,https://ca.linkedin.com/jobs/view/data-scientist-toronto-at-brainstation-1594218083?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=12&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings.
Data Scientist,Loopio,https://ca.linkedin.com/jobs/view/data-scientist-at-loopio-1519518042?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=13&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Working with business stakeholders to identify opportunities where statistical analysis, machine learning, and Natural Language Processing can improve business processes   Working with product managers to translate product requirements into R&D activities   Researching, developing, and validating models to generate predictions, recommendations, alerts, and other insights   Working with engineers to collect, clean, and perform feature engineering and selection on customer data to support model R&D activities   Working with engineers on the delivery and integration of models into product   3+ years of experience in applied statistical analysis and machine learning in a software development environment, ideally using Natural Language Processing   A deep understanding of probability theory, statistics and multivariate calculus   Experience in the use of statistical analysis and machine learning tools, packages and languages    Strong scripting and engineering skills in Python and proficiency in using query languages such as SQL   Knowledge of data structures and algorithms   Experience in a high growth agile software development environment (Scrum or Kanban)   You'll have tons of autonomy and responsibility; we have a results-driven environment   You'll work in the bustling and lively neighborhood of Kensington Market   You'll learn more than you thought was possible; our team is obsessed with personal and professional growth   You'll have a piece of the pie; every Loopio employee participates in our stock option plan   You'll participate in a health and benefits plan that kicks in on day one   The career growth opportunities are endless at a successful, high-growth company    You'll be a part of one of LinkedIn's Top 10 Startups in Canada and Deloitte's Technology Fast 50™ Companies to Watch in 2018!"
Data Scientist,Bank of Montreal,https://ca.linkedin.com/jobs/view/data-scientist-at-bank-of-montreal-1594022333?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=14&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Use case identification:    Expand on the currently identified use cases by partnering with the existing model development groups and the business partners and identify other types of models/applications where ML and AI can add value. This will cover areas such as credit risk, economic capital, AML and market risk.    Structure above identified use cases, define operating model, manage delivery and provide    Data collection and manipulation    Collect data for model development purposes by identifying new candidate variables and predictive variables.    Analyze and summarize data to identify outliers and assess data quality.    Perform data imputation using advanced statistical techniques (multiple imputation, machine learning estimations).    Transform and prepare the data for developing AI models.    Predictive models development    Fully understand the existing version of the models where applicable, their limitations and all the underlying assumptions made.    Use the prepared data to build machine learning predictive models using advanced regression techniques such as random forests, neural networks, boosted trees, deep learning, logistic regressions, NLP etc...    Rank and compare the candidate models to select the best fitting models.    Use statistical tests to ensure the stability and robustness of the candidate models.    Identify new opportunities to apply machine learning in the current model development process.    Reasonableness assessment    Ensure that the models developed make business and intuitive sense by participating in sessions with the model owners, lines of businesses and including their feedback in the model.    Design a process to explain the output of the models on a consistent basis to understand why the models are producing these decisions.    Documentation    Document the process along the way by capturing the details around all assumptions made.    Keep record and detailed notes about the thought process. The models developed will serve as a proof of concept for future ML & AI models in credit risk.    Master or PhD candidate in Engineering, Statistics, Mathematics, Computer Science or related quantitative field.    5-10 years of experience in AML, risk management and machine learning and AI techniques    Familiarity with risk management processes and methodologies, ideally AML    Familiarity with Bank credit instruments and product structures    Familiarity with systems management and data architecture principles    Experience with statistical model development and data mining    Proven experience using SAS, R or Python to build machine learning models    Strong theoretical knowledge of machine learning techniques and advanced regression methods and data imputation techniques    Well-developed relationship management skills.    Excellent influencing and negotiation skills    Strong problem solving skills and capacity to turnaround analysis in short period of time    Comfortable in a challenging environment with tight timelines    Excellent written and verbal communication skills    Capacity to cope with a high degree of ambiguity and change    Ability to work both independently and as part of cross-functional teams    Prior industry experience or academic projects with machine learning and advanced programming is preferred.    High-level of competency with MS Office suite of tools"
Graduate Data Scientist Intern,Thomson Reuters,https://ca.linkedin.com/jobs/view/graduate-data-scientist-intern-at-thomson-reuters-1603458138?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=15&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Build new solutions from the ground up, work like a startup, utilizing the resources of a large enterprise.    Take on two to three projects during the term, with the goal of getting new products into market, building new data sets, and de-risking new customer opportunities in terms of technical viability, data viability, and customer demand.    Some examples of our work includes ranking  global energy leaders , evaluating  free trade , using data to combat  modern day slavery , forecasting  global food supply , and analyzing the transition from gas to  electric vehicles .    Learn from Data Scientists in Toronto and our sister-labs in Waterloo, Boston, London, and Zurich. Pick the brains of PhD’s and Masters grads with experience in big data, statistics, machine learning, natural language processing, deep learning, and data visualization.    Evaluate career opportunities with a technology team that’s hiring rapidly en route to over  1,500 staff  in Canada as part of a  $100M expansion .    Information Retrieval    Natural Language Processing   Machine Learning    Development skills to rapidly deliver minimum viable products    Strong experience with programming languages like Python, Java, or Scala    Strong experience with data systems like DBMS, NoSQL, Elastic Search or graph databases    Big data systems   Knowledge graphs"
Data Scientist,SNC-Lavalin,https://ca.linkedin.com/jobs/view/data-scientist-at-snc-lavalin-1523460961?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=16&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Work with client teams to understand their data needs and develop ETL solutions   Collaborating with full-time and contractual staff to communicate with hardware and software systems (PATs, Data Historians)   Working closely with data scientists to build data integrations for investigation needs   Coordinate the system validation of enterprise analytical tools   Bachelor's degree in statistics, computer science, engineering, physical sciences, or economics   Expertise in computerized system validation methodologies with 2-3 years hands on experience   Knowledge of shop floor management information systems (e.g. MES, LIMS, DCS, eDMS)   Knowledge of Business requirements regarding Statistical Process Control (SPC) and their prerequisites.   Experience with data validation in a data warehouse context   Knowledge of technology project management is an asset (i.e. PUMA methodology)   Expertise and comfort with programming (Python, Matlab, R)   Analytical data science experience (developing/deploying models) is an asset   Process control/optimization knowledge is desirable, but not mandatory"
Data Scientist,Jobspring Partners,https://ca.linkedin.com/jobs/view/data-scientist-at-jobspring-partners-1486276741?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=17&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"3+ years of professional experience as a Data Scientist   Experience leading a project in the past   Experience in R for predictive modelling and data analysis   Machine learning tools such as TensorFlow   Strong in mathematics and algorithms   Import and analyze data   Meeting business requirements   80% Hands on   20% Team leadership and collaboration   Competitive Salary: Up to $130,000, DOE   3 weeks’ vacation   Benefits package   Bonus structure"
Data Scientist,Michael Page,https://ca.linkedin.com/jobs/view/data-scientist-at-michael-page-1465020964?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=18&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Be a part of one of the leading organizations in this space   Exciting opportunity for a driven individual looking for a fastpaced environment   You will help the team to improve upon current methods and models. With a practical mindset, you will bring these models into a production environment.    Your software development experience will allow you to closely collaborate with our Engineering team to improve our models and push them through our release process.   You will work with big data (GPS fixes and sensor data) from hundreds of thousands of users.   You will train algorithms related to activity detection (type of transports, home/work location, etc.) and human behavior (commuting, sporting, shopping, etc.).   You will create machine learning pipelines capable of extracting insights from social interactions between users on our platforms   You will design context-aware recommender systems   You have a masters degree or PhD in computer science or a related field.   You are fluent in Python programming and its machine learning stack   You are an expert in machine learning and data modeling.   You have knowledge/experience with software engineering and deployment to production   You have experience with at least one of the fields listed above.   You possess a deep understanding of clustering, manifold learning and predictive modeling techniques.   You can use big data tools such as Spark for development   You can work independently and take matters into your own hands.   Sensor data modeling from mobile devices or wearables   Data engineering technologies (Spark, Kafka, database,...)   Java   Mobile programming (Android or iOS)"
Network Data Scientist,TELUS,https://ca.linkedin.com/jobs/view/network-data-scientist-at-telus-1585018159?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=19&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Constructing, validating/testing and deploying artificial intelligence models that predict customer experience tied to network analytics   Design, develop innovative predictive models, metrics, and dashboards to uncover actionable insights from raw data; working with structured and unstructured data sources    Design and implement statistical data quality procedures for new data sources    Visualize and report data findings creatively in a variety of visual formats that appropriately provides insights to the organization   Ability to communicate findings in simple terms to business leaders and executives in order to influence how TELUS approaches their business challenges and opportunities   Work with others in creating the end to end workflow required to put models into production   Ensuring all work is all properly documented and packaged while taking advantage of prior work in similar areas that can be repurposed   Regarded as collaborative, creative, entrepreneurial and willing to experiment   Sought out for your application of data mining, predictive modeling, statistics and other analytical techniques to solve diverse business problems in a data rich environment   Respected for your ability to perform hypothesis testing and develop predictive model    Talented at understanding data warehouse/Hadoop architecture, ETL processes and the software development lifecycle (Waterfall and Agile/Scrum)   Known for your ability to develop experimental and analytic plans for data modeling processes   Skilled in various statistical techniques:   Machine Learning (Supervised/Unsupervised Learning): Classification, Clustering and Segmentation   Time series analysis and forecasting   Optimization   Causal Impact   Reliability analysis (time to failure)   Computer Simulation   Experiment Design       With 5 or more years of data analytics related experience in a matrix or consulting environment    With a Masters or PhD degree in Math, Statistics, Computer Science, Engineering, Economics with a strong foundation in modeling, statistics, analytics, engineering or math   ETL experience   Hadoop data extraction using frameworks like Hive and from MPP platforms   SQL, MySQL, Oracle, R, Python, Java, SAS, node.js   Real time streaming analytics such as Spark    Cloud platform experience: Microsoft, Amazon, Google   Deep Learning such as RNN, LSTM, etc   Data visualization using Tableau, Qlikview, or Domo"
Data Scientist - Toronto,Cerebri AI,https://ca.linkedin.com/jobs/view/data-scientist-toronto-at-cerebri-ai-1594213017?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=20&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click," Understanding and worked with database systems.     Understanding and worked with machine learning algorithms.    Perform feature analysis.     Develop ontology for key market segments.    Develop outcome/event taxonomy for key business models.    Build utility code and handle miscellaneous support tasks.     Documenting software projects and maintaining project documentation.    Working in a team environment as well as working alone.    Experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning.    Python programming skills with two (2) years or more of Python experience.    Good verbal and written communication skills.    Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.    Master's degree or six (6) years related work experience delivering quality code on time.    Confluence    JIRA    Spark    Azure    Python    Keras    Scikit-learn    Bit bucket    Jupyter Notebook    Scala    MonetdB    OrientDB    Experience in some subset of the following: Java, R, Python, SQL, Scala, Spark.    Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.     Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, supervised learning, recommendation and optimization algorithms."
Data Scientist,Loblaw Digital,https://ca.linkedin.com/jobs/view/data-scientist-at-loblaw-digital-1563308813?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=21&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,
Data Scientist,eFinancialCareers,https://ca.linkedin.com/jobs/view/data-scientist-at-efinancialcareers-1546333299?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=22&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Use case identification:   Expand on the currently identified use cases by partnering with the existing model development groups and the business partners and identify other types of models/applications where ML and AI can add value. This will cover areas such as credit risk, economic capital, AML and market risk.   Structure above identified use cases, define operating model, manage delivery and provide  Data collection and manipulation Collect data for model development purposes by identifying new candidate variables and predictive variables. Analyze and summarize data to identify outliers and assess data quality. Perform data imputation using advanced statistical techniques (multiple imputation, machine learning estimations). Transform and prepare the data for developing AI models.  Predictive models development Fully understand the existing version of the models where applicable, their limitations and all the underlying assumptions made. Use the prepared data to build machine learning predictive models using advanced regression techniques such as random forests, neural networks, boosted trees, deep learning, logistic regressions, NLP etc... Rank and compare the candidate models to select the best fitting models. Use statistical tests to ensure the stability and robustness of the candidate models. Identify new opportunities to apply machine learning in the current model development process.  Reasonableness assessment Ensure that the models developed make business and intuitive sense by participating in sessions with the model owners, lines of businesses and including their feedback in the model. Design a process to explain the output of the models on a consistent basis to understand why the models are producing these decisions.  Documentation Document the process along the way by capturing the details around all assumptions made. Keep record and detailed notes about the thought process. The models developed will serve as a proof of concept for future ML & AI models in credit risk. Qualifications Skills required: Master or PhD candidate in Engineering, Statistics, Mathematics, Computer Science or related quantitative field. 5-10 years of experience in AML, risk management and machine learning and AI techniques Familiarity with risk management processes and methodologies, ideally AML Familiarity with Bank credit instruments and product structures Familiarity with systems management and data architecture principles Experience with statistical model development and data mining Proven experience using SAS, R or Python to build machine learning models Strong theoretical knowledge of machine learning techniques and advanced regression methods and data imputation techniques Well-developed relationship management skills. Excellent influencing and negotiation skills Strong problem solving skills and capacity to turnaround analysis in short period of time Comfortable in a challenging environment with tight timelines Excellent written and verbal communication skills Capacity to cope with a high degree of ambiguity and change Ability to work both independently and as part of cross-functional teams Prior industry experience or academic projects with machine learning and advanced programming is preferred. High-level of competency with MS Office suite of tools We're here to help At BMO we have a shared purpose; we put the customer at the centre of everything we do - helping people is in our DNA. For 200 years we have thought about the future-the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we're changing the way people think about a bank. As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset. To find out more visit us at https://bmocareers.com . BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter."
Data Scientist,Loblaw Companies Limited,https://ca.linkedin.com/jobs/view/data-scientist-at-loblaw-companies-limited-1557946887?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=23&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click," Leverage data to analyze customer purchase behavior and product and sales data to perform pre-campaign analysis for the purpose of audience management and targeting for Media campaigns.    Perform post-mortem analysis to determine performance of campaigns    Work with cross-functional teams such as Client services teams, Sales team, Audience management team and Media trading teams to continue to refine targeting and optimizing media investments and maximizing campaign effectiveness for external clients.     Responsible for the data extraction and analysis of complex information from a variety of databases (Teradata, Hadoop, etc.).    Applying advanced analytical and statistical techniques to solve marketing questions   Derive distilled insights out of data and clearly present insights (from analyses, etc.) to stakeholders using reports, slide deck, etc.   Support with designing and deploying advanced campaign performance reporting dashboards   Support with designing, delivering, and maintaining Loblaw Media analytic solutions and future capabilities   Troubleshooting issues related to data and analytics, including the management of ad-hoc reporting requests   Support with developing data driven insights and analytics presentations to internal and external stakeholders and partners    Monitor and track programs and process issues and make recommendation to streamline, enhance and improve processes     Work with IT in terms of identifying opportunities to make key information more easily and reliably accessible.     Act as gatekeeper with regards to security and confidentiality of data obtained through all sources.     Mandatory: 3+ years of programming experience with Python, Hive QL or SAS.     3 years’ experience in utilizing advanced SQL data extraction and manipulation tools.     University Degree in Computer Science, Statistics, and Mathematics is preferred    Solid understanding of statistical concepts and hands-on experience of applying statistical methodologies on retail data.    Retail analytics experience with a marketing focus preferred.    Marketing experience with a focus on using customer data, such as Direct Marketing, Database Marketing, Loyalty Marketing preferred.    Experience with Hadoop and understanding of its components (HDFS, HBase, Spark) is an asset.     Data mining experience working with a large relational customer database     Superb analytical and conceptual thinking skills; to not only manipulate but also derive meaningful interpretations from data     Ability to take initiative, multi-task and work in a fast-paced environment     Capability to liaise with all levels across the enterprise on projects and ad-hoc requests.     Strong detail orientation is essential in this role     A Team player and self-starter     Advanced MS Office skills (Excel, PowerPoint)    Competitive compensation and benefits package   A flexible work environment which values balance   Colleague Discount Program   Tuition reimbursement Program   Employee Share Ownership plan   Pension Plan"
Senior Data Scientist,jobleads.com - Careers for Senior-Level Professionals,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-jobleads-com-careers-for-senior-level-professionals-1555996041?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=24&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Understanding of dimensional modelling concepts and database design/architecture or experience with feature engineering both at model build and in production   Experience with statistical methods like regression, GLMs, clustering, experiment design, including sampling and multi-armed bandit approaches, shipping productionized machine learning systems at scale and other predictor or classifier models   Extensive experience using Python including a strong grasp of object oriented programming (OOP) fundamentals   Extensive experience analyzing data using SQL   Exposure to Tableau, QlikView, Mode, Matplotlib, Jupyter, or similar data visualization tools   Strong background in machine learning including experience implementing models at scale (from Random Forest and GBMs to RNN/CNNs)   Knowledge of digital marketing and traditional media data and metrics   Previous experience using Spark (esp. via Python or Scala)"
Biomedical Data Scientist,Myant Inc.,https://ca.linkedin.com/jobs/view/biomedical-data-scientist-at-myant-inc-1519493171?refId=39e4aa31-9685-4637-8bf0-3383177e2602&position=25&pageNum=0&trk=guest_job_search_job-result-card_result-card_full-click,"Work with the data science team to develop efficient and robust signal processing-based algorithms for extracting/detecting/predicting and monitoring of vital signs    Define and design study protocols to collect data for testing signal quality, algorithm development, and validation of our product    Propose, research, create, implement and test algorithms using clinical data sets and mathematical models   Take ownership of all your deliverables and communicate your results to timely project delivery   Prepare technical documentations   PhD or Master's degree in Biomedical, Electrical/Electronics Engineering, Engineering, Computer Science or related discipline   Signal processing, machine learning and data mining for physiological patient data   Proficiency in one modern scripting language such as MATLAB, Python or R   Solid experience with developing and testing software applications    Solid experience working or doing research on biomedical signal processing, parameter estimation and feature extraction etc.   Background in time-domain and frequency-domain discrete-time signal processing algorithms   Previous experience on planning and coordinating clinical studies, data collection and operating medical devices is a bonus   Proficiency in one of the programming languages such as C, C++ is a bonus    Experience in any of the following industries: pharmaceutical, medical technology, healthcare, consumer electronics, wearables, apparel / fashion    Experience working in start-ups or growth companies"
Data Scientist (NLP),Manulife,https://ca.linkedin.com/jobs/view/data-scientist-nlp-at-manulife-1422497756?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=1&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Develop and implement models and algorithms to support Group Functions strategy and business pillar initiatives   Identify, assess and drive the adoption of new NLP techniques and tools across Manulife   Innovate and find creative ways to source data to support modeling efforts, using structured and unstructured data using big data technologies   Lead and deliver NLP solutions through consulting type engagements with internal business clients   Turn statistical and computational analysis into user-friendly graphs, charts, and animation. Enable those who aren’t professional data analysts to effectively interpret data.   Conduct research to push Manulife abilities in data science and machine learning   Peer review other Data Scientists’ work   Advanced degree in Computer Science or Computer Engineering with a focus on ML or NLP (PhD preferred)   Minimum of 3 years of applied experience in ML, deep learning and NLP   Have expert understanding of machine learning and NLP tasks such as classification, feature engineering, information extraction, structured prediction, sentiment analysis, Q/A, NER and topic modelling   Fully understand different neural networks (LSTM, CNN, RNN, seq2seq, BERT etc.), different word embedding models and transfer learning.   Proficient in Python or C/C++   Knowledge of packages such as Tensorflow, Pytorch, Keras, Scikit Learn, Pandas, NLTK, Gensim, spaCy and XGBoost   Have experience with embeddings, transfer learning, and interpretability methods   Have working knowledge of Hadoop ecosystem (e.g. Spark)   Have the ability to build, validate, deploy and monitor iteratively advanced predictive models   Excellent communication, influencing, consulting and conflict management skills   Extensive experience in debugging and solving performance issues when taking care of terabytes of data   Proven track record of delivering innovative analytical insights to a variety of customers   Strong dedication to interpersonal success and teamwork   Adaptable and open to change with strong collaboration and presentation skills   Familiarity with Agile methodologies   Inspires and motivates others.   Role model of ethics and integrity who builds a culture of respect.   Highly effective change agent who embraces change and leads change management.   Provides courageous advice.   Results oriented; highly focused on accountability.   Ability to handle multiple partners   Demonstrates a commitment to delivering excellent service balanced with appropriate risk management.   Strategic perspective.   Highly collaborative working style."
Senior Data Scientist - Toronto,YouVisit,https://ca.linkedin.com/jobs/view/senior-data-scientist-toronto-at-youvisit-1594172699?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=2&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Conduct advanced exploratory data analysis on large datasets across multiple data sources.    Develop and test hypotheses and provide insights based on the results of statistical analyses.   Determine the best algorithms to apply to the data, including machine learning tools as appropriate.   Work in teams to develop machine learning models that support and enhance our products by adopting best practices in processes and techniques for statistical modeling.   Prototype and build new machine learning pipelines that train the models.   Build tools and metrics to monitor and analyze model performance and data accuracy.   Collaborate with other Data Scientists as well as the Product and Engineering teams to deliver data products and incorporate your models/pipelines/architectures into new deployed products.   Effectively communicate model results and limitation considerations to internal stakeholders.   Provide mentorship and guidance to our junior Data Analysts/Businesses Intelligence Engineers and Data Scientists in the Data & Analytics team.   A Master's or Ph.D. degree in Computer Science, Math, Statistics, Physical Sciences, Engineering or other related quantitative fields.   5+ years of industrial experience in related roles, solving complex problems including machine learning applications.   5+ years of experience performing advanced data analysis using SQL, Python (numpy, scipy, pandas, scikit-learn, tensorflow/keras/pytorch, etc.), R or other equivalent languages.   Strong background in SQL, relational data modeling, and data architecture.   Experience working with Spark, Hive, Hadoop, Elasticsearch, Kinesis, Kafka.   Ability to write production-quality code applying knowledge of data structures and algorithms with Python or related programming languages.   Understanding of common software development practices around design, coding, and testing of large codebases.   Background in NLP/NLU.   Background in Info Retrieval.   Previous experience building production-ready recommender systems.   Experience with marketing technology products (interactive web content, web browsing tracking, etcâ€¦) and related metrics and analytics.   Experience in a SaaS-based growth-stage company.   Experience in the MarTech, AdTech, or EdTech space.   Located near Penn Station surrounded by great food, entertainment, shopping, multiple transportation points, and much more!   Open floor plan for ease of communication and increased visibility   Fully stocked office with snacks and flexible workspace   Bi-weekly catered lunches with the entire office   Cutting edge technology to work on   Career development and training   Competitive salary and incentives   Comprehensive health, dental, and vision coverage   401K   Generous vacation, paid holidays, unlimited sick days"
Data Scientist,Overbond,https://ca.linkedin.com/jobs/view/data-scientist-at-overbond-1603897232?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=3&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Collect, analyze and visualize colossal datasets using a variety of emerging technologies to help solidify our understanding of users and improve product decision-making   Design, build and maintain an expanding set of robust predictive models and applications to drive forecast accuracy   Lead data science initiatives to recommend actionable business insights using big data analytics and machine learning techniques   Leverage distributed and open-source computing tools for recommendations, classification, regression, and feature extraction, from logistic regression to matrix factorization, to deep learning neural networks   Prepare detailed documentation to specify data sources, models and algorithms used and developed   Collaborate with the engineering team to deploy models and algorithms in production   Effectively communicate data insights in a non-technical manner to key stakeholders and senior management team    Bachelor or Masters degree in relevant disciplines (Mathematics, Computer Science, Statistics, Electrical/Software Engineering)   5+ years of experience in data mining, machine learning and statistical modeling   Solid understanding of the underlying statistical theory and predictive modeling lifecycle   Proven track record of building and demonstrating business value from predictive models and data products   Highly proficient in building statistical and algorithmic models with complex and large data sets such as supervised statistical learning, times-series analysis, regression analysis, data visualization and deep learning   Capability to architect highly scalable distributed systems, using different open source tools   An entrepreneurial mindset, likes working in an agile environment, driven to ship frequently   Excellent communication and interpersonal skills    Team-oriented, pragmatic, self-starting   Likes to learn and grow with teammates in a highly collaborative and open environment   Understanding of, or interest in, finance and investments   The challenge and opportunity of joining an exciting startup company   Opportunity to work on a real product with very demanding paying enterprise clients   Lots of opportunity for learning and self-development   Ability to contribute in all stages of product development"
Epidemiologist/ Data Scientist,LMC Healthcare,https://ca.linkedin.com/jobs/view/epidemiologist-data-scientist-at-lmc-healthcare-1524237191?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=4&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Management of large data sets including extraction, manipulation and data analysis   Protocol design and writing; Abstract writing; Poster development, Manuscript writing and submission   Research project coordination, training of staff, and project management   In–depth data analysis and reporting for research projects using various statistical methods and software   PhD degree in Epidemiology or Health Sciences   Minimum of 2 years experience with statistical analysis   Proficiency with statistical software packages such as SAS, SPSS, or R, and familiarity with Word, Excel, PowerPoint, Access, PRISM, and other packages and programming languages   Experience in manipulating large data sets   Excellent verbal and written communication skills to present various data and concepts to diverse audiences including clinical staff and external parties such as industry experts, and to prepare written summaries of research reports and scientific manuscripts   Driven to achieve and produce abstracts and manuscripts to drive learning and patient care in diabetes.   Ability to work collaboratively within an interdisciplinary team   Adaptable and ready to work in a fast-paced and changing environment   Strong initiative, organizational and project management skills   Endocrinology Specialist Practice (publicly-funded) - representing the largest group of Endocrinologists globally   Nationally-accredited Diabetes Education Program (publicly-funded)   Diabetes Pharmacy   Chiropody & Foot Specialist Care   Optometry & Eye Specialist Care   Canada's largest Clinical Research network specializing in Diabetes innovations   2016 Certified Best Workplace™   2014 and 2015 Canada's Best Workplaces™   Competitive Salary   Comprehensive Health Benefits   RRSP contribution matching   Education allowance (days and funding)   Ongoing career training and development   Employee Appreciation Days Off   Additional Holiday Closure   Opportunities to work with internationally renowned Endocrinologists   State of the art Electronic Medical Records (EMR) environment"
Data Scientist,Nulogy,https://ca.linkedin.com/jobs/view/data-scientist-at-nulogy-1595652981?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=5&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Research, develop and build machine learning models that generate insightful recommendations for customers   Work alongside data scientists and data engineers to deploy models in production   Work alongside product management and other stakeholders to translate business requirements into machine learning functionality   Conduct statistical analysis to discover trends in data   Develop optimization algorithms to improve customers operations   Help distill complex machine learning products to various audiences   Identify data driven opportunities across the Nulogy platform and communicate findings to the appropriate stakeholders   Develop domain expertise in supply chain   Degree in Computer Science, Statistics, Math, Operations Research, Engineering or equivalent   MSc in related fields a big plus   3-5 years of industry experience working as a Data Scientist   Deep knowledge in machine learning, data mining and statistics   Extensive experience using Python (pandas, numpy, scikit-learn, etc.)   Expert SQL experience   Exposure to optimization and scheduling algorithms   Experience working in an agile environment   Strong software engineering fundamentals   Expertise in optimization and operations research   Strong business acumen   You are an expert in python    You are an expert in applied statistics, data mining and machine learning   You are a creative problem solver   You are capable of narrating the story behind the data to a non-technical audience   You value autonomy, and are capable of owning data projects from start to finish   You are comfortable working with messy data   You have experience with SQL"
Data Analyst,Covenant House Toronto,https://ca.linkedin.com/jobs/view/data-analyst-at-covenant-house-toronto-1594464780?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=6&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Bachelor's Degree in Statistics, Math, Computer Science or other   Minimum of 4 years of relevant experience   Experience running and writing queries and stored procedures   Experience in performing inserts and updates, creating databases, tables, indexes, views and other database objects   Intermediate database and data management skills   Experience in creating databases, tables, indexes, views and other database objects   Experience with Microsoft Excel, Power Query, Power BI and Crystal reports or other business intelligence (BI)/analytical tools   Must have strong skill in SQL Query   Experience in direct marketing is also an asset   Detail oriented   Analytical   Accuracy and quality assurance   Excellent interpersonal skills   Strong communication skills with the ability to communicate with technical and non-technical staff   Life-learner who stays on top of industry changes   Meaningful work   Competitive compensation   Paid vacation time   Full benefits package (Health, Dental, Vision, Personal Days, Employee Assistance Program, Tuition Reimbursement and more)   Employee Perks "
Senior Data Scientist (Multiple Roles),Shopify,https://ca.linkedin.com/jobs/view/senior-data-scientist-multiple-roles-at-shopify-1571105249?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=7&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click,"Understanding of dimensional modelling concepts and database design/architecture or experience with feature engineering both at model build and in production   Experience with statistical methods like regression, GLMs, clustering, experiment design, including sampling and multi-armed bandit approaches, shipping productionized machine learning systems at scale and other predictor or classifier models   Extensive experience using Python including a strong grasp of object oriented programming (OOP) fundamentals   Extensive experience analyzing data using SQL   Exposure to Tableau, QlikView, Mode, Matplotlib, Jupyter, or similar data visualization tools   Strong background in machine learning including experience implementing models at scale (from Random Forest and GBMs to RNN/CNNs)   Knowledge of digital marketing and traditional media data and metrics   Previous experience using Spark (esp. via Python or Scala)"
Customer Facing Data Scientist - Toronto,DataRobot,https://ca.linkedin.com/jobs/view/customer-facing-data-scientist-toronto-at-datarobot-1497552999?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=8&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click," Product     Representing the DataRobot product from a technical standpoint to customers - including demonstrations, conducting proof-of-concept trials, helping clients evaluate success criteria, and training users     Providing the customer’s point of view to DataRobot’s Product team, informing the direction of future product feature development     Data Science     Enabling customers to solve complex data science problems using DataRobot - including problem framing, data preparation, model building, model deployment, model management, and output consumption     In some cases, executing data science workflows for customers     Providing data science knowledge and expertise as a trusted advisor to the client     Project management     Conducting and managing data science projects with customer’s vision of success in mind     Collaborating with Sales, Field Engineers, and the rest of the DataRobot team to identify the best possible resources to move forward customer’s projects     Leadership     Building a long-term trusted relationship with the customer so that the customers can be led towards success     Understanding and empathizing with customers’ pain points of building AI solutions     Qualifying opportunities where DataRobot can be a suitable fit and thus making DataRobot more efficient     Presenting DataRobot in industry conferences as well as creating powerful technical content for marketing purposes     4-5+ years of real-world business experience in a data science role     Hands-on experience building and implementing predictive models using machine learning algorithms     Strong customer interaction experience     Strong project management skills     Excellent organizational, communication, writing and interpersonal skills     Familiarity with a variety of technical tools for the manipulation of datasets     Fluency with scripting (Python / R)     Going onsite to customer locations in and around Toronto. Up to 20% Travel outside Toronto area, including to US.     Familiarity with consultative sales process in the analytics marketplace     Familiarity with Hadoop and related Big Data technologies     Experience dealing with complex customer organizations     Deep experience with specific industries (e.g. banking, healthcare, insurance) or specific problem types (e.g. time-series, optimization)"
Data Engineer,Ritual,https://ca.linkedin.com/jobs/view/data-engineer-at-ritual-1600229697?refId=646a1ff6-f6ab-4006-a821-99c7600787ab&position=9&pageNum=1&trk=guest_job_search_job-result-card_result-card_full-click," You’ll be getting your hands dirty with the data plus thinking big picture to develop our longer term data strategy     Create and maintain optimal data pipeline architecture     Assemble large, complex data sets that meet functional / non-functional business requirements     Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.     Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources     Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics     Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs     Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader     We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field     Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases     Experience with object-oriented & functional scripting languages including Python and Java     Experience building and optimizing ‘big data’ data pipelines, architectures and data sets     Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement     Strong analytic skills related to working with unstructured datasets     Build processes supporting data transformation, data structures, metadata, dependency and workload management     A successful history of manipulating, processing and extracting value from large disconnected datasets     Strong project management and organizational skills     Experience supporting and working with cross-functional teams in a dynamic environment     Understands and helps drive business impact via data systems and their resulting output     Competitive salaries – we strive to pay top market compensation     Every Ritual employee owns equity and becomes a shareholder     Health coverage & life insurance plans to fit your needs     Flexible vacation policy – work hard and take time when you need it     Ritual credits provided daily for coffees and lunches at the best spots around you     Work with truly world class peers in a highly collaborative culture     Be at the heart of the growth startup community"
Marketing Analyst / Data Scientist,TripElephant Inc.,https://ca.linkedin.com/jobs/view/marketing-analyst-data-scientist-at-tripelephant-inc-1496028632?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=1&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Perform preprocessing of structured and unstructured data     Review large amounts of information to discover trends and patterns     Create predictive models and machine-learning algorithms     Modify and combine different models through ensemble modeling     Develop and suggest solutions and strategies to business challenges     Work closely with data analytics (in effect, our whole company) to implement stat-sig analysis and decisions.    2+ years' experience of working on Data Scientist or Data Analyst     Significant experience in data mining, machine-learning and operations research     Proficient in SQL (all our data is pre-cleaned and structured, but there is ALOT of if) you must be able to be resourceful, editing and writing queries to connect the dots in related and unrelated data structures     Strong math and analytical skills, with business acumen"
Data Analyst,CST Consultants Inc.,https://ca.linkedin.com/jobs/view/data-analyst-at-cst-consultants-inc-1595285099?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=2&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Support the department with the implementation of any initiatives, tools and projects that will improve Gather requirements, develop and roll-out reporting for all customer sales and service metrics/KPIs used to support management decision-making and provide value added analysis   Utilize available tools and/or work with the IT department to automate reports, build models and perform complex data analyses to identify key customer sales and service insights and solutions   Maintain and ensure the integrity of historical departmental data to build a strong base for forecasting, team performance management, and continuous improvement   Generate strategic/operational reports and share immediate business insights and key findings in the report with the audience   Answer any deliverable related questions from the audience in a timely manner and continuously improve deliverables based on improvement suggestions provided   Analyze all customer service metrics, KPIs, and trends forecasts within the department to identify root causes for issues/variances, make recommendations, and identify opportunities for service improvements   Communicate and provide feedback regarding Departmental performance metrics to Management and Executives   Responsible for making recommendations to management for staffing needs, scheduling and service metrics, day-to-day operations, and process adherence    Support the department with the implementation of any initiatives, tools and projects that will improve customer satisfaction, operational efficiency or reporting   Fulfilling analytical needs of other departments within the organization from time to time   3+ years data analyst experience; have demonstrated analytical and problem-solving ability with a track record of results    A post-secondary education, preferably in a business, math or engineering related discipline, or equivalent work experience   Expertise in Excel, Access, VBA, and/or SQL    Expertise in Tableau / PowerBI / ETL tools    Expertise in R / Python an asset    Experience in designing and analyzing marketing surveys and tracking studies an asset   Contact centre and/or financial services and/or management consulting experience an asset    Self-motivated, innovative, attentive to details and solutions-oriented   Strong team player   Strong written and verbal communication skills   Strong organizational and interpersonal skills   Excellent customer service and professional communication etiquette   Strong people & relationship building skills; team player; able to work with all levels (junior to executive)   Personable, energetic, positive with ""can-do"" attitude "
Data Analyst,J. Walter Thompson Worldwide,https://ca.linkedin.com/jobs/view/data-analyst-at-j-walter-thompson-worldwide-1600388486?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=3&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Develop tracking guidelines based on measurement plans, following the brand strategy and client key performance indicators.   Create and maintain tracking tags (including media tags) for accurate reporting for website analytics on weekly and monthly basis. Test tags to ensure data is being captured accurately.   Development of dashboards and reporting on various client’s marketing channels including but not limited to website, display ads and social.   Deliver weekly and monthly analytics reporting by: Extracting data from various analytics tools. Manipulating data outputs to accommodate data visualization tools. Preparing outputs for client presentations.   Implement a creative testing framework including marketing best practices. Work with media partners to gather, interpret and report creative results   Target setting and recommendations to achieve targets.   Build ad-hoc reports, analytics and presentations based on available data sources Analyze data for trends and identify areas for business growth.   Identify opportunities for on-site UX/UI optimizations. Interpret results.   3 - 5 years related industry experience required.   1+ years Agency experience preferred.   High proficiency with Excel and PowerPoint   In-depth knowledge of Web Analytics tools (Google 360 [including Big Query], Crazy Egg, Adobe Analytics)   Experience creating dashboards in Data Studio, Tableau &   Experience with tag management tools/working closely with a team to implement tags   Basic JavaScript knowledge an asset.   Understanding of how data helps to drive business decisions.   Ability to generate actionable insights.   Excellent communication skills; skillful at engaging and interacting with clients.   Experience working in a cross-functional team environment.   Nice to Have: SQL, Python, R"
"Lead Data Scientist 3, Words with Friends",Zynga,https://ca.linkedin.com/jobs/view/lead-data-scientist-3-words-with-friends-at-zynga-1499333676?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=4&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Work with large amounts of data to find opportunities to improve the experience that Zynga provides to its players   Define analytics and data science roadmap, balancing actionable insights to substantially improve core game metrics   Drive and empower game studio to make quantitatively informed, evidence based decisions   Work closely with game team to design, test, verify and implement machine learning models with Zynga’s games that impact millions of users   Design and evaluate novel scalable approaches to experimentation   BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters, MBA or PhD preferred   5+ years of work experience in data science or analytics roles   Fluent in SQL; Strong experience with programming in Python and/or R; Adept in at least one visualization tool such as Tableau, or QlikView   Demonstrated experience with some or all of the following: statistics, experimental design, machine learning, data mining, predictive modeling, deep learning   Experience in analyzing large datasets, preferably in a Hadoop or Spark environment, and deploying production-ready systems at scale   Strong written and oral communication skills   Ability to work effectively in a fast-paced environment with changing priorities   Ability to collaborate effectively with engineers, product managers, analysts, and marketing to deliver unambiguous business impact   Strong passion for gaming!   Zynga Stock RSUs and Bonus Plan   Full medical, dental, vision benefits as well as life insurance   Catered lunch daily   Generous Paid Maternity/Paternity leave   Open vacation policy for many employees   Flexible working hours on many teams   Casual dress every single day   Work with cool people!"
Data Analyst (Analytics & Insights),Cossette,https://ca.linkedin.com/jobs/view/data-analyst-analytics-insights-at-cossette-1557966711?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=5&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Analyzing and preparing 1:1 and media reports for clients   Creating scripts/queries and ETL tools to automate report generation   Working to build and populate client dashboards by using the internal data infrastructure   Using web analytic tools such as Adobe Analytics or Google Analytics to provide insights on performance of digital campaigns   Assisting with ad operations/media trafficking   Effectively performing analysis of various types of 1:1, digital media packages and digital media opportunities   Establishing KPI’s and success metrics for digital campaigns, including DR campaigns   Collaboratively working to analyze and develop cross-platform media opportunities that include digital media elements   Assisting in the preparation of documents and reports for client meetings and ongoing client communication   Explaining complex data and analytical concepts and processes to non-analytic based teams (both via email and in face-to-face situations)   Other duties may be assigned as is deemed necessary to meet client, team and company needs"
Data Scientist - NLP / ML,The Calliere Group,https://ca.linkedin.com/jobs/view/data-scientist-nlp-ml-at-the-calliere-group-1594010232?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=6&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Exceptional numerical ability and creative thinker/problem solver.    Experience using some of the major data science tools e.g. Python (preferable), R, SAS, etc.    Organized, autonomous, and a drive / commitment    Excellent interpersonal skills: the candidate would be expected to work across and between existing teams.    Strong communication and presentation skills, including the ability to translate analyses to non-technical audiences.    Proficiency in statistical modelling and machine learning techniques e.g. k-means, decision trees, neural networks, ensemble learning, etc.    Good working knowledge of SQL and understanding of data modelling and relational databases.    Experience in handling big-data an advantage e.g. AWS/Spark/Hadoop.    Experience of machine learning libraries e.g. Pytorch, scikit-learn, Tensorflow.    Experience in feature engineering and designing robust model tuning approaches.    Knowledge of/experience with cloud-based applications and development in e.g. Amazon, Azure    Experience with one or more programming languages C/C++, Java, FORTRAN, VB.net/C#, Python, etc.    Familiarity with DevOps practices including source code management/version control e.g. git, SVN and automated testing    Experience of natural language processing and associated techniques e.g. word-embedding, pos-tagging, etc. as well as associated software libraries e.g. StanfordCore NLP, NLTK, Spacy, etc.    Knowledge of advanced AI techniques i.e. deep learning, reinforcement learning, etc."
Product Data Analyst,HomeStars,https://ca.linkedin.com/jobs/view/product-data-analyst-at-homestars-1550940434?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=7&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,
"Data Scientist, Co-Op, Jan '20(Toronto Location)",LoyaltyOne,https://ca.linkedin.com/jobs/view/data-scientist-co-op-jan-20-toronto-location-at-loyaltyone-1525305367?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=8&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Open concept and casual relaxed attire within the office    Free on-site coffee, beverages, fruit & snacks    Subsidized café providing healthy food options    On-site gym classes, Wellness Centre, GoodLife Membership Discounts Games room, outdoor terrace, mini-putt, ping-pong, shuffle board & Foosball    High impact role with interesting challenges    Flexible hours and strong work life balance    Free shuttle bus from Union Station    Inclusive events for co-ops, sports games, nights out & more! Internal co-op mentoring program    One of the highest performing companies in the market (NYSE: ADS)    The ability to work in an open concept environment with no assigned seating    Company wide volunteer event and charitable matching donations    Implement advanced machine learning techniques and statistical and econometric models to pricing, assortment and marketing mix. Provide analytical consulting on best practices and approaches.    Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations based on customer-centric data. Be an internal expert in advanced capabilities.    Work closely with client teams to develop methodology and implement analysis and technology that enables more profitable pricing, assortment and marketing/promotion decisions in support of partner customer strategies.    Take analytical objectives and define data requirements.    Extract, clean, and transform customer and item-level data for purposes of analysis, modeling/segmentation and reporting    Identify, develop and make recommendations for process improvements and best practices; own implementation of recommendations required.    Execute on Precima’s engagement with Clients, delivering on our commitments and assisting the client to understand and derive the most value out of Precima-provided initiatives and tools.    Continually support a strategic viewpoint as subject matter experts vs. data support to client.   Masters (PhD highly desirable) in Statistics, Operations Research, Mathematics, Economics, Econometrics, Industrial Engineering, Computer Science    Proficiency in developing original statistical and econometric models in pricing, assortment and marketing mix to support clients in B2B, Retail and CPG areas.    Strong experience on SQL, SAS / Python / R.    Proficiency in implementing models using Python or R."
"Senior Data Analyst, Business Operations",AppLovin,https://ca.linkedin.com/jobs/view/senior-data-analyst-business-operations-at-applovin-1561421341?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=9&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Apply data driven problem solving to find and execute top growth opportunities for the company     Define and analyze metrics to achieve success for our partners     Monitor daily performance against key metrics to identify opportunities and anomalies     Become a mobile advertising guru and expert on our suite of products     Stay relevant on industry trends and work with product team to develop high impact features     Help define and shape companies business intelligence products and tools     2-5 years in a Data Analyst or similar role     Bachelor’s degree or higher in Computer Science, Information Systems, Business, Economics, or equivalent analytical degree     Demonstrate outstanding analytical ability, comfort working with numbers, and strategic grasp of the “big picture”     Have experience prioritizing competing demands     Proficiency in Excel, and comfortable working with large data sets     Flexible team-player who can use drive, creativity and initiative to move the organization forward     Demonstrated experience applying statistical methodologies to real world problems     Ability to communicate complex results with clarity to both technical and non-technical audiences     Basic understanding of SQL and data structures     Proven interest in technology     Passion for mobile games     Previous mobile industry experience is a plus but not required    Competitive Salary    Comprehensive medical insurance    Free lunches and fully stocked kitchen   Commuting benefits    Gym membership benefits     Fun company parties and events     Autonomy to make decisions in a rapidly growing company "
Data Engineer,"Hitachi Solutions, Ltd.",https://ca.linkedin.com/jobs/view/data-engineer-at-hitachi-solutions-ltd-1581397740?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=10&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Hands-on experience with the Azure Data Platform (Data Factory, Data Lake, Data Warehouse, Blob Storage, SQL DB, Analysis Services)    Data quality (profiling, cleansing, enriching)    Data Modeling – including design from conceptual to logical to physical data models    Considered to be an expert in T-SQL    Hands-on experience with MPP database technologies such as Azure SQL DW, Teradata Netezza, etc.    Knowledge of Cap Theorum and Distributed Database Management Systems    Opportunity for a career path into a Data Scientist role if desired    Nice-to-have:    Power BI including DAX    Database migration from legacy systems to new solutions    DevOps    Interpreted languages (i.e. python, C-sharp, Java, Scala, etc.)    Databricks    LogicApps    PowerApps    HDInsight    D365FO / CE experience as it pertains to data extraction    Proven ability to engage customers to understand customer challenges and needs to develop technical solutions    Proven experience of architecting Azure services into a solution platform on Microsoft Azure for Analytics OR a strong level of technical experience on a competing cloud platform (i.e. AWS, GCP) with a desire to grow into an expert role on the Azure platform    Hands on development experience with ELT/ETL using MS SQL Servicer, Oracle or similar RDBMS Platform (minimum 5 years)    Experience or desire to coach, mentor and provide leadership to team members    Familiarity with data visualization tools (e.g. PowerBI, Tableau etc.)    Post-secondary degree/diploma in Business, Computer Science or a related discipline;    Prepared for domestic and US travel as required whilst recognizing the goal is to service local customers whenever possible    Nice-to-have:    Project management experience    Databricks and Spark SQL    Previous Consulting experience"
ERP Data Analyst,Motion Specialties Inc,https://ca.linkedin.com/jobs/view/erp-data-analyst-at-motion-specialties-inc-1598900220?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=11&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Data analysis. You will use your technical expertise to clean, reorganize, summarize, and derive meaning from large data sets. You will generate progress reports on data maintenance initiatives; identifying risks and areas for improvement. You will cleanse and analyze inventory count and customer files before entering them into Navision.    ERP support. You will solve ERP helpdesk requests to ensure information quality and data accessibility. You will add new vendors into Navision and will assist end-users with item code use.    Data management. You will lead the strategy behind ERP data table structures and will find a way to upload master data sets as efficiently as possible. You will perform regular data audits to check and increase the quality of existing data records.    Cross-functional collaboration. You will work with teams across the organization to learn the business context of ERP processes and will develop a strong understanding of ERP product configurations. You will work with the finance team to upload physical inventory count files and will help reconcile physical to book adjustments. You will identify teams and locations that would benefit from extra technical training.    The education and experience. You have a post-secondary degree as well as 2+ years of experience working with business systems such as ERPs, SCMs, PDMs, etc. Ideally, you have worked at small to mid-sized manufacturing or distribution companies in the past.   The analytical mindset. You’re an Excel power user who is excellent at manipulating data to create insightful reports. You are well-versed in test procedures, SQL-Transact language, and relational database theory including its principles and structures.    The drive. You’re a self-starter with excellent problem-solving and conceptual skills. You’re a strong multi-tasker with the ability to prioritize based on business needs. You’re a team player who works well autonomously. "
Machine Learning Engineer / Data Analyst,24-7 Intouch,https://ca.linkedin.com/jobs/view/machine-learning-engineer-data-analyst-at-24-7-intouch-1579107797?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=12&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,
"Data Scientist, Digital Products (English Services)",CBC/Radio-Canada,https://ca.linkedin.com/jobs/view/data-scientist-digital-products-english-services-at-cbc-radio-canada-1596195138?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=13&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"  C utting edge tech. You will be utilizing Google Cloud Platform to design, enhance and optimize our data implementation infrastructure. While data integration is your main responsibility, you will have the chance to experiment with various algorithms to develop an understanding of audience behaviour.      B uilding. You will create key data systems and data pipelines for the collection of content features, user features and link disparate data sources.      C areer growth. You’ll be joining a team of highly capable and creative Machine Intelligence developers, that has a strong team culture. CBC is fully invested in our people. We will provide you with the time, resources and championing that you need to keep your career here rewarding.     An understanding of database design principles. Implement business requirements through multiple phases of database design and development lifecycle (i.e. data modelling, database architecture/design, database development, testing, support/tuning, etc.).     The passion for machine learning and data. You will use modern tools to define, build and manage cloud infrastructure to gather, structure, and process million of records, from multiple sources, at scale. Familiarity with end-to-end data science application development is a plus.     The education and the technical skills. At a minimum a Computer Science, Engineering degree or equivalent is preferred. Strong Python skills, along with knowledge and experience in Big Data technologies, NoSQL, Google Cloud Platform, AWS, ETL, Statistics, or academic research. "
Senior Data Scientist – Front End and Personalization,Agoda,https://ca.linkedin.com/jobs/view/senior-data-scientist-%E2%80%93-front-end-and-personalization-at-agoda-1442563094?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=14&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Design, code, experiment and implement models and algorithms to maximize customer engagement and business outcomes.   Mine a big data of hundreds of millions of customers and more than 600M daily user generated events and discover actionable insights to drive improvements and innovation.   Work with developers and a variety of business owners to deliver daily results with the best quality.   Research discover and harness new ideas that can make a difference.   3+ years hands-on data science experience.   Excellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks.   Significant proficiency in SQL and languages like Python, PySpark and/or Scala.   Can lead, work independently as well as play a key role in a team.   Good communication and interpersonal skills for working in a multicultural work environment.   PhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields   Experience in NLP, image processing and/or recommendation systems   Hands on experience in data engineering, working with big data framework like Spark/Hadoop   Experience in data science for e-commerce and/or OTA"
Data Science Specialist Gen Med INpatient Initiati - Toronto,"St. Joseph's Health Centre, Toronto",https://ca.linkedin.com/jobs/view/data-science-specialist-gen-med-inpatient-initiati-toronto-at-st-joseph-s-health-centre-toronto-1594215936?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=15&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Perform descriptive statistical analysis in R, including but not limited to: variability, z-scores, skewness, kurtosis, confidence intervals, coefficients of variation;    Perform inferential statistical analysis in R, including statistical tests for significance, such as null-hypothesis testing;     Manipulate, transform, and combine data from multiple R data sets to prepare for multiple study design formats, including cross-sectional, cohort, and case-control studies, and randomized trials;    Follow detailed study protocols and analysis plans to perform a wide variety of statistical analyses, including: multivariable modeling, multilevel hierarchical analysis, longitudinal designs (including repeated measures), propensity score analysis, genetic algorithms, prediction modeling, multiple imputation;    Conduct analyses with basic supervised and unsupervised machine learning methods;    Validate any output tables, listings or figures generated to ensure accuracy and reliability of analyses;    Prepare tables and patient lists to help research assistants perform manual chart review    Produce high quality ad hoc and standardized reports customized per study, using R procedures;    Perform data audits to ensure the accuracy, integrity, and completeness of data;    Data cleaning and validation of raw data following Standard Operating Procedures to ensure data is complete, accurate and of high quality prior to analysis;    Develop workflows and automation scripts to maintain and streamline work;    Maintain high quality coding practices and documentation of coding;    Efficiently identify and correct syntax and programming logic errors in R code.    A Master's in Computer Science, Bioinformatics, Biostatistics or related discipline;    At least 3 years’ relevant experience;    Fully proficient in the use of R, SQL and MS Office software (Word, Excel, PowerPoint, Outlook, Internet Explorer, etc.);     Experience using databases such as: PostgreSQL, MySQL, Access, REDCap is a plus;     Knowledge of Python, Perl, and Matlab is a plus;    Experience with the Ontario healthcare system is an asset;    Understanding of oncology data holdings at CCO, ICES, MOH is an asset;    Familiarity with health data and advanced knowledge in data science in a clinical research setting is a plus;     Experience with working with large datasets using high-performance clusters or GPUs is a plus;    Demonstrated ability to develop software tools and support analytical operations;    Experience preparing data for varied statistical methods preferred;    Excellent attention to detail and proven ability to learn new skills;    Experience working independently and as part of a team;"
"Manager, Data Scientist (2 year contract)",Scotiabank,https://ca.linkedin.com/jobs/view/manager-data-scientist-2-year-contract-at-scotiabank-1541085201?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=16&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Design and build machine learning solutions to Retail Credit Risk Stragies leveraging big data decisions in core banking systems and credit risk technologies   Support existing analytic pipelines by delivering innovative, cleanly coded and well documented machine learning models to improve the profitability and credit risk life cycle decisioning   This individual will leverage large-scale data skills to manage and transform multiple sourced data and non-traditional data timely delivered   Deliverables will be set under AGILE rapid lab environments   Excellent communication and presentation skills   2+ years hand-on industry experience in a machine learning role working with Python (data analysis libraries)   4+ years total machine learning experience, including years of academic research   Solid experience designing and building large-scale data solutions to business problems and or modeling development   Proficiency in database management such as SAS, SSPS, SQL is desired but not a requirement   University / Master’s Degree in Computer Science or related field"
Sr. Data Scientist who will be responsible for mining big data and turning that data into actionable intelligence for clients products and services using SQL and Big Query - 13921,S.i. Systems,https://ca.linkedin.com/jobs/view/sr-data-scientist-who-will-be-responsible-for-mining-big-data-and-turning-that-data-into-actionable-intelligence-for-clients-products-and-services-using-sql-and-big-query-13921-at-s-i-systems-1524420588?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=17&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"SQL   BigQuery   Big Data Experience    Data Tools  (Python, R, Hive, or SAS)   Data Analytics  (Predictive Model Development & Location Analytics)   Google Cloud   Data Communication   Previous Telecommunications Experience"
Data Science Manager,Mozilla,https://ca.linkedin.com/jobs/view/data-science-manager-at-mozilla-1542572093?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=18&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"You are comfortable steering a team of 2-7 data scientists to align with business priorities, legal and policy agendas, and Mozilla’s greater mission   You pride yourself on your ability to communicate technical concepts to diverse audiences across Mozilla   You define requirements for data scientists to other parts of the Mozilla organization   You collaborate with cross-functional management to create new initiatives and refine existing processes that increase the impact of the data science team   You possess a strategic mindset and find motivation in creatively solving problems   You establish best practices for data science workflows and know how to create an environment and team culture that enables data scientists to perform at their best   You have a strong desire to contribute to Mozilla’s mission through data science   At least 2 years directly managing a team of data scientists.   At least 5 years of industry experience in the data science profession.   You have experience with a breadth of analytical methodologies and possess a solid foundation in numerous statistical techniques   You also have experience with common data science technologies, namely SQL, Python, or R, as well as familiarity with conventional code and programming concepts   You have strong communication skills; experience speaking at industry or academic conferences a plus   You consider contributing to a collaborative and open team culture an important responsibility   Purpose is built into our work, with our mission driving every decision   We challenge assumptions, the status quo, ourselves, and each other   We are transparent: in our code, our business partnerships, and our everyday interactions    We seek out people from diverse backgrounds and with perspectives different from our own    We pair purpose with performance and put people ahead of profit   1000+ paid staff from over 30 countries   Thousands of volunteer contributors across six continents   10 global offices: Beijing, Berlin, London, Paris, Mountain View, Portland, San Francisco, Taipei, Toronto and Vancouver   Hundreds of home offices globally   Flexible work environment (nearly half of Mozillians work remotely)   Industry-leading paid parental leave (up to 26 weeks of fully paid leave for childbearing parents and up to 12 weeks for non-childbearing parents)   Reimbursement for professional development (up to $3,000/year)   A work setup including the latest hardware and software of your choice   Wellness programs—we reimburses up to $1700/year for expenses like child and elder care, mental wellness, and personal enrichment "
2 x Data Scientists,Alquemy Search & Consulting,https://ca.linkedin.com/jobs/view/2-x-data-scientists-at-alquemy-search-consulting-1509012164?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=19&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Stats or Math Background    R and Python    AI   SQL   Understand logic of how to build models    Breakdown problems and understand how to articulate a solution    Troubleshoot equations    Modelling for Attrition rate    Example - understand sales data, build a model to support this"
Data Scientist,BrainStation,https://ca.linkedin.com/jobs/view/data-scientist-at-brainstation-1569735324?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=20&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Lead our 12-week Data Science Diploma program   Help build a world class technical team   Deliver lectures and mentor the next wave of Data Science talent   Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses   Actively work on writing and researching new content to teach the most up to date skills in data science to our students   Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students   Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material   Define the education experience of the future   3+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years experience as a Data Scientist or Analytics professional   Experience building and leading teams   Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modelling and machine learning principles   Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner   Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job   An empathetic, friendly, and approachable demeanour   A proven ability to work under pressure and meet deadlines   Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings."
Enterprise Big Data Specialist,TMX Group,https://ca.linkedin.com/jobs/view/enterprise-big-data-specialist-at-tmx-group-1597305277?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=21&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Developing and managing a broad range of data systems, architecture, and application components & processes across the entire data value chain from data sourcing, ingestion to consumption for structured and unstructured data sets.   Evaluate new technologies and open source or third party products   Work closely with Data Governance, Architecture, Cloud Infrastructure & Applications teams to develop, implement and manage solutions for Enterprise Data Platform and Advance Analytical Platform.   Collaborate with business unit stakeholders in ensuring data quality metrics while ensuring compliance with data policies, standards, roles & responsibilities, and adoption requirements.   Collaborate with business unit stakeholders in selecting, introducing and integrating data consumption solution, tools & methodologies into the organization.   Coordinate and manage vendor work assignments    Collaborate external client’s technical team to setup new clients for Advance Analytical platform.    Provide oversight to operations of the data intake and Analytical platform functions from a technical development and data services activity standpoint.    Practice established development disciplines such as good code management, branching and merging of code in a GIT repository   Mentor/ train junior big data developers in the team.   Perform code review and proactively avoid exposure to platform vulnerabilities.   Lead moderate to complex assignments/projects and/or manage projects and the jobs/team(s) across different departments within TMX.   Advise on department/division or business level strategy but typically contributes to execution of strategy   Has relevant and highly developed professional and technical skills; experienced level of knowledge in field of expertise and strong knowledge of business/context   Ability to multi-task   Strong analysis / design experience   Meticulous attention to detail   Must be a self-starter with ability to follow through on projects assigned   Technical thought leader with hands-on experience in data technologies   Undergraduate degree in MIS, Computer Science   10+ years of overall IT experience in an enterprise environment   Minimum 3+ years in Big Data development/design including the following Hadoop eco system components – HDFS, Hive, Sqoop, Flume, Pig, Kafka, Spark / Spark SQL, Oozie, Hue and Java programming   Strong knowledge of various DMBS systems including NoSQL architectures and design principles.   Good understanding of AWS cloud technology and hadoop implementation on AWS including S3, EC2 and EMR   Proven experience in performance tuning Hive tables is required   Experience working with Big data development tools like Zaloni, Podium data, Informatica is an asset   Experience in Python, Scala, Zeppelin Notebook, Ranger a plus   Experience with development using Agile methodologies   Excellent interpersonal and communication skills   Be a strategic thinker with excellent analytical and problem solving skills   Previous experience in the financial and/or securities industry   Experience designing a technology stack for machine learning is an asset   Experience in the configuration of YARN, MapReduce for performance, security is an asset"
Data Analyst,Cover Group,https://ca.linkedin.com/jobs/view/data-analyst-at-cover-group-1587520520?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=22&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click," Delivering meaningful and impactful reporting that enable insights and solutions     Develop and maintain existing reports and dashboards to track KPIs across product, growth and sales     Identifying data inconsistencies and flagging for process improvement     Manage and develop our data analytics pipeline (ETLs etc.)    Understand how to make data visually appealing and simple to both navigate and comprehend     Solve business problems using data analytics, business intelligence, and critical thinking.     Work cross-functionally to design solutions to operations problems, influence product roadmaps, and solution new products/processes     BS/BA in Statistics, Math, Engineering, Computer Science, Economics, Business, or a related technical field    1-2 years of professional working experience involving data analysis     Strong proficiency with SQL-based languages. An ability to write and troubleshoot complex SQL queries.     Experience with data visualization tools (Tableau, Periscope, Looker, etc.)     Experience in analytical programming such as Python and R.     Strong analytical problem-solving skills, able to transform data into business insights and actionable recommendations     Strong understanding of analytics and how to measure the non-obvious within the domains of user acquisition, product improvements/optimizations, and sales operations     Has a keen interest in learning and getting involved in the business operations at Cover     Experience working on ETLs/data pipelines     Experience developing machine learning / predictive models to solve complex business problems     Experience in Technology or Insurance "
Senior Data Scientist,Rubikloud Technologies,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-rubikloud-technologies-1598304510?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=23&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Masters/PhD degree or equivalent in Computer Science, Engineering, Mathematics or related field   Strong familiarity with various machine learning & statistical techniques   Self-motivated, strong sense of ownership, and adaptable in a fast paced environment   Ability to initiate and drive projects to completion with minimal guidance   Strong written and verbal communication skills to describe results of analyses in a clear and effective manner   Proficiency in Python; software development experience is a plus   Experience working with relational data via SQL; experience with big data technologies such as Spark and Hadoop a plus   Ability to work in *nix environments   Experience in retail analytics is a bonus"
Data Analyst,Daisy Intelligence Corporation,https://ca.linkedin.com/jobs/view/data-analyst-at-daisy-intelligence-corporation-1548174977?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=24&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Educate new clients on data requirements of the products and solution   Establish a rapport with new clients, work very closely with both technical and business clients to gain an understanding of their data and processes   Conduct in-depth data analysis and profiling of client data   Conduct statistical, data validation and quality, assessments   Develop client-facing presentations and work with the client to resolve data issues.    Build automated solutions to aid in data onboarding and integration   Create data-related technical documentation    Develop appropriate data mappings to implement business logic into detailed technical ETL specs    Work collaboratively with ETL development roles to establish efficient and effective data transformation    Successful candidates will have a balance of functional (Business) and technical expertise   Experience in a client-facing, SaaS implementation environment    Knowledge of data warehouse concepts, processes, and ETL development methodologies   Understanding of dimensional data models   Understanding of ETL pipelines using SQL, Python, Hive, and Spark   Operational experience in a multi-platform environment (Linux, Windows)   Good knowledge of Hadoop and RDBMS (DB2 preferred)   Proven data analysis and manipulation skills, as well as experience in big data   Extensive experience with SQL preferably in a DB2 and Hadoop environment    Demonstrated proficiency in the use of shell scripting (Linux Bash, Python, etc.)   Knowledge of retail and/or insurance data is a plus   Proficiency in MS Excel importing and exporting data, creating pivot tables, and VLOOKUPs   Bachelor’s degree from a college or university is required, a Computer Science degree is nice to have.    Willingness to question the validity, accuracy of data and assumptions while remaining sensitive to clients' needs. Ability to develop warm client relationships   Strong written, oral communication, and interpersonal skills   Adept communicator with the ability to translate difficult concepts into layman’s terms and act as the interpreter between technical and non-technical implementation stakeholders   Ability to think critically, problem-solve, and innovate within a team environment   Demonstrated collaboration skills and experience working with cross-functional and/or remote teams to achieve common goals and client outcomes   High level of attention to detail, excellent time management skills, ability to perform under pressure   Availability to travel globally    Annual performance bonus   Group health benefits   Vacation allowance   Skills development   Flexibility   Start-up culture   Stock Options   All-day healthy snacks and drinks   Team events"
Data Analyst,Cover,https://ca.linkedin.com/jobs/view/data-analyst-at-cover-1526852837?refId=00312f42-8ad1-464f-b030-1a1a5df59bf9&position=25&pageNum=2&trk=guest_job_search_job-result-card_result-card_full-click,"Delivering meaningful and impactful reporting that enable insights and solutions   Develop and maintain existing reports and dashboards to track KPIs across product, growth and sales    Identifying data inconsistencies and flagging for process improvement   Manage and develop our data analytics pipeline (ETLs etc.)   Understand how to make data visually appealing and simple to both navigate and comprehend   Solve business problems using data analytics, business intelligence, and critical thinking.   Work cross-functionally to design solutions to operations problems, influence product roadmaps, and solution new products/processes    BS/BA in Statistics, Math, Engineering, Computer Science, Economics, Business, or a related technical field    1-2 years of professional working experience involving data analysis   Strong proficiency with SQL-based languages. An ability to write and troubleshoot complex SQL queries.   Experience with data visualization tools (Tableau, Periscope, Looker, etc.)    Experience in analytical programming such as Python and R.   Strong analytical problem-solving skills, able to transform data into business insights and actionable recommendations   Strong understanding of analytics and how to measure the non-obvious within the domains of user acquisition, product improvements/optimizations, and sales operations    Has a keen interest in learning and getting involved in the business operations at Cover   Experience working on ETLs/data pipelines   Experience developing machine learning / predictive models to solve complex business problems    Experience in Technology or Insurance"
Data Analyst - Toronto,Sunnybrook,https://ca.linkedin.com/jobs/view/data-analyst-toronto-at-sunnybrook-1600355923?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=1&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click," Assigns ICD-10-CA/CCI codes related to Acute Care Discharges (DAD)    Applies ICD10-CA/CCI coding methodologies resulting in proper grouping outcomes    Abstracting information according to standards from MOHLTC/CIHI (DAD, NACRS), and hospital abstracting guidelines    Ensures that all visits to be coded are done and balance at the end of each month    Document productivity in accordance with departmental protocols    Perform regular audits on coded/abstracted data to ensure quality of coded data and adherence to coding standards    Other related duties as assigned    Graduate from a recognized Health Information Management/Professional program.    Current active CHIMA member in good standing and maintained on an annual basis.    Certification with the Canadian Health Information Management Associate (CHIMA).    2 year previous experience in inpatient DAD coding    An in-depth knowledge and understanding of CMG's, HIG’s, ACW's, Case Mix Index (CMI) and expected length of stay    Demonstrated coding competency in Inpatient and Emergency patient records.    Demonstrated excellent organizational and communication skills.    Ability to work independently and exercise tact and discretion    Ability to work under pressure and meet deadlines.    Proficient in Windows-based applications environment and keyboard speed of 40 wpm    Demonstrated ability to function in a changing and sometimes stressful work environment    Must be willing to travel between Sunnybrook campuses as required"
Data Scientist,Perpetua,https://ca.linkedin.com/jobs/view/data-scientist-at-perpetua-1580872519?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=2&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Interact with Product Managers to translate customer business requirements into technical specifications.   Partner with software engineers on common areas of scalability, data quality management, data delivery management and performance optimization.   Track success criteria, communicate results with senior leaders, support adhoc requests, bridge technical and business program metrics   Design and implement metrics, data storage, and reporting mechanisms   Analyze customer data in order to improve the core strategies that power Perpetua’s advertising engine   Develop core features for Perpetua’s backend infrastructure   Work on advertising algorithms and large scale data pipelines   Work in a fast-paced, scaling start-up building software that is truly impactful   Degree in Computer/Software Engineering or Computer Science   3+ Years of Software Engineering Experience   2+ Years of Data Science Experience   Proficient in Python (Pandas, SciPy Stack); Google BigQuery and Dataflow a plus   A design thinking methodology coupled with quick and independent decision-making    Ability to solve problems in new and innovative ways   Self starter who takes initiative; owning a project from start to finish   Strong analytical and problem-solving skills   The ability to communicate complex technical issues in a clear and concise manner    Flexibility to adjust to changing priorities, requirements, and schedules   Experience working in a fast-paced, agile environment   Ability to understand the big picture   Previous experience with a fast scaling start-up   Experience with B2B or business insights and analytics   Master's Degree in Computer/Software Engineering or Computer Science   Relevant personal projects and open source work   Experience in the marketing or advertising space   Experience with PyTorch and/or Keras   Impactful work that will help lay the foundation for future projects   Meaningful equity at an early stage company   Ground floor opportunity    Paid-for meals   Unlimited snacks and drinks   Full benefits plus a health spending account   Top of the line technology to help you build your own workspace   Flexible time off policy"
Junior Data Analyst - Data Governance,Procom,https://ca.linkedin.com/jobs/view/junior-data-analyst-data-governance-at-procom-1566820705?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=3&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"The Junior Data Analyst, Finance Data Governance and Services, supports Finance in maintaining excellence in Master and Reference Data stewardship, data entry, and analysis.   This role requires interaction our major stakeholders in Finance Tax and Treasury, as well as with the rest of the team. The Junior Data Analyst will be responsible for ensuring:   Primary responsibility is to support and execute Master and Reference Data maintenance processes as we consolidate these processes into a single team for the whole Bank.   This includes active participation and engagement in these processes, as well as filling in data rekeying gaps as we centralize and retire legacy data applications.   Additionally, you will be called upon to pull report and help with producing analyses on our data as needed.   Reviews master data requests for completeness   Numbers new master data dimension members   Provides quality assurance on master data   Assists with the commissioning and decommissioning of data sets   Manually transfers / rekeys data from one application to anothera   Verifies data by comparing it to its source   Updates existing data, and retrieves data from databases or electronic files as requested   Organizes paperwork and backup so that it is not lost   Helps develop reports and analysis   Helps to troubleshoot master data and analysis issues   Produces reports and analyses on demand   1 to 2 years of progressive work experience in information governance, Data governance, or records management experience   Intermediate knowledge of Microsoft Excel 2010 or higher   Great attention to detail   Is comfortable communicating with new people on a regular basis   Good command of English (both oral and written) and customer services skills   Basic understanding of databases   Possesses a university degree (preferably in accounting, finance or business)   Previous work with Confluence and JIRA would be an asset   Medium-level competency at writing SQL queries (nice to have)"
Senior Data Scientist,YouVisit,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-youvisit-1552661812?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=4&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Conduct advanced exploratory data analysis on large datasets across multiple data sources.    Develop and test hypotheses and provide insights based on the results of statistical analyses.   Determine the best algorithms to apply to the data, including machine learning tools as appropriate.   Work in teams to develop machine learning models that support and enhance our products by adopting best practices in processes and techniques for statistical modeling.   Prototype and build new machine learning pipelines that train the models.   Build tools and metrics to monitor and analyze model performance and data accuracy.   Collaborate with other Data Scientists as well as the Product and Engineering teams to deliver data products and incorporate your models/pipelines/architectures into new deployed products.   Effectively communicate model results and limitation considerations to internal stakeholders.   Provide mentorship and guidance to our junior Data Analysts/Businesses Intelligence Engineers and Data Scientists in the Data & Analytics team.   A Master's or Ph.D. degree in Computer Science, Math, Statistics, Physical Sciences, Engineering or other related quantitative fields.   5+ years of industrial experience in related roles, solving complex problems including machine learning applications.   5+ years of experience performing advanced data analysis using SQL, Python (numpy, scipy, pandas, scikit-learn, tensorflow/keras/pytorch, etc.), R or other equivalent languages.   Strong background in SQL, relational data modeling, and data architecture.   Experience working with Spark, Hive, Hadoop, Elasticsearch, Kinesis, Kafka.   Ability to write production-quality code applying knowledge of data structures and algorithms with Python or related programming languages.   Understanding of common software development practices around design, coding, and testing of large codebases.   Background in NLP/NLU.   Background in Info Retrieval.   Previous experience building production-ready recommender systems.   Experience with marketing technology products (interactive web content, web browsing tracking, etc…) and related metrics and analytics.   Experience in a SaaS-based growth-stage company.   Experience in the MarTech, AdTech, or EdTech space.   Located near Penn Station surrounded by great food, entertainment, shopping, multiple transportation points, and much more!   Open floor plan for ease of communication and increased visibility   Fully stocked office with snacks and flexible workspace   Bi-weekly catered lunches with the entire office   Cutting edge technology to work on   Career development and training   Competitive salary and incentives   Comprehensive health, dental, and vision coverage   401K   Generous vacation, paid holidays, unlimited sick days"
"Data Scientist I, Machine Learning Model Validation",TD,https://ca.linkedin.com/jobs/view/data-scientist-i-machine-learning-model-validation-at-td-1548138677?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=5&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Validate Machine Learning models and AI applications.   Develop/implement Machine Learning model validation methodologies and standards. Ensure that the validation methodologies and standards are in line with industry best practice or address regulatory and audit requirements and/or findings in a timely manner.   Develop and apply a variety of statistical tests and modeling techniques to identify/recommend improvements to models and undertake related initiatives. Ensure extensive testing of model sensitivity that help assessing model behavior and risk.   Implement and evaluate external models used for benchmarking internal model performance. Participate in model selection and related due diligence activity.   Actively participate with business partners in internal data management to ensure data integrity and the completeness of data capture for model validation and development purpose.   Maintain full professional knowledge of techniques and developments in the field of Machine Learning and share knowledge with business partners and senior management.   The position involves working effectively with different internal partners such as TD Wealth, TD Insurance, ED&A, PBSA, Layer6 and etc   Strong quantitative skills with an advanced degree in one or more of the following areas: computer science, mathematics, physics, statistics, machine learning, economics, engineering, and/or actuarial science.   Up to 3 years' experience of working in analytical environments.   Experience with and strong knowledge of Machine Learning theory and predictive algorithms:  Neural Networks/Deep Learning, NLP, Bagging and Gradient Boosting methods, Generalized Additive Models, Graphical Models, Bayesian/probabilistic methods and etc.   Experience or knowledge of Machine Learning Model Interpretation/Explanation, as well as Bias/Fairness assessment, tools and algorithms.   Experience with Big Data analytics tools and environments, such as, Hadoop/Hive, Spark, and H2O.   Ability to research and implement Machine Learning algorithms from academic research papers is a plus.   Obje ct Oriented and Functional programming skills.   Proficient in one or more programming languages such as Java, Scala, Python and/or R.   Knowledge of neural network tools such as Tensorflow/Keras, MXNet and/or PyTorch.   Excellent verbal and written communication skills.   Quick learner who constantly works on improving their skills and expertise.   Good time management and multitasking skills with minimal supervision"
Senior Data Analyst,ADP,https://ca.linkedin.com/jobs/view/senior-data-analyst-at-adp-1569264685?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=6&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Developing data models to capture and report on KPIs   Building dashboards and tools to support our internal teams   Exploring our data to uncover meaningful insights that help drive company growth   Contextualizing data for a variety of audiences, internally and externally   Providing coaching and mentorship to less experienced colleagues   5+ years of experience as a Data Analyst   Experience with BI tools (Looker, Tableau, et al)   Demonstrated interest in exploring data and extracting valuable insights   Proven analytical, problem-solving, and troubleshooting expertise   Proficiency in SQL, preferably across a number of dialects (we commonly write MySQL, PostgreSQL, and Redshift)   Ability to learn and assimilate technical information quickly   Experience with version control and shell commands (git, github, SSH, *nix, etc.)   Python for Data Analysis (pandas, scikit-learn, etc.)   Database/query performance optimization   Comfort with the AWS ecosystem (EC2, S3, RDS, Redshift, et al)   Experience with data warehousing (Stars and Snowflakes!)   Knowledge of SaaS-based business   Enterprise-grade data and systems knowledge   Tolerance for the occasional data cleansing"
Senior Data Scientist,Manulife,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-manulife-1550088437?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=7&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Takes a leading role in the model validation in Group Advanced Analytics by developing the model validation and risk management framework   Reviews documentation, meets with the business, model owner to ensure understanding of the business problem   Assesses the data for model development, checks assumptions, inputs to the model and does in-depth analysis to identify potential issues,   Independently develops benchmark model to assess whether submitted model behaviour is consistent with the documented specifications and intended use   Compares validation results with model developer results for replicability.   Ensure the transparency and interpretability of the models by keeping current with new research and methodologies that can explain black box models   Ensure that proper and adequate model documentation (using model inventory template) and model risk mitigation processes are in place in order to appropriately assess and mitigate model risk.   Keeps informed of current practices and research in statistical and machine learning modelling techniques and risk management by reading academic literature, attending academic and practitioner workshops and conferences.   Provides technical advice and guidance to assigned business/group on implementation of the model validation framework, and resolution of model risk issues.   Develops and maintains in-depth knowledge of business and related model validation/risk management requirements and regulatory guidelines   Builds effective relationships with internal/external partners.   Ensures that business units understand that the model submission process involves preparing adequate model documentation to enable an appropriate model review   Participate in ad-hoc projects   Implement measurement & documentation framework against all project work   Generate insights in such a way that the businesses can clearly understand the quantifiable value. Enable the business to make clear trade-offs between and among choices, with a reasonable view into the most likely outcomes of each.   Turn statistical and computational analysis into user-friendly graphs, charts, and animation. Enable those who aren’t professional data analysts to effectively interpret data. Ability to communicate results and educate others through reports and presentations   Provide thought leadership around analytics methodology, tools, and measurement   Advanced degree in Statistics, Math, Comp Sci, Engineering or other related discipline (post-grad preferred)   Minimum of 5 years' experience specifically in building statistical/ machine learning models, data analysis and data mining   Experience with model risk management practices, model life cycle.   In-depth knowledge & experience with risk policy frameworks; quality control / testing frameworks.   Experience with Natural Language Processing, unstructured data, use of APIs   Proficient in either Python, R, SAS, SQL with working knowledge of the others   Demonstrated data transformation & manipulation experience   Track record of delivering innovative analytical insights to lines of businesses   Model validation experience is preferred   Experience with Big Data platforms   Experience with Gitlab   Strong commitment to organizational success and team work   Adaptable and open to change with strong collaboration and communication skills   Insurance/Financial Services experience desired   Inspires and motivates others.   Role model of ethics and integrity who builds a culture of respect.   Highly effective change agent who embraces change and leads change management.   Provides courageous advice.   Results oriented; highly focused on accountability.   Ability to handle multiple partners   Demonstrates a commitment to delivering excellent service balanced with appropriate risk management.   Strategic perspective.   Highly collaborative working style."
Senior Data Scientist,Thomson Reuters,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-thomson-reuters-1549897921?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=8&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Interact with business stakeholders to understand their challenges, develop hypotheses and prototype solutions to real world problems using innovative image recognition and machine learning techniques.   Design, implement and validate developed algorithms.   Applicant should be able to quickly spot errors, remove obstacles, and provide guidance when research progress slows.   Demonstrating successful mentorship of junior team members and delegation of tasks to other team members to further plan execution, as appropriate.   Collaborate with engineering and technology teams to move your solutions into production.   PhD or Masters in a data-heavy technical field, such as Computer Vision, Computer Science, Engineering, Statistics, Mathematics, or other data-heavy discipline such as Physics or Chemistry or quantitative social science.   3+ years of relevant experience in building machine learning models and/or systems.   Proficient programming skills in a high-level language (e.g. Java, Scala, Python, C/C++, Perl, Matlab, R).   Project-based experience with some of the following tools: Traditional image processing and learning (e.g. SIFT, SURF, Bag-of-features, Fisher Vector etc.) Expertise in at least one area of visual image enhancement, semantic understanding and reasoning of images (e.g., intelligent scene recognition, saliency detection, image semantic, color balance, image super-resolution and denoising, OCR, image search and image captioning, etc.)  Supervised and unsupervised machine learning (e.g. libSVM, Shogun, Scikit-learn or similar) and deep learning Statistical data analysis and experimental design (e.g., using R, Matlab, iPython, etc.) Information retrieval and search engines, e.g. Solr/Lucene Distributed computing platforms, such as Hadoop (Hive, HBase, Pig), Spark, GraphLab Databases (traditional and noSQL).   Ability to translate the latest technical papers into implementations addressing our use cases.   Experience with statistical data analysis, experimental design, and hypotheses validation.   Must be a self-motivated, lifelong learner, who is passionate about turning new ideas into solutions for clients.   Excellent oral and written communication skills."
Data Analyst,Levio,https://ca.linkedin.com/jobs/view/data-analyst-at-levio-1565082233?refId=388d1b09-bfa1-4728-a8a6-6f750bdf7056&position=9&pageNum=3&trk=guest_job_search_job-result-card_result-card_full-click,"Concrete commitment to deliver the expected benefits    Succeed as a team, through work, leadership and adaptability    The highest degree of rigor in planning, monitoring and execution    Sense of responsibility    Pride and enthusiasm for our customers' success   Work with our clients in the Insurance and Finance industry to modernize their core systems and ensure compliance with regulations;   Analyze and interpret large data sets compiled from different sources within the organization;   Analyze, develop and implement data mining compliance components;   Assist in the modeling development of various data models;   Provide ad-hoc data analysis for various stakeholders;   Work in close collaboration with actuarial and compliance team to rapidly identify problems, proposes and implement innovative and efficient solutions;   Keep up on industry trends, best practices and technology;   Contribute to various stages of testing and documentation.   Degree in Computer Science, Software Engineering, Statistics, Data Science or other relevant field   Minimum of 3 years of experience working as a data analyst   Experience in Insurance or banking industry - required   Knowledge with Analytical platforms such as: SAS/Base, SAS/Enterprise Guide, SAS/Enterprise Miner, Oracle SQL, especially in exploratory analysis, analytical studies, data quality, and data mining   Experience with data migration & ETL tools and methodology   Experience working with complex data sets and/or large projects   Ability to clearly and confidently communicate results/conclusions to partners   Customer-oriented, strong propensity for teamwork   Strong English communication skills   Experience in compliance projects such as Bale 2 or solvency 2 is an asset   Experience in consultation is an asset"
"Associate/Senior Associate - Data Scientist, Investment Analytics and Insights",CPP Investment Board,https://ca.linkedin.com/jobs/view/associate-senior-associate-data-scientist-investment-analytics-and-insights-at-cpp-investment-board-1485222430?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=1&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Diverse and inspiring colleagues and approachable leaders   Stimulating work in a fast-paced, intellectually challenging environment   Accelerated exposure and responsibility   Global career development opportunities   Being motivated every day by CPPIB’s important social purpose and unshakable principles   A deeply rooted culture of Integrity, Partnership and High Performance   Blend alternative sources of data with discretionary investment research to generate important and actionable investment ideas   Work in a fast-paced environment, collocated with data engineers, data scientists and portfolio managers.   Leverage cutting edge technology and data to make the most informed investment decisions by building deeply proprietary research methodologies.   Define and shape CPPIB’s future research process.   Advanced university degree in Engineering/Computer Science/Mathematics/Statistics or other quantitative field preferred.   Experience with private equity due diligence process is required.   Deep experience working with both structured and unstructured big data including data exploration/analysis.   Deep proficiency with one or more programming languages and statistical packages such as Python, R, pandas, pyspark, SQL.   Very familiar working with time-series and panel data and performing manipulations.   Familiarity working with ETL pipelines.   Experience using cloud providers and associated services – AWS/GCP/etc.   Familiarity working with data lakes using S3/Redshift.   Exposure to big data workflows and analytics tools (Spark/Databricks/Cassandra).   Familiar with one or more analytic tools such as Tableau, Looker and creating clear and effective visual displays of data.   Knowledge of and interest in discretionary investment research.   Interest in predictive analytics / machine learning.   Creative and logical thinking.   Ability to work in an entrepreneurial environment and be a self-starter."
SAP Data Analyst,Talencity,https://ca.linkedin.com/jobs/view/sap-data-analyst-at-talencity-1585601343?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=2&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,1-3 years experience with data cleaning and migration    Experience with SAP implementation and operating environments    Experience with SAP S/4HANA or ECC    Exposure and understanding of SAP ETL practices    Degree and/or diploma in Computer Science/Software Engineering or equivalent    Opportunity to be part of a great team   
Data Analyst and Report Specialist,Heliolytics,https://ca.linkedin.com/jobs/view/data-analyst-and-report-specialist-at-heliolytics-1585807386?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=3&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Onboarding client assets into our internal systems and digitizing them   Analyzing collected field imagery and resulting anomaly distribution, suggesting potential issues and remediation for client assets   Identifying trends across client portfolios and ensuring that these are communicated through our reports   Reviewing data with our technical experts and writing client reports   Creating other client deliverables using specialized software tools   Tasks related to our analysis workflow, such as database management, troubleshooting and statistical analysis   PV system components, layouts, and maintenance   The development process of new software tools, and the creation of efficiencies for analysis processes   Processing and presenting spatial datasets   The North American and global renewable energy industries   A proven ability to derive data insights - experience with data analysis, data science, statistical analysis, or handling large datasets.   Experience with technical, academic, or professional writing.   Experience with project management or project coordination, or experience working on projects with tight timelines, multiple stakeholders, or other complexities.   To be detail oriented. We pride ourselves on the quality of our deliverables, and you will be responsible for ensuring that our products are the highest quality.   Technologically proficiency, with a clear ability to learn and adapt to new software and technologies, and have advanced experience with broadly-used software packages (Adobe suite, Excel, Google suite, etc).   Enthusiasm and an innovation mindset. We’re a small team - If a rapidly evolving job description appeals to you, and you’re keen to do your best at a variety of tasks, this might be a good fit.    Familiarity with programming or software design (the majority of coding at Heliolytics is done using python. Additional proficiency in R or SQL would be an asset)   Experience in the solar or renewable energy industries   Imagery interpretation experience (satellite-based imagery analysis, or air photo interpretation)   Experience with or knowledge of scientific classification schemes   Experience with GIS software or packages or geospatial analysis (note: this is not a GIS technician position)"
Senior Data Scientist,Jobspring Partners,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-jobspring-partners-1563303169?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=4&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"3+ years of professional experience as a Data Scientist   Experience leading a project in the past   Being exposed to multiple solutions in both Python and R.   Machine learning tools such as TensorFlow   Great communication   Strong in mathematics and algorithms   Import and analyze data   Meeting business requirements   70% Hands on   30% Team leadership and collaboration   Competitive Salary: Up to $130,000, DOE   3 weeks’ vacation   Benefits package   Bonus structure"
Energy Data Analyst,Energy Profiles Limited,https://ca.linkedin.com/jobs/view/energy-data-analyst-at-energy-profiles-limited-1503335708?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=5&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click," Create and/or verify annual energy consumption and cost models/forecasts for large commercial buildings, factoring in historical usage, projected utility rates, and weather patterns.    Perform utility rate research and compile utility rate assumptions across Canadian and US energy markets.    Monitor and maintain utility consumption models that directly impact forecast/budget activities.    Identify ways to optimize data acquisition, modelling and analysis processes and tools.    Assist in preparing GHG emissions reports for our clients using recognized industry protocols.   Unlimited Vacation & Flexible Work Hours (truly own your time)   Insured Benefits and Health Spending Account   Paid monthly transit pass"
sr. data scientist,Randstad Canada,https://ca.linkedin.com/jobs/view/sr-data-scientist-at-randstad-canada-1552315615?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=6&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,
Senior Data Scientist,eFinancialCareers,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-efinancialcareers-1546327375?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=7&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Use case identification:   Expand on the currently identified use cases by partnering with the existing model development groups and the business partners and identify other types of models/applications where ML and AI can add value. This will cover areas such as credit risk, economic capital, AML and market risk.   Structure above identified use cases, define operating model, manage delivery and provide  Data collection and manipulation Collect data for model development purposes by identifying new candidate variables and predictive variables. Analyze and summarize data to identify outliers and assess data quality. Perform data imputation using advanced statistical techniques (multiple imputation, machine learning estimations). Transform and prepare the data for developing AI models.  Predictive models development Fully understand the existing version of the models where applicable, their limitations and all the underlying assumptions made. Use the prepared data to build machine learning predictive models using advanced regression techniques such as random forests, neural networks, boosted trees, deep learning, logistic regressions, NLP etc... Rank and compare the candidate models to select the best fitting models. Use statistical tests to ensure the stability and robustness of the candidate models. Identify new opportunities to apply machine learning in the current model development process.  Reasonableness assessment Ensure that the models developed make business and intuitive sense by participating in sessions with the model owners, lines of businesses and including their feedback in the model. Design a process to explain the output of the models on a consistent basis to understand why the models are producing these decisions.  Documentation Document the process along the way by capturing the details around all assumptions made. Keep record and detailed notes about the thought process. The models developed will serve as a proof of concept for future ML & AI models in credit risk. Qualifications Skills required: Master or PhD candidate in Engineering, Statistics, Mathematics, Computer Science or related quantitative field. 5-10 years of experience in AML, risk management and machine learning and AI techniques Familiarity with risk management processes and methodologies, ideally AML Familiarity with Bank credit instruments and product structures Familiarity with systems management and data architecture principles Experience with statistical model development and data mining Proven experience using SAS, R or Python to build machine learning models Strong theoretical knowledge of machine learning techniques and advanced regression methods and data imputation techniques Well-developed relationship management skills. Excellent influencing and negotiation skills Strong problem solving skills and capacity to turnaround analysis in short period of time Comfortable in a challenging environment with tight timelines Excellent written and verbal communication skills Capacity to cope with a high degree of ambiguity and change Ability to work both independently and as part of cross-functional teams Prior industry experience or academic projects with machine learning and advanced programming is preferred. High-level of competency with MS Office suite of tools We're here to help At BMO we have a shared purpose; we put the customer at the centre of everything we do - helping people is in our DNA. For 200 years we have thought about the future-the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we're changing the way people think about a bank. As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset. To find out more visit us at https://bmocareers.com . BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter."
Senior Data Scientist,Michael Page,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-michael-page-1471112648?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=8&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Are you interested in artificial intelligence?   Are you interested in working closely with customers?    Work closely with clients to understand needs and how to implement solutions- Work collaboratively with Machine Learning and Client Solutions teams - Ingest, transform and map data    7+ years of experience working in Data Science- 4+ years working with Hive - 7+ years working with Hadoop - 10+ years working with AWS"
Senior-Data-Analyst,Community Living Toronto,https://ca.linkedin.com/jobs/view/senior-data-analyst-at-community-living-toronto-1493905051?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=9&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click," Works in partnership with stakeholders to define/analyze business requirements and provide data/information solutions and support, including but not limited to: o Data collection, extraction, integration, and mining o Analytics and reporting o Data visualization o Decision support o Data quality improvement    Leads and/or participates in developing performance metrics and KPIs to support key strategic priorities.    Queries data, performs analysis, and uses clear and innovative visualizations to develop reports, dashboards, and scorecards for informed decision making and business performance initiatives.    Delivers findings and recommends actionable insights to leadership team and program areas to drive business intelligence.    Develops, improves and maintains departmental processes and documentation.    Supports the development and maintenance of databases and applications."
Big Data Developer,Ingram Micro Cloud,https://ca.linkedin.com/jobs/view/big-data-developer-at-ingram-micro-cloud-1459431118?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=10&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Working on designing and maintaining/mining large data stores   Working with the latest cloud technologies like Azure, AWS, etc.   Develop, support, maintain and extend ETL processes, database modeling/tuning/validation, Business Intelligence and Data Warehouse services   Working in a an Agile environment   Support the continuous improvement and evolution of the Reporting / BW business policies   Diagnose and support the resolution of Reporting / BI system defects identified by users   Provide training and expert knowledge regarding the Reporting / BI business process and standard operating procedures to business users   Experienced on RDBMS -architecting/designing/implementing/maintaining large data warehouses   Expert on SQL - querying and integrating new data sources   Expert on ETL - processes and data modeling   Experience working with distributed big data processing algorithms   Experience with cloud data platforms - E.g. Azure SQL, Power BI   Strong understanding of financial analysis and reporting   Ability to become a subject matter expert on the Ingram Micro Cloud business processes and systems   Hands-on experience with SQL Server with working knowledge of Views, Stored Procedures, Jobs and SQL Scripting   Ability to take responsibility, meet deadlines and work under pressure with multiple task"
Data Analyst – Data and Knowledge Management,Heart & Stroke,https://ca.linkedin.com/jobs/view/data-analyst-%E2%80%93-data-and-knowledge-management-at-heart-stroke-1490572495?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=11&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Data cleaning, validation, and analysis    Programming in SAS or R for data analysis runs, including some modelling and forecasting.   Performs analysis of Canadian Institute of Health Information (CIHI) datasets, survey data, data from polling companies, and other population or heart and stroke-related data.   Documents and validates raw data, analyzed data and program(s) used for data analysis.   Generates summary reports, graphs and flat excel files based on project needs to support evidence-guided decisions and knowledge products.   Creates interactive visualizations in Power BI where appropriate.   Creates and develops proper documentation for data storage, analysis, methodologies and analysis outcomes.   Understanding and executing data analysis plans   You work independently to accomplish tasks and goals defined primarily by Senior Manager, Data and Knowledge Management, with additional guidance from Director, Data and Knowledge Management as appropriate.   Controlling and monitoring of data and knowledge quality   Ensuring consistent data quality, and executing appropriate corrective actions if errors are identified.   Ensuring accuracy and appropriate use of statistical methodologies, coordinating data analysis project and generating activities and metrics for review.   Following data quality standards, policies and procedures to ensure compliance.   Supporting the Mission Department's data quality assurance efforts to identify and correct errors, and to articulate limitations in the data.   Capacity Building within the Foundation Maintaining awareness of CIHI and broader health sector data issues and standards. Communicating within the Foundation the importance of maintaining data quality and standards (as appropriate) and supporting their application internally. Working collaboratively with internal and external partners to ensure wherever possible, data are used, interpreted and presented accurately.   The education. You have a degree in statistics, biostatistics and/or similar. Master's an asset.    The experience. You have 3-5 years' experience in statistical analysis in a health setting, such as public health and health planning organization.   The technical skills. You have strong computer skills and ability to use technological tools to organize and advance the work of the team, such as MS Office Suite, SharePoint, BigQuery, JIRA, and other workflow tools. You also have some proficiency with SAS and/or R.   The analytical skills. You have solid attention to detail and the ability to apply good judgement and demonstrate initiative to resolve and communicate issues. You also have strong skills in evaluating quantitative health data and utilizing analytic approaches for clustering, stratification and weighting of large data set, as well as mathematical modelling and forecasting.   The communication skills. You have outstanding written and verbal communication skills needed to work collaboratively and effectively in a team environment.    The ownership. You are attentive to detail, diplomatic, and can think flexibly to find solutions for automating workflows and storing and manipulating data   The adaptability. You are comfortable working in a fast-paced, ever-changing environment. You can effectively manage a demanding schedule and prioritize responsibilities"
Data Analyst - Market Insights - Open Application,Verto Analytics,https://ca.linkedin.com/jobs/view/data-analyst-market-insights-open-application-at-verto-analytics-1457656502?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=12&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Participate in projects with client-facing exposure, working with the largest media and tech companies   Perform hands-on analysis of our data to create and deliver customized insights and reports   Present the research outcomes and recommendations to business decision-makers   Specify and develop new data products and product features for our analytical platform, together with our analysts and engineers   Collaborate internally with Sales, Account Management, Data Science and Product Management teams to assure that we find the best possible solutions to address customer needs   Experience in a client-facing analyst position at a publisher, advertiser, market research strategy/consulting firm or advertising agency   Experience producing high-quality presentations and reports (slide decks, spreadsheets) for audiences with high expectations   Exploratory data analysis and storytelling skills using Excel/SQL to dive into data and search for patterns and new insights   Customer-oriented, creative mindset: ability to understand and anticipate customers’ key business questions, and to address these with insightful data analyses and visualizations   SQL skills or willingness to quickly learn   Experience working with survey data using SPSS or other analysis tools to surface insights   Data Visualization skills using Tableau or other BI tools Please note that Verto does not sponsor employment work visas in North America."
Business Data Analyst,Breakthru Beverage Group,https://ca.linkedin.com/jobs/view/business-data-analyst-at-breakthru-beverage-group-1604129430?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=13&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click," Understand National and Provincial strategies and objectives     Provide fact-based, analytic support to the Senior Director of Business Analytics and to the sales teams as needed     Facilitate the production of actionable channel and brand information     Delivery on monthly performance analysis identifying specific regions/brand/channel issues opportunities to be actioned     Produce pre and post analysis on trade promotions with recommendations to trade development     Delivery of actionable market intelligence to trade development team .     Assist in developing key initiative metrics and target accounts     Provide channel performance assessment and appropriate tracking documents for key initiatives as required.     Prepare market update for key accounts, quarterly     Lead special projects as needed     Manage and maintain the Breakthru Customer SAP database for Spear and Mobility tools     Prepare weekly and monthly reports for the Consignment Wines division     Assist with the development of monthly and quarterly sales meeting content as needed     Live and demonstrate the Company Values     Demonstrate and exhibit high levels of professionalism with internal and external customers     Bachelor’s Degree in business or finance     2 years’ experience in sales or marketing in CPG company or Beverage Alcohol company     Proficiency in MS Office with advance Excels skills in Pivot Tables, Vlookups, Sumifs, Countifs required.     Sound knowledge of business planning and/or market research processes.     Knowledge of brand activation best practices     Strong analytical and business planning skills     Good Multi-tasking and organizational skills     Good communication and presentation skills     Basic trade development knowledge (supplier, sales, customer, brand)     Develop complete understanding of the sales tools including SAP, Spear, TIPS, LCBO Microstrategy, LCBO Elite system, etc.     Nielsen experience as asset     Beverage alcohol experience an asset     Physical demands in operating computer and telephone equipment.     Occasional carrying, reaching and lifting to perform various duties as assigned     Occasional standing, walking for short amounts of time to perform various duties     Extended sitting for long periods of time at desk or workstation"
"Google Cloud Big Data Engineer, Cloud Engineering",Deloitte Canada,https://ca.linkedin.com/jobs/view/google-cloud-big-data-engineer-cloud-engineering-at-deloitte-canada-1541340513?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=14&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"A bachelor's degree in a Technical or Engineering field or equivalent practical experience. Master's degree in a technical or engineering field is an asset.   Minimum 2-4 years of experience designing and deploying distributed data processing systems with one or more technologies (MySQL, Oracle, Cassandra, HBase, Redis, MongoDB, Hadoop, Spark, fluentd, etc.). Hands on experience with Google Cloud Dataflow and Google BigQuery is a must.   GCP Professional Data Architect certification or working towards it   A deep software development experience in one or more programming languages (Java, C/C++, C#, Objective C, Python, JavaScript) along with some scripting skills in Python, Perl, Shell or another common programming language   Experience in systems design, with the ability to architect or explain complex systems interactions including data flows, common interfaces, APIs and methods available, Data Processing Pipelines: ETL pipelines using JAVA or Scala, architecting, developing and/or maintaining production-grade cloud solutions in virtualized environments     You will lead at every level:  We grow the world’s best leaders so you can achieve the impact you seek, faster.     You can work your way:  We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.     You will feel included and inspired:  We create a deep sense of belonging where you can bring your whole self to work."
Business Intelligence Engineer - Data Science,Localcoin,https://ca.linkedin.com/jobs/view/business-intelligence-engineer-data-science-at-localcoin-1509132641?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=15&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Utilize existing research and data, while proactively integrating new sources of data and information to ensure the most impactful and relevant insights are brought to life for our teams through interactive dashboards   Collaborate with the Director of IT to build a centralized database used to aggregate company-wide data and drive automated solutions across all departments    Conduct competitive analysis to determine the strategic position of the company and identify growth opportunities    Develop sales forecasts using various methods, enabling our sales team to make informed business decisions and predict short and long-term performance   Lead the development and execution of consumer research, both primary and secondary, for new product launches and ongoing maintenance to assist with marketing and sales optimization initiatives   Partner with cross-functional leaders to understand learning objectives that will inform both quantitative and qualitative research development, deployment, and analysis to drive actionable recommendations and thoughtful decisions about the future of our company   Set the direction for research priorities based on what will bring the best products to market for our current and future customers, informing concept ideation and validation through sample testing and monitoring pre and post-launch success    Work with our Finance and Communications teams on developing communication materials for investors and other external stakeholders   Collaborate with the Director of Operations to identify pain points in cash cycle process (cash processing, pickup) monitoring lead times, optimizing inefficiencies. Reducing working capital requirements on machines.   5-8 years relevant work experience in highly strategic and analytical roles with proven ability to transform insights into action   Quantitative and qualitative research experience with range of methodologies and tools is a must, and the candidate should be comfortable with presenting findings to key stakeholders including Co-Founders   Curious problem solver that is focused on developing clear research plans that identify the best methods for delivering actionable, results-driven decisions   Detail-oriented mindset with strong project management, process, and organizational skills; can prioritize effectively to manage multiple projects, and varied timelines   Collaborative working style with ability to build strong cross-functional relationships and influence decision-making through both written and verbal communication   You have advanced knowledge working with SQL, Data Studio, Tableau, Microsoft excel, Google big query and analytics / presentation tools, pulling data from API resources as well as familiarity with JIRA   You have experience with technologies such as Python, or R, as well as familiarity with conventional code and programming concepts   Hard working with a ""no task is too small"" attitude   Enjoy working in a fast-paced and ever-changing environment"
Aircraft Maintenance Data Analyst,De Havilland Aircraft of Canada Limited,https://ca.linkedin.com/jobs/view/aircraft-maintenance-data-analyst-at-de-havilland-aircraft-of-canada-limited-1571732657?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=16&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Competitive salary   Full extended health and benefit plan   The opportunity to join an organization from the ground floor   Great task diversity and unique challenges   Work closely with originators of queries (De Havilland-internal and external customers) to ensure all necessary data are obtained in order to meet customer's expectations with regards to timeline and quality.    Work independently and with Maintenance Programs and Procedures team members to support them and align in all Maintenance Engineering queries, reports, projects and assignments    Provide qualitative and timely reliability and cost data and analyses to key supporting functions in Customer Services and Support, Sales & Marketing, Procurement, Engineering and other De Havilland teams   Analyze all maintenance cost data (repair station, heavy/line maintenance, non-routine, labour, etc), for trends, inconsistencies, and problem areas and initiate potential improvements.   Maintain, update, expand and develop analytical tools and models.   You have a University Degree in Engineering, Mathematics or Engineering Physics with at least 3 years' experience in Industrial or Aerospace or College Diploma in Aviation Technology with at least 5 years' experience in Aerospace Industry.    You have strong analytical abilities and experience using statistics to resolve engineering problems    You have robust understanding of reliability and aircraft direct maintenance costs. Aircraft maintenance programs and planning concepts, methods and management is a definite asset    You have good knowledge of aircraft systems. Familiarity with with De Havilland aircraft Dash 8 Series 100, 200, 300 and 400 is a definite asset.    You are familiar and proficient with Microsoft Software products - especially Excel and Access. Familiarity with Oracle database is a definite asset"
Big Data Engineer (Spark/Python),Collective[i],https://ca.linkedin.com/jobs/view/big-data-engineer-spark-python-at-collective-i-1603557073?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=17&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Working closely with the data-science team to create and enhance software that enables state of the art data processing, data analysis and machine learning   Developing and deploying data pipelines and machine learning pipelines using tools like Airflow, Spark, SparkML   Performing unit tests and conducting reviews with other team members to make sure the code is rigorously designed, elegantly coded, and effectively tuned for performance   Diagnosing, troubleshooting and resolving production issues   Team player with experience with working in distributed teams   4+ years of software development experience in a production environment   3+ years of experience building robust and scalable data processing pipelines using Python and Spark (PySpark)   2+ years of experience writing SQL and interacting with NoSQL databases (Mongo, Elastic Search)   2+ years of experience with the spark software stack and package distribution   Experience with Agile methodology, using test-driven development   Passion to learn quickly and work independently   Talent to write well designed, fully-documented, testable, efficient code   Understanding of Continuous Integration, Continuous Deployment and Test Automation to enable the rapid delivery of working code utilizing tools like Jenkins, Git, Gitflow   Good understanding of big data architecture, frameworks, and design patterns   Good communication sills   Working well with time-sensitive delivery deadlines   Comfortable with navigating through ambiguity   Team player mentality   Sense of pride and ownership for your quality of work   Sense of humor"
"Data Analyst – Consultant, Risk Analytics",KPMG Canada,https://ca.linkedin.com/jobs/view/data-analyst-%E2%80%93-consultant-risk-analytics-at-kpmg-canada-1556363843?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=18&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Work closely with clients in understanding key business issues.   Gather and analyze requirements to develop impactful recommendations and solutions.   Utilize advanced analytical technics to solve challenging business problems. Leverage a diverse set of technologies and tools to deliver insights.   Develop a strong experience in analytics, statistics, data mining, reporting, visualization and/or intelligent automation.    Develop problem solving ability through the use and/or development of algorithms, models, testing, etc.   Work with large volumes of data (structured and unstructured).    Run queries for descriptive analytics and provide formatted result sets.   Proactively contribute to the creation of presentation materials relating to data activities for stakeholder discussions.    Bridge the gap between technical platform needs and business issues.    Perform quantitative analysis of data issues.   Effectively communicate orally and written with peers within Internal Audit, Risk and Compliance Services (IARCS), KPMG and the client.   Learn more about Risk Consulting here   Learn more about our Toronto office here   Work closely with clients and partners on digital opportunities.   Perform In-depth data analysis to identify areas of risk, opportunities and recommend solutions for our clients.   Work with unique data analytic programs to deliver innovative solutions to our clients.   Work in multi-disciplinary and cross-functional teams to translate business objectives into artificial intelligence approaches and objectives; strong aptitude for quickly learning business operational, process, delivery, and revenue models.    Work in a fast-paced and dynamic environment with both virtual and face-to-face interactions; utilize structured approaches to solving problems, managing risks, and documenting assumptions; communicate results and educate others through insightful visualizations, reports, and presentations.    Build ingestion processes to prepare, extract, and enrich a variety of structured and unstructured data sources.   Utilize a hypothesis-driven, problem-solving approach to design, construct, and rapidly test/iterate exploratory models that will reveal insight and opportunities for the client; proactively broaden and deepen client relationships by working with varying levels of client team members.   Develop complex SQL queries to ask questions of large/complex datasets.    Strong experience of 2-3 years, working with data from a variety of databases.    Independent ability to review the data quality and data definitions, and perform data cleansing and data management tasks.   Strong knowledge and/or experience in the following SQL, BI tools (like Tableau and PowerBI), Python, R, ETL, Alteryx and RPA tools (like Blue Prism, Automation Anywhere and UIPath)    Experience working in a multi-disciplinary team to tack unstructured data processing problems across a diverse range of industries.   Certificate or degree in Computing or IT, with a focus on Business Systems Analysis, Business Intelligence, Data Analysis and Reporting, or similar, is an asset.   Ability to explain data and analytics concepts to non-technical team members.   Ability to apply data and analytics concepts to business problems.   Ability to understand and explain business value of data and analytics concepts   Strong relationship-building skills to interact with clients, colleagues, and the wider community.   Ability to provide crucial consultation, analysis, and recommendations on a broad range of projects in a deadline drive environment with ambiguity.   Effectively work as part of a project team, and communicate findings of analysis, key implications, and recommendations in written and verbal formats."
Data Analyst,College of Nurses of Ontario,https://ca.linkedin.com/jobs/view/data-analyst-at-college-of-nurses-of-ontario-1595668334?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=19&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Consult with teams at the College to define and/or refine analytics goals to support evidence-based decision making   Conduct analyses of the College’s data including determining the appropriate methodology and approach; designing the analysis plan; and preparing reports and presentations summarizing the results   Develop web-based applications using R packages or similar tools to support the release of College data   Respond to requests for College data from researchers and other stakeholders   Collaborate with the Information Systems team at the College on the ongoing development of the College’s data warehouse   Master’s Degree in a highly quantitative field (Mathematics, Statistics, Physics, Engineering) or related analytical fields (a Bachelor’s Degree would be considered with the appropriate practical and relevant work experience)   At least 3 years of experience performing data analysis and reporting including gathering requirements, analysing data and communicating results, both written and verbally, to technical and non-technical audiences   Extensive programming experience for data analysis (including extraction, validation, variable derivation and visualization), using any of R, Python, SPSS, SAS, Excel etc.   Must have strong SQL skills and general database knowledge   Must have strong attention to detail   Ability to work well independently   Ability to manage projects and priorities effectively in a dynamic environment   Aptitude and willingness to learn new technologies related to data science and analytics"
Big data Hadoop Developer,destinationoneTech,https://ca.linkedin.com/jobs/view/big-data-hadoop-developer-at-destinationonetech-1600289298?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=20&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Responsible for the development, design, and implementation of application systems.   Designs and codes programs, including the ability to test their coding, find errors, and correct codes to provide quality coding.   Interfaces with technical team to design and implement application systems.   Participate in all aspects of Big Data solution delivery life cycle including analysis, design, development, testing, production deployment, and support   Develop standardized practices for delivering new products and capabilities using Big Data technologies, including data acquisition, transformation, and analysis   Ensure Big Data practices integrate into overall data architectures and data management principles (e.g. data governance, data security, metadata, data quality)   Assist in the development of comprehensive and strategic business cases used at management and executive levels for funding and scoping decisions on Big Data solutions   Troubleshoot production issues within the Hadoop environment   Performance tuning of a Hadoop processes and applications   Proven experience as a Hadoop Developer/Analyst in Business Intelligence and Data management production support space is needed.   Bachelor of Computer Science, Management Information Systems, or Computer Information Systems is required.   Minimum of 2 years of building and coding applications using Hadoop components - HDFS, Kafka, Flume, Hbase, Hive, Sqoop.   Minimum of 2 years of coding Java, Scala / Spark, Python, Hadoop Streaming, HiveQL   Minimum 4 years’ experience of traditional ETL tools & Data Warehousing design.   Must be proficient in SQL/HiveQL   Strong personal leadership and collaborative skills, combined with comprehensive, practical experience and knowledge in end-to-end delivery of Big Data solutions.   Hands on expertise in Linux/Unix and scripting skills are required."
Consultant- Big Data Developer,Project X Ltd.,https://ca.linkedin.com/jobs/view/consultant-big-data-developer-at-project-x-ltd-1529458555?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=21&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Design and implement technical enhancements of Data Warehouse, Business Intelligence, or Big Data solutions as require   Utilize SQL, shell scripts and other external programming languages to complement and enhance the functionality the ETL tools provid   Apply automation and innovation on new and existing data platforms for those development projects aligned to the client's business or organizational strategie   Participate in the requirements gathering, analysis and solutions desig   Conduct unit & integration tests, assisting in test preparations to ensure data integrity, data quality, and program functional completeness & correctness   Create detailed technical documentation for ETL programs and other deliverable   Implement processes aligned to data management best practices (as defined or adopted by the client) and standards, ensure data quality and process performance within all system development deliverables   Develop a deep, multilayered understanding of the business issues and the Big Data challenges facing the client's organization and industr   Demonstrate collegial teamwork, by communicating clearly and completely with all project team members to identify, and resolve issue   Participate in the development of project plans to establish appropriate work load expectations and schedule   Own the responsibility to meet deadlines and strive to complete work in accordance with project plans    mplement processes aligned to data management best practices (as defined or adopted by the client) and standards, ensure data quality and process performance within all system development deliverables    3-5 years' experience on technical projects including two years as a Big Data Developer providing technical solutions through the use of Big Data tools    Detailed, practical working knowledge in Big data, data query/ingestion tools such as HBase, Hive, Pig, Sqoop, Flume, Spark, Kafka, Impala, Hadoop, Oozie   Experience in working on ETL tools such as Talend ETL, Informatica, Microsoft SSIS, SAP BODS, IBM DataStage, Oracle Data Integrator (ODI) or Ab Initio   Worked in Data Warehousing, including data mapping and transformations, data dependencies, data source analysis and profiling, OLTP, OLAP, SQL, and DBMS   Working knowledge in Relational SQL, MPP and/or NoSQL databases, including SQL Server, Oracle, Teradata, MongoDB, Post Gres, Snowflake   SQL Programming, creating complex queries, tables, view, and procedures   Working knowledge in Agile delivery methodology, DevOps, Continuous Integration/Continuous Deployment concepts and methods   Working knowledge of data modelling and data modelling concepts such as logical/physical modelling, 3rdNormal Form, Entity Relationship Diagrams, IDEF, & IE modelling syntax. Exposure to Erwin.   Testing automation and knowledge in Java, C#, Python or Scala is an asset   Above average skills in communication, solution-based approaches to solving problems, level-headed decision making, time management, collaborating with internal teams (Project X ltd.), external teams (non-Project X 3rdparties), and client team members   Demonstrated skills in leadership, integrity and working independently    Ability to recognize and highlight scope changes early and manage expectations on achievability   A Bachelor's degree, preferably in software or computer science/engineering fields Or related industry experience or acumen   Specialized and/or vendor certification or training in one or more of the Big Data technologies is an asset   Health and dental benefits package   Gym membership discount   Casual dress code and working environment   Holiday parties and BBQs   Getting together for team socials and sporting events"
Business Data Analyst,Sterling-Turner Corporation,https://ca.linkedin.com/jobs/view/business-data-analyst-at-sterling-turner-corporation-1493348863?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=22&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Ensure the successful maintenance, downloading & consolidation of accurate operational and campaign data for use in reporting and analysis   Execute on and provide timely distribution of Sponsored Markets operational & campaign reporting   Experience in developing and maintaining large databases with complex relationships between tables   Ability to stay organized under conditions of multiple tasks and tight deadlines with minimal supervision while ensuring accuracy, efficiency and quality of deliverables   Develop operational/analysis/reporting tools to support Sponsored Markets Leadership’s accurate and timely assessment of business efficiencies and practices   Participate in the technical design, development testing and creation of operational user documentation and processes   Responsible for understanding business processes in order to research, analyze, interpret and advise managers on findings of analysis   Perform calculations and develop forecasts to formulate responses/recommendations to specific queries from Client Services managers & project teams   Maintain data collection processes, report library and data dictionary for Sponsored Markets   Partner with Operations, Best Practices and other Sponsored Markets partners to ensure effective use of reporting   Ensure operational tools meet the requirements of partners and provide considered recommendations to management on direction of Sponsored Markets production and reporting toolset   Provide direction on intake of requests and perform tasks as assigned by the Manager, Sponsored Markets Analytics   Foster a work environment that values the people and encourages participation, creativity, learning and accountability   Strong analytical skills and financial acumen to perform analytical work with an eye for detail and accuracy   Customer and results focused, with an ability to work with customers to understand and act based on their needs, assess risks, and achieve a valued result   Comfortable with ambiguity and able to operate in a matrix environment with complex tasks   Experience managing and presenting large data sets   Proven problem solving skills with the ability to break down high-level data into easily communicated information   In-depth planning, organizational and time management skills   Comfortable learning new applications and processes quickly with minimal direction   Ability to quickly find alternate solutions to challenges   Proven client orientation, strong interpersonal skills   In-depth prioritization and change management skills to stay within time/scope of a task   Thrives in an environment where there is a need to quickly respond to and adapt plans to accommodate new and changing priorities   Undergraduate in Business or Computer Science (or equivalent university degree or college diploma)   Solid experience with SQL Server/ MySQL   Solid experience with statistical tools like MATLAB, Mathematica, Maple or R would be an asset   Financial services / product experience and knowledge"
"Research Scientist, Google AI",Google,https://ca.linkedin.com/jobs/view/research-scientist-google-ai-at-google-1554425811?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=23&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"PhD in Computer Science, related technical field, or equivalent practical experience.   Experience in Natural Language Understanding, Computer Vision, Machine Learning, Algorithmic Foundations of Optimization, Data Mining or Machine Intelligence (Artificial Intelligence).   Programming experience in one or more of the following: C, C++, Python.   Experience contributing to research communities and/or efforts, including publishing papers in machine learning venues (e.g: JMLR, ICLR, NeurIPS, ICML, ACL and CVPR).   Relevant work experience, including full time industry experience or as a researcher in a lab.   Developed publication record.   Ability to design and execute on research agenda.   Participate in cutting edge research in machine intelligence and machine learning applications.   Develop solutions for real world, large scale problems."
Big Data Consultant,Ataccama,https://ca.linkedin.com/jobs/view/big-data-consultant-at-ataccama-1545305881?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=24&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,"Analyze Hadoop/Spark ecosystems and find ways to benefit from integration with our products and solutions.   Work with our customers to find new opportunities where big data can help their businesses.   Prepare, manage, and deliver POCs from beginning to end using a wide array of technologies.   Provide feedback to product managers and developers. Explore new markets, look for business opportunities, and support marketing initiatives.   You can effectively and comfortably communicate with English-speaking teams located around the world.   You see challenges as opportunities. Why wait for a task list when you can start innovating right away?   You enjoy constantly learning new things and sharing your knowledge with others.   Programming experience   SQL and relational DB principles   Unix shell   Java   Apache Hadoop, Spark, NoSQL, XSLT   Parallel programming and distributed systems   Computer science, graph theory, automata theory    Experienced team to support your professional growth    Room to adjust and expand your role based on your individual skills and interests    Education (courses, conference tickets, etc.)    Various company events (parties, outings, barbecues, annual allstaff event and holiday party in Prague office, etc.)    Fitness benefits ($150 return for joining 1 year membership at a gym)    Perkopolis benefits (gym membership discounts, discounts on clothes, assortment of tickets & travels, etc.)    Manulife medical & health insurance benefits    Excellent office location in downtown Toronto    Excellent coffee and refreshments in the kitchen"
Data Analyst - Toronto,Ontario Institute for Cancer Research,https://ca.linkedin.com/jobs/view/data-analyst-toronto-at-ontario-institute-for-cancer-research-1600402105?refId=4c0f1ead-9aeb-4ae9-bb07-880e9dea9215&position=25&pageNum=4&trk=guest_job_search_job-result-card_result-card_full-click,
Telecom Cost & Data Analyst,Distributel,https://ca.linkedin.com/jobs/view/telecom-cost-data-analyst-at-distributel-1545433509?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=1&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Hold overall responsibility for all aspects of data management within the department. This includes financial data, numbering resources, circuit info, rate info, routing details, etc. This encompasses the identification, collection, sanitizing, storing and reporting of this data;   Responsible for auditing COS charges to validate dates, charges, and quantities;   Responsible for collecting, analyzing and reporting financial information and other information related to cost of sales;   Responsible for the overall management of supplier contracts, including tracking, reporting and renewal communication;   This role requires a flexible candidate who is able to work well in a collaborative environment with minimal supervision and who prides themselves on their attention to detail;   Excellent database, analytical and Excel skills are an absolute must for this position.   At least 5+ years of experience working with databases and data management;   3-5 years Financial and/or Accounting knowledge/experience in a Telecom environment;   3-5 years Telecom Expense Management, carrier billing methods and/or telecom infrastructure experience;   Certificate, diploma, or degree in Accounting or Business Administration or a related field considered an asset;   Expert level proficiency in using Excel and Access Databases.   Passion for being best in class in everything we do;   Comfort with the rapid change that continually challenges the status quo in order to continually improve;   Relentless curiosity, a drive to think outside the box, to do things better for our customers, colleagues and our business;   Superior analytical and problem-solving skills, with attention to detail;   Demonstrated ability to lead, develop and mentor;   Strong interpersonal skills for effective interaction with employees and third parties;   Strong organizational and time management skills;   Verbal and written communications skills in French and English is an asset   Solid decision-making skills and the ability to exercise professional judgment    We have insurance benefits;   We promote work-life balance;   We provide a great work environment with organized social events;   You’ll have opportunities for growth & development;   We provide a business-casual working environment;   We have great downtown locations and amazing people!"
Senior Data Scientist,Workbridge Associates,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-workbridge-associates-1266738476?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=2&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"5+ years of Data Science/Machine learning experience   Extensive experience with SQL   Expert with Python, Scala, R.   Familiar with Big Data technologies   A Computer Science Degree   Passion for problem solving   100% Development   50% Hands On   25% Management Duties   25% Team Collaboration   Competitive Salary: Up to $120k/year, DOE   Statutory Vacation   Benefits Package – Dental, Medical, Vision   Workbridge Toronto - OSD"
Data Analyst - Market Insights - Open Application,Verto Technologies,https://ca.linkedin.com/jobs/view/data-analyst-market-insights-open-application-at-verto-technologies-1345598951?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=3&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Participate in projects with client-facing exposure, working with the largest media and tech companies   Perform hands-on analysis of our data to create and deliver customized insights and reports   Present the research outcomes and recommendations to business decision-makers   Specify and develop new data products and product features for our analytical platform, together with our analysts and engineers   Collaborate internally with Sales, Account Management, Data Science and Product Management teams to assure that we find the best possible solutions to address customer needs   Experience in a client-facing analyst position at a publisher, advertiser, market research strategy/consulting firm or advertising agency   Experience producing high-quality presentations and reports (slide decks, spreadsheets) for audiences with high expectations   Exploratory data analysis and storytelling skills using Excel/SQL to dive into data and search for patterns and new insights   Customer-oriented, creative mindset: ability to understand and anticipate customers’ key business questions, and to address these with insightful data analyses and visualizations   SQL skills or willingness to quickly learn   Experience working with survey data using SPSS or other analysis tools to surface insights   Data Visualization skills using Tableau or other BI tools Please note that Verto does not sponsor employment work visas in North America."
Data Analyst and Reporting Tools Developer,Fidelity Canada,https://ca.linkedin.com/jobs/view/data-analyst-and-reporting-tools-developer-at-fidelity-canada-1561427151?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=4&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Research and analyze current reporting and business data needs   Provide ongoing status reports and prepare detailed documentation of tools and reporting Procedures   Devise and implement tools to automate and streamline processes that achieve efficiency for both business and finance users   Design and implement reporting databases and applications utilizing data from relational databases and flat file sources   Design and perform testing for data integrity and application performance   Maintain and re-engineer existing Business Objects, Access and Excel based reports   Perform data cleansing and manipulation, working with multiple disparate data sources   4+ years experience working with relational / multidimensional databases and SQL coding   Performing complex business analysis, including data flow analysis and modelling   Expertise in VBA programming and reporting in MS Access and Excel   University degree (preferably in computer science, information science, management information systems, business administration or finance)   Using enterprise reporting applications (Business Objects is an asset)   Experience in the financial services or mutual fund industry would be an asset   Skilled in process re-design and re-engineering   Strong project management skills   Strong analytical and multitasking skills   Solid communication skills   Excellent problem solver demonstrating the ability to work independently   Canada’s Top 100 Employers (2019)   Greater Toronto's Top Employers for 2019   Canada’s Top Family Friendly Employers (2019)   2018 National HR Awards - Queen’s University IRC Professional Development Award   A Canadian Compassionate Company   An Imagine Canada Caring Company"
Consultant- Big Data Developer,ProjectX,https://ca.linkedin.com/jobs/view/consultant-big-data-developer-at-projectx-1493369713?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=5&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Design and implement technical enhancements of Data Warehouse, Business Intelligence, or Big Data solutions as require   Utilize SQL, shell scripts and other external programming languages to complement and enhance the functionality the ETL tools provid   Apply automation and innovation on new and existing data platforms for those development projects aligned to the client’s business or organizational strategie   Participate in the requirements gathering, analysis and solutions desig   Conduct unit & integration tests, assisting in test preparations to ensure data integrity, data quality, and program functional completeness & correctness   Create detailed technical documentation for ETL programs and other deliverable   Implement processes aligned to data management best practices (as defined or adopted by the client) and standards, ensure data quality and process performance within all system development deliverables   Develop a deep, multilayered understanding of the business issues and the Big Data challenges facing the client’s organization and industr   Demonstrate collegial teamwork, by communicating clearly and completely with all project team members to identify, and resolve issue   Participate in the development of project plans to establish appropriate work load expectations and schedule   Own the responsibility to meet deadlines and strive to complete work in accordance with project plans   mplement processes aligned to data management best practices (as defined or adopted by the client) and standards, ensure data quality and process performance within all system development deliverables   3-5 years’ experience on technical projects including two years as a Big Data Developer providing technical solutions through the use of Big Data tools   Detailed, practical working knowledge in Big data, data query/ingestion tools such as HBase, Hive, Pig, Sqoop, Flume, Spark, Kafka, Impala, Hadoop, Oozie   Experience in working on ETL tools such as Talend ETL, Informatica, Microsoft SSIS, SAP BODS, IBM DataStage, Oracle Data Integrator (ODI) or Ab Initio   Worked in Data Warehousing, including data mapping and transformations, data dependencies, data source analysis and profiling, OLTP, OLAP, SQL, and DBMS   Working knowledge in Relational SQL, MPP and/or NoSQL databases, including SQL Server, Oracle, Teradata, MongoDB, Post Gres, Snowflake   SQL Programming, creating complex queries, tables, view, and procedures   Working knowledge in Agile delivery methodology, DevOps, Continuous Integration/Continuous Deployment concepts and methods   Working knowledge of data modelling and data modelling concepts such as logical/physical modelling, 3rdNormal Form, Entity Relationship Diagrams, IDEF, & IE modelling syntax. Exposure to Erwin.   Testing automation and knowledge in Java, C#, Python or Scala is an asset   Above average skills in communication,solution-based approaches to solving problems, level-headed decision making,time management, collaborating with internal teams (Project X ltd.), external teams (non-Project X 3rdparties), and client team members   Demonstrated skills in leadership, integrity and working independently   Ability to recognize and highlight scope changes early and manage expectations on achievability   A Bachelor's degree, preferably in software or computer science/engineering fields Or related industry experience or acumen   Specialized and/or vendor certification or training in one or more of the Big Data technologies is an asset   Health and dental benefits package   Gym membership discount   Casual dress code and working environment   Holiday parties and BBQs   Getting together for team socials and sporting events"
5200 - Senior AWS Big Data Engineer,NorthBay Solutions,https://ca.linkedin.com/jobs/view/5200-senior-aws-big-data-engineer-at-northbay-solutions-1493520763?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=6&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Possess In depth knowledge and hands on development experience in building Distributed Big Data Solutions including ingestion, caching, processing, consumption, logging & monitoring) (Must Have)   Strong Development Experience in either one of the Distributed Big Data processing (bulk) engines preferably using Spark on EMR or related (Must Have)   Strong Development Experience on at least one or more event driven streaming platforms prefer Kinesis, Firehose, Kafka or related (Must Have)   Strong Data Orchestration experience using tools such has AWS Step Functions, Lambda, AWS Data Pipeline, Apache Airflow or related (Must Have)   Assess use cases for various teams within the client company and evaluate pros and cons and justify recommended tooling and component solution options using AWS native services, 3rd party and open source solutions (Must Have)   Strong experience on either one or more MPP Data Warehouse Platforms prefer AWS RedShift, PostgreSQL, Teradata or similar (Must Have)   Strong understanding and experience with Cloud Storage infrastructure and operationalizing AWS based storage services & solutions prefer S3 or related (Must Have)   Strong technical communication skills and ability to engage a variety of business and technical audiences explaining features, metrics of Big Data technologies based on experience with previous solutions (Must Have)   Strong Data Cataloging experience preferably using AWS Glue (Nice to Have)   Strong Development Experience on at least one NoSQL OR Document databases (Nice to Have)   Experience on at least one or More Ingestion Integration tools Like Apache NIFI or Streamset or related (Nice to Have)   Strong Development Experience on at least one Caching Tools like Redis, Lucene, Memcached (Nice to Have)   Strong Understanding and experience in Big Data Audit Logging and Monitoring solutions (Nice to Have)   Strong Understanding of at least one or more Cluster Managers (Yarn, Hive, Pig, etc) (Nice to Have)Interface with client project sponsors to gather, assess and interpret client needs and requirements   Advising on database performance, altering the ETL process, providing SQL transformations, discussing API integration, and deriving business and technical KPIs   Develop a data model around stated use cases to capture client’s KPIs and data transformations   Assess, document and translate goals, objectives, problem statements, etc. to our offshore team and onshore management   Document and communicate product feedback in order to improve user experience   5+ years of AWS Solutions implementation, professional services experience, prefer Data Analytics space.   A passion for exploring data and extracting valuable insights.   Proven analytical, problem solving, and troubleshooting expertise.   Proficiency in SQL, preferably across a number of dialects (we commonly write MySQL, PostgreSQL, Redshift, SQL Server, and Oracle).   Exposure to developer tools/workflow (e.g., git/github, *nix, SSH)Experience optimizing database/query performance.   Experience with AWS ecosystem (EC2, S3, RDS, Redshift).Experience with business intelligence tools with a physical model (e.g., MicroStrategy, Business Objects, Cognos).Experience with data warehousing.   Exposure to NoSQL-based, SQL-like technologies (e.g., Hive, Pig, Spark SQL/Shark, Impala, BigQuery)   Bachelor’s Degree in Computer Science or Equivalent   Minimum five years of Big Data Engineering on AWS experience"
Data Analyst - Creative Destruction Lab - Toronto,University of Toronto - Rotman School of Management,https://ca.linkedin.com/jobs/view/data-analyst-creative-destruction-lab-toronto-at-university-of-toronto-rotman-school-of-management-1600384469?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=7&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click," Processing datasets using technical tools    Analyzing datasets    Verifying that datasets are properly entered and stored    Running queries to gather data    Analyzing and writing program scripts to extract, reformat and analyze data    Disseminating data reports    Serving as a resource to others by providing (non-supervisory) job-related guidance    Bachelor's Degree in Statistics or Econometrics or acceptable combination of equivalent education and experience    Minimum three years related experience with one year or experience in regression analysis    Proficiency in statistical packages such as Stata    Experience with data visualization tools    Ability to work independently    Accountable    Diligent    Efficient    Meticulous    Proactive    Team player"
Data Science Manager- Retail,Shopify,https://ca.linkedin.com/jobs/view/data-science-manager-retail-at-shopify-1601456880?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=8&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Define and guide the short-term and long-term data strategy for Retail   Partner with other functional teams such as Engineering, Product, Design, and GTM to identify unsolved user and business needs. Build data powered solutions that scale.    Cultivate a data-informed culture and deliver meaningful insights that drive product roadmaps and optimize business strategies   Drive excellent practices for establishing metrics & KPIs to drive cross-functional alignment    Lead, mentor, and guide your team of data scientists, helping them develop their analytical and leadership skills   Collaborate with peer leaders in the Channels Data Science team (and the broader Data org) to improve and drive the group wide Data Science vision   Experience building and managing high performance data science teams   Exceptional problem solving and analysis skills combined with the ability to synthesize and effectively communicate findings to both technical and non-technical stakeholders   An entrepreneurial mindset. You must be comfortable rolling up your sleeves, thriving in ambiguity, and getting the work done   Extensive experience with Python    Extensive experience with data pipelines and ETL design   Experience with statistical methods like regressions, GLMs, experiment design and shipping productionized machine learning systems at scale   Experience with Tableau, Mode, or similar data visualization tools    Ganesh Iyer , Director of Data Science (Channels)    Solmaz Shahalizadeh , VP Data Science & Engineering    Ian Black , Director of Retail    Arpan Podduturi , Director of Product"
Data Analyst Intern (Co-op),PayBright,https://ca.linkedin.com/jobs/view/data-analyst-intern-co-op-at-paybright-1602590328?refId=a4413da0-5643-4b62-a083-d9c71b91f487&position=9&pageNum=5&trk=guest_job_search_job-result-card_result-card_full-click,"Develop data definitions and process documentation   Support the ongoing review of data control procedures to improve overall data quality   Build dashboards to measure KPIs, working collaboratively across functions   Analyze key business trends and identify potential areas for improvement   Assist in ongoing development of business intelligence platform   Work with large volumes of data (both structured and unstructured)   Currently enrolled in a Canadian post-secondary institution with a focus on Finance, Statistics, Engineering, or a related field   Strong written and verbal communication skills   Proficiency in Microsoft Office (Word, PowerPoint, Outlook, Excel)   Understanding of SQL including join logic   Energetic and eager to tackle new projects   Ability to work in a cross-functional team environment and build relationships   High level of curiosity and desire to “roll up your sleeves”"
"Senior Software Developer, Big Data",Rakuten Kobo Inc.,https://ca.linkedin.com/jobs/view/senior-software-developer-big-data-at-rakuten-kobo-inc-1439622308?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=1&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Design and develop backend services to store and process data in new ways.     Build, optimize, and deploy production-quality code for our search, recommendations and content analysis research projects.     Build on frameworks such as Spark, Hadoop, Storm, Flume and Hive to implement innovative solutions and technologies.     Integrate with 3rd party and other in-house teams’ APIs.     Own, architect and design new services.     Provide leadership on many levels both inside and outside the team     Undergraduate degree or equivalent in Computer Science, Computer or Electrical Engineering, or related field.     5 years or more experience with multiple mainstream programming languages such as Python, Java, C++, C#, Go, etc.     Expertise in designing, implementing, testing and deploying software solutions.     Comfort operating on the command line in Linux.     Experience working with distributed Big Data tools such as Spark, Hadoop, Storm, Hive and Flume is an asset, but is not required.     Machine Learning, Statistics, or related knowledge is an asset.     Go to the site: https://www.kobo.com     Get the behind-the-scenes look: https://news.kobo.com/     Follow us on Twitter @: http://twitter.com/kobo "
AWS Solutions Architect - Big Data,Amazon Web Services (AWS),https://ca.linkedin.com/jobs/view/aws-solutions-architect-big-data-at-amazon-web-services-aws-1525102067?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=2&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Evangelizing current and future AWS services and technologies    Building and maintaining technical trusted advisor relationships with influential technical decision makers for the successful adoption and deployment of AWS services and technologies    Work in collaboration with the sales team to create and execute business plans to accelerate the adoption of AWS, exceed revenue goals, and drive customer satisfaction    Capture and share best-practice knowledge amongst the AWS solutions architect community    Identifying customer requirements and providing feedback into appropriate AWS services teams      7+ years design/implementation/consulting experience of large-scale data solutions, including data warehousing, storage, and business intelligence.    Deep experience with DBA storage architectures, ETL solutions, Relational and NoSQL DB's, Hadoop, Spark, and object storage at scale.    Experience with replication, high availability, archiving, backup & restore, and disaster recovery/business continuity data best practices.    Technical consulting and architecture with large-scale engagements.    Strong customer facing experience. Ability to present to large audiences and public forums is a must.    Technical degree required.    Experience using and adapting to new technologies.    Professional experience architecting/operating solutions built on AWS, Azure, or Google Cloud.    Experience communicating effectively across internal and external organizations, for complex mission-critical solutions    Experience with Enterprise data vendors such as Hortonworks, Hadoop, Spark, Tez, Presto, SQL Server, Oracle, MongoDB, RavenDB, PowerBI, Tableau, and others.    Understanding and experience with Machine Learning and AI related technologies."
"Senior Manager, Collections Strategy and Data Scientist - Contract",Scotiabank,https://ca.linkedin.com/jobs/view/senior-manager-collections-strategy-and-data-scientist-contract-at-scotiabank-1594049065?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=3&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Opportunity to make a direct impact to Bank’s profitability   A compensation program with competitive salary, opportunities for annual performance incentives based on performance thresholds, a competitive benefits program and continuing education programs   This an 18m contract opportunity to directly influence and impact change in risk management   Manage collections analytics, performance monitoring and strategy evaluation routines   Lead the gathering and processing of structured and unstructured data into a form suitable for analysis (for instance writing scripts, web scraping, calling APIs, write SQL queries, etc.)   Deliver on analytical projects that provide actionable insights to improve collection efforts and recoveries   Develop statistical segmentations to forecast customer payment behaviour   Design and implement policies to help our customers in need of loan modification programs   Recommend improvements to outsourcing strategies   Provide oversight of collection efforts by developing performance reports and early warning triggers   Strong collaboration and communication skills   University degree in relevant STEM discipline (Science, Technology, Engineering and Mathematics) and strong background in statistical and quantitative analysis   Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL, Sybase, PYTHON) and using statistical software such as R or SAS   Experience manipulating large and complex databases; ability to clean, transform and work with large volumes of structured and unstructured non-traditional data and with various data formats (e.g. unstructured logs, XML, JSON, flat files)   Experience with TRIAD or similar collections risk platforms strongly desired   Experience with big data tools and programming languages such as Hive, R, Python, Spark and with NoSQL databases (Hbase as an example) would be an asset   Experience with machine learning and other AI techniques for strategy design would be an asset   Results driven individual with high level of curiosity and ability to dive into details without loosing sight of the big picture   Exceptional organization skills to prioritize, manage, and implement a variety of competing initiatives, on a concurrent or staggered basis   A Master's degree in Economics, Finance, Industrial Engineer, Mathematics, Computer science, or Information technology related discipline   6 years of experience in retail credit risk management"
Big Data/Hadoop Developer,Tata Consultancy Services,https://ca.linkedin.com/jobs/view/big-data-hadoop-developer-at-tata-consultancy-services-1529873612?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=4&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,
CRM Data Analyst,Ricoh Canada Inc.,https://ca.linkedin.com/jobs/view/crm-data-analyst-at-ricoh-canada-inc-1578479690?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=5&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Manage tasks associated with CRM database    Merge companies, perform data clean up, update contact information to ensure accuracy    Map Records    Remove duplications    Match company information and update from Inside View    Conduct web searches to find most up to date information via Google, Marketwire, Linkedin    Taking and acting on instructions    Carrying out general administrative duties    Any ad hoc duties as requested by the business    Requires a high school diploma or equivalent    Diploma or certificate from a legal program is an asset    Requires 1-3 years of experience in the legal field or related area.    Excellent interpersonal skills with the ability to quickly develop business relationships    Strong self-motivation to drive results    Excellent communication skills both verbal and written    Effective use of Microsoft Office    Recevoir et traiter les demandes de gestion de dossiers    Créer de nouveaux fichiers dans le système    Ouvrir de nouveaux dossiers de fichiers et les étiqueter en conséquence    Retourner ou ajouter des documents aux dossiers de clients existants    Utiliser le système de gestion de pratique pour consigner et enregistrer les documents    Manipuler et administrer les dossiers fermés tel que demandé    Entreprendre les procédures de gestion de dossiers et d'entretien de dossiers afin d'assurer que le classement est toujours à jour    Effectuer l'ouverture de nouvelles affaires    Comprendre, identifier et traiter tous les principaux documents dans les dossiers    Préparer les dossiers pour la clôture conformément aux procédures    Entamer les demandes de récupération d'archives    Garder toutes les aires de travail et de classement en bon ordre et propres    Réaliser les demandes de copie, la numérisation, la reliure et la finitionr des tâches de copie (travailler avec le centre d'affaires le cas échéant)    Fournir de l'assistance dans le cadre de la procédure de facturation, incluant sortir la préfacturation, faire la correction d'épreuves et apporter des changements mineurs sur les préfacturations, finaliser les factures et préparer les lettres d'accompagnement    Effectuer des recherches de conflits    Commander des fournitures    Recevoir et agir selon les directives    Effectuer des tâches administratives de façon générale    Tenir un registre du temps consacré aux différentes tâches administratives à des fins internes    Toute autre tâche pouvant être exigée par l'entreprise    Diplôme d'études secondaires ou l'équivalent    Diplôme ou certificat d'un programme juridique, un atout    De 1 à 3 ans d'expérience dans le domaine juridique ou un domaine connexe    Excellentes aptitudes interpersonnelles, ainsi qu'une capacité à pouvoir développer rapidement des relations d'affaires    Avoir une forte motivation personnelle permettant d'obtenir des résultats    Excellente habileté de communication orale et écrite    Utilisation efficace de Microsoft Office"
CIND 119 Introduction to Big Data T Hybrid,Ryerson University,https://ca.linkedin.com/jobs/view/cind-119-introduction-to-big-data-t-hybrid-at-ryerson-university-1550935229?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=6&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Applicants must have a PhD (or near completion) in Computer Science or a related discipline.    Applicants must have experience in Big Data and Analytics applications.    Applicants must be experienced with or, before course startup, be willing to complete accelerated training in D2L Brightspace (including creation of discussion forums, tests, assignments, chat rooms) and the content management system (Ektron) to edit and modify course content when required.    Applicants must demonstrate their knowledge of best practices for the delivery and management of online courses as adopted by The Chang School, including, but not limited to    Applicants must demonstrate proficiency in all aspects of personal computers that are relevant to this course, including document creation, file management, internet research, and communications, and must have access to the appropriate technology.   a commitment to deliver the prescribed curriculum   demonstrated ability to apply required instructional techniques; and the ability to create a positive learning environment for adults   pedagogy for diverse populations   course management   academic advising   understanding and respect for human rights and diversity   commitment to positive interpersonal skills   Applicants must have a commitment to professional collegial life."
Data Analyst,Alquemy Search & Consulting,https://ca.linkedin.com/jobs/view/data-analyst-at-alquemy-search-consulting-1538187487?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=7&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Very strong with SQL.    Programming skills, Python/SAS skills are preferred.    Familiar with retail banking.    Very detailed oriented.    Overtime work is expected (lieu time will be provided).    ETL experience preferred."
Master Data Analyst,Aecon Group Inc.,https://ca.linkedin.com/jobs/view/master-data-analyst-at-aecon-group-inc-1603528949?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=8&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Process master data requests in accordance with data governance policies and guidelines, within the defined service level agreement    Resolve master data integrity issues and work with stakeholders to identify root causes and implement permanent corrective actions    Evaluate technologies and processes to improve master data creation efficiency (SLA) and accuracy   Support the development and maintenance of policies, guidelines, procedures and training materials   Develop and maintain material master naming convention guidelines for all material groups   Responsible for maintaining Aecon’s material group structure   Provide analytics to support the business   Support the Strategic Sourcing team to develop and maintain Pricing agreements in SAP   Ensure master data is in compliance with data governance policy at point of creation and through regular monitoring and cleansing of existing master data   Work with stakeholders to improve/automate business processes through the use of master data   Work with stakeholders to align master data with estimating tools such as Hard Dollar and Accubid   University or College degree in Civil, Electrical or Mechanical Engineering preferable   Technical background with a solid understanding of civil, mechanical, electrical and related components used in the construction industry   Highly proficient with Microsoft Excel and MS Office ERP experience an asset   Good communications skills (both written and verbal)   Analytical and problem solving skills   High attention to detail   Ability to maintain focus on a repetitive tasks for a long duration   Data collection and manipulation experience   Demonstrated High goal achievement orientation   Ability to work in a team environment   Able to perform in a rigorous and fast paced environment   Able to consistently take a disciplined track in achieving a goal using disciplined thought   Uncompromising honesty"
Data Analyst - Toronto,Covenant House Toronto,https://ca.linkedin.com/jobs/view/data-analyst-toronto-at-covenant-house-toronto-1594202693?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=9&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Bachelor's Degree in Statistics, Math, Computer Science or other   Minimum of 4 years of relevant experience   Experience running and writing queries and stored procedures   Experience in performing inserts and updates, creating databases, tables, indexes, views and other database objects   Intermediate database and data management skills   Experience in creating databases, tables, indexes, views and other database objects   Experience with Microsoft Excel, Power Query, Power BI and Crystal reports or other business intelligence (BI)/analytical tools   Must have strong skill in SQL Query   Experience in direct marketing is also an asset   Detail oriented   Analytical   Accuracy and quality assurance   Excellent interpersonal skills   Strong communication skills with the ability to communicate with technical and non-technical staff   Life-learner who stays on top of industry changes   Meaningful work   Competitive compensation   Paid vacation time   Full benefits package (Health, Dental, Vision, Personal Days, Employee Assistance Program, Tuition Reimbursement and more)   Employee Perks "
DIGITAL DATA ANALYST (DIGITAL AND DATA SCIENCE),The Globe and Mail,https://ca.linkedin.com/jobs/view/digital-data-analyst-digital-and-data-science-at-the-globe-and-mail-1536928086?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=10&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Analysis:  Modeling and interpreting large volumes of data, identifying trends and extracting insights. Reporting the results and insights back to the relevant stakeholders.   Data Visualization:  Create, maintain, enhance and automate various dashboards and reports that provide insights into user behaviour while keeping in mind business needs and goals.   Requirement Gathering and Documentation:  Assist with documenting data sources, relationships between data entities and business concepts, and methods of calculation and measurement while understanding stakeholder needs.   Quantitatively focused bachelor’s degree with at least 3 years of experience working as a Data Analyst   Experience working with Level of Detail, Table, and Window functions in Tableau   Experience working with analytical (OLAP, HTAP, etc.) databases (Teradata, Snowflake, BigQuery, etc.)   Command of analytical SQL (ex. Window Functions & Frames, Group Sets, Cubes, Rollups, etc.)   Experience with Python or JavaScript   Knowledge of inner workings of various web analytics tools (i.e. knowledge of beacons, data processing and enrichment)   Comfortable working in a ‘self-serve’ capacity as a data analyst (i.e. retrieving and modeling your own data when so required)   Experience gathering stakeholder requirements with a demonstrated ability to get to the bottom of specific business rationale   Clear and concise written and verbal communication skills   Ability to thrive in fast-paced environment with tight deadlines   Data Visualization skills and at least a year of experience working with Tableau   Working knowledge of web analytics tools such as Omniture or Google Analytics   Good understanding of SQL and relational databases   Working knowledge of JavaScript, CSS, HTML   Knowledge of statistical analysis methods   Experience deploying tracking via Tag Manager(s)   Experience working with AWS   Experience working on Linux systems (shell scripting, vi, cron management, etc.)   Experience using Git   Experience with managing Analytics and Marketing tags (via a tag manager or inline)   Experience in directing and teaching non-technical stakeholders on use of analytics tools"
Market and Data Analyst,"beBee, Inc.",https://ca.linkedin.com/jobs/view/market-and-data-analyst-at-bebee-inc-1603264016?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=11&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Ensure a smooth flow of data between the research team and our client database    Data checks, investigation of data anomalies and development of audit reports    Maintenance and upgrade of existing analytical tools    Development of new tools and processes to improve data quality and integrity    Discussion of modelling assumptions and outputs with individual market analysts, and development of recommendations for the improvement of data quality.    A Bachelor or Master?s degree in a business, economics, engineering or science discipline, with a solid foundation in quantitative skills    A minimum of 1-2-year(s) experience in a research/analysis function    Strong numerical skills and the capacity to interpret data    Good working knowledge of Excel and possibly database software.    Basic Programming skills (Macros/VBA) are not essential but would be a bonus    Some experience in forecasting and modelling techniques    The capacity to work both independently and within a team in a highly organised manner with excellent attention to detail    Good communication skills    Fluency in any foreign language preferred but not essential."
Senior Data Engineer,Thales,https://ca.linkedin.com/jobs/view/senior-data-engineer-at-thales-1563419111?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=12&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Acts as the lead for any high complexity functional data requirements and transformation needs   Architects data pipes and technology stacks related to data manipulations   Defines the requirements and oversees the development and build out of big data tool chains   Defines the requirements and oversees the development of cloud deployments of big data tools and processes   Work with the management closely to bridge the technical discipline and business disciple to achieve the common goals for the organization   Data scientist and implementer on the CBTC product portfolio   Create and maintains all documentation related to the product data platform activities   Act as the lead for developing Minimum Viable Products for Machine Learning and AI focused data platforms   Act as the key contact for any data related architecture decisions and the overall vision for data centric products and solutions   Work with the SW architects to understand downstream development activities and to increase upstream SW capabilities   Develop prototype tools and utilities to aid the integration effort and define requirements for the platform group to industrial the minimum viable products   Stays current with technology by attending workshops and through self-learning and experimentation   Reviews the software development cycle periodically to evaluate the applicability of new development strategies such as Agile etc.   Mentors and coaches junior members of the team and helps them develop their technical expertise   Focal point for technical interface into the other technical departments, will sit on any cross functional workgroups/committees   University degree in Computer Science, Software Engineering, System Engineering, Electrical Engineering or a closely related field   Over 5 years of relevant working experience   Expert knowledge in full stack development on infrastructure elements (infrastructure as a service)   Expert knowledge in full stack development on data platforms and maintenance   Expert knowledge of railway signaling techniques, including SelTrac CBTC   Expert in the ELK stack (elastic search, logstash, Kibana) or equivalent   Full stack developer with AWS or Azure   Ability to interface with important customer leadership and project leadership   Meticulous evidence based decision making and engineering approach to problem solving.   Knowledge of CBTC solution deployment and working within site constraints   Ability to work in high stress work environments where deadlines are tight and expectations are high   Expert Knowledge of Engineering risk and decision making process   Ability to travel on short notice   P. Eng certification an asset"
Data Scientist,Boost Agents Inc.,https://ca.linkedin.com/jobs/view/data-scientist-at-boost-agents-inc-1552572319?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=13&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,
Data Analyst – Group Retirement Solutions,Procom,https://ca.linkedin.com/jobs/view/data-analyst-%E2%80%93-group-retirement-solutions-at-procom-1592887947?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=14&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Main responsibility will be to convert data from current in-house platform to a third-party administrator platform.   Data conversion from in house platform to third party administrator platform   Provide oversight on improvement on data conversion tool   Handle inquiries from external Consulting Firms and internal partners in regards of group annuity   Handle the monthly reconciliations of health premiums and secondary insurer payments for active groups   Maintain up to date data records of ongoing changes that impact pricing (premium reconciliation process)   Act as a Client Relations liaison between other departments on special projects or initiatives   Develop, analyze and provide management information reports as needed   Prepare Database and files to facilitate data transfer   Prepare contract documentation to be sent to new policyholders   Prepare annual reports to be sent to annuitants   Carry out functions with an extremely high sense of urgency   Work in tandem with Customer Service Center to support the New Business Implementation process   Process improvement   Provide expertise and insight to support process improvement   Act as a Insurance liaison with external vendors providing services to Insurance in order to improve business process or develop new markets   1-3 years of experience in data analytics   Good knowledge of the regulatory and tax requirements   Advanced Microsoft Excel and Word skills, programming language (e.g. python)   Experience with an in-house Pension plan/ or large corporation/consulting firms   Strong written and verbal communication skills   In-depth analytical and problem-solving skills   Strong relationship management skills   Excellent organization skills   Keen attention to detail.   Undergraduate university degree   Good knowledge of group annuity products and sales channels   French (oral & written) is a definite asset   Good knowledge of the regulatory and tax requirements from a pension perspective   Pension background   Pension industry and Life insurance related education (e.g.: CEBS, LOMA,) is an asset   Knowledge of Insurance systems (CAPSIL, Work Management and Alias) is an asset."
Senior Data Analyst | Bangkok-Based,Agoda,https://ca.linkedin.com/jobs/view/senior-data-analyst-bangkok-based-at-agoda-1592392091?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=15&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Support business initiatives and ensures good coordination and collaboration between the teams in various Agoda’s departments and within the CEG organization to achieve projects milestones and goals    Improve scalability, stability, accuracy, speed and efficiency of our existing data analytic projects and establish projects based on extracted data insight    Work with tech and data teams to identify and build tools to support or automate data analysis/reporting tasks    Understand and report to your team and senior management on business performance    Drive data analysis projects aiming at improving and maintaining operational KPIs such as service-level agreement (SLA) / response time, customer satisfaction (CSAT), net promoter score (NPS), quality of service, productivity KPIs, costs, etc.    Provide efficient and automated regular reporting to management    Analyze issues, identify risks, report accordingly to management, and propose solutions to be implemented in efficient and effective communication    5+ years of experience working as a Data Analyst, strong Business Intelligence/Data Visualization experience preferably in the field of HR    Bachelor’s in a quantitative degree    Experience with BI/reporting software in terms of building dashboards – Tableau in particular    Expert Excel user: ability to understand and build complex spreadsheets; ability to efficiently extract data from large and complex database    Quick learner, proactive/forthcoming attitude, problem-solving aptitude, effective prioritization, attention to detail    Strong “story-teller” that can communicate insights and recommendations effectively    Excellent problem solving and comprehension skills as well as strong business sense    Excellent communication skills: ability to communicate with people of differing levels of seniority and analytical understanding    Project management: able to initiate and drive projects, liaise with stakeholders and manage resources to reach objectives and deliver product    High level of organization: ability to manage multiple, competing priorities and deliver results under tight deadlines and pressure    Excellent communication skills in written and spoken English    Experience working with relational databases (MSSQL, Postgress, MySQL, etc…)    Experience working with SaaS (Workday, Greenhouse.io) platforms and APIs in any programming language (Python, C#, Java, etc.…)    Be part of a dynamic and exciting data-driven multinational team in a successful and fast-growing tech company    A career path will help you to continuously develop your skills    The chance to propose ideas to improve operations based on data and have an impact on the customer experience    Competitive compensation package (relocation support for successful overseas candidates)    International and domestic health insurance    Annual performance bonus"
Intermediate Data Analyst to provide deep technical analysis using Python & R Programming for a Data Management initiative.,S.i. Systems,https://ca.linkedin.com/jobs/view/intermediate-data-analyst-to-provide-deep-technical-analysis-using-python-r-programming-for-a-data-management-initiative-at-s-i-systems-1537118252?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=16&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Working with SME's to understand the data , identify issues and validate it with the SME's.   80% will focus on using R and cleaning the data and putting it into Hadoop, 20% will be tweaking code and cleansing data.    Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.   Conduct ETL, SQL and DB performance tuning, troubleshooting, support, and capacity estimation to ensure highest data quality standards with the business and technical SME’s.   Helps with the process of profiles data and ETL logic for documenting end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing)   Profile and analyze source data to determine the best reporting structures to build.   Design and develop ETL pipelines using multiple sources of data in various formats according to business requirements.   Conduct dimensional modelling, metadata management, data cleaning and conforming, and warehouse querying.   Use sound agile development practices (code reviews, testing, etc.) to develop and deliver data products   2+ years’ experience working as a  Data Analyst/Data Engineer   Proficiency with  Python & R Programming    2+ years working within  Hadoop & Hive   Strong proficiency in  SQL   Proficient in a variety of languages including:  Scala, Java, Javascript   Data modelling  and  warehousing  experience would be a plus   API  development experience   Experience working in an  Agile  team environment"
Data Analyst (Quality Control),Jam City,https://ca.linkedin.com/jobs/view/data-analyst-quality-control-at-jam-city-1561478195?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=17&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click," Unlimited Vacation, Paid Sick Days & Holidays    100% Employee Covered Medical, Dental, Vision Plan Base Plan    Life Insurance, RRSP matching, Flexible Spending Accounts & More    Catered Lunches & Well-stocked Kitchens    Fully catered breakfast, lunch, and snack-filled kitchen    Company Events such as movie night, pub night and more…    You'll be equipped with a high-end laptop, monitor and mobile device    Convenient location in downtown Toronto’s entertainment and technology district   Building reports, dashboards and data visualizations to monitor the health and accuracy of our data.   Monitor the entire data pipeline, proactively identify issues, discrepancies or anomalies.   Create and improve ETL jobs and dashboard scripts, primarily in SQL and Scala.   Constantly validate data to ensure that our product team is working with the correct data, from installs to revenue to game specific metrics such as a new reward type.   Proactively identify discrepancies or anomalies and take ownership in ensuring the problem is fixed.   Debug issues and resolve them, either yourself or by providing detailed information to the appropriate team member, from QA to product to engineering.   Create dashboards, automated reports and alerts to allow developers and QA to easily monitor and quickly identify data quality issues.   Work with product and design to understand new game features and their intent, in order to have the necessary logging to analyze the feature in order to provide actionable insights.   Constantly play the product and monitor KPIs, team and community feedback in order to give context to the data.   Monitor performance and failures in the data pipeline, and understand the priority and resolve or escalate accordingly .   Compare data across multiple sources, such as the app stores and third party analytics providers.   Assist the data engineers in managing billions of rows of data.   Organize and prioritize requests from a variety of stakeholders, including ad-hoc and time sensitive issues.   BA/BS degree in Computer Science, Math, Stats or equivalent.   1+ years of experience working with data on a live product.   Strong data analysis skills using SQL and Excel.   Programming experience with R, Python, or Scala.   Ability to create reports and visualize data to provide actionable insights.   Previous startup experience is desirable, comfort in an agile environment.   Strong attention to detail and proven analytical skills.   A curious mindset to identify issues and follow through.   The ability to communicate and present information clearly.   An appetite to learn, grow, and take on increasingly more responsibility.   A strong desire to answer questions that can drive actionable decisions.   Knowledge of the mobile gaming industry in order to provide recommendations on game design."
Research Scientist,7B Search Group Inc.,https://ca.linkedin.com/jobs/view/research-scientist-at-7b-search-group-inc-1594193280?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=18&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,
Data Analyst at GH:S Traktor City,JOIN Solutions AG,https://ca.linkedin.com/jobs/view/data-analyst-at-gh-s-traktor-city-at-join-solutions-ag-1546370063?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=19&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,
Data Analyst- 1 year contract (multiple vacancies),Reliance Home Comfort,https://ca.linkedin.com/jobs/view/data-analyst-1-year-contract-multiple-vacancies-at-reliance-home-comfort-1597775194?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=20&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Responsible for working with Business data lead and SAP technical migration lead to develop a data cleansing and migration strategy, execute data cleansing and migration project activities, and perform data conversion during mock conversions, cutover, and go-live phases.   Support Reliance data workstream in developing a data governance strategy that includes business metadata definition, data quality measures, and data controls definition.   Leverage SAP data migration methodologies and migration tools to execute data migration activities for data extraction, transformation to SAP S/4HANA target, load and validation activities.   Bring a business lens to the data workstream required to understand the nature of legacy data elements.   Standardize and simplify Reliance data definitions and content to migrate into an SAP S/4HANA master and transactional data schema.   Ensure the data elements being migrated supports the user journey within SAP roles and across Reliance business functions.   Create processes for Data Life Cycle management so that Reliance can continue data discipline in an SAP production landscape.   Responsible for the management of the data migration task lists and update the plan with the latest estimates to complete.   Monitor and report on key data cleansing and migration metrics to the Business data lead and SAP Technical migration lead in a business professional manner.   Ensure execution of data cleansing and migration tasks as per project plan and escalate when there are risk, issues, or decisions identified.   Ensure data issues are remediated and completed on-time – to be measured via volume and quality yields.   Manage dependencies between the project milestone dates and data migration project due dates.   Support business data lead in setting up appropriate SAP master and operational data governance.   Support in building and executing on mock conversion and cutover plans.    5 - 10 years’ experience in SAP implementations and operating SAP in a production environment focused on data cleansing / data migration / and post go-live master data management    Ideally worked on at least 1 SAP S/4HANA or SAP ECC implementation in the role of a data cleansing &/or data conversion analyst within the past 5 years.   Past experience with Banner CIS billing system and Solomon Financial system (Microsoft Dynamics SL) would be an asset.   SAP project implementation experience ideally with the following tools: SQL, SAP S/4HANA or SAP ECC data conversion, Python, Power BI / Tableau, JIRA, SAP HANA architecture, HANA Modeling, HANA data provisioning, HANA views (Attribute, Analytic, & Calculation views), SLT (SAP Landscape Transformation Replication Server), SAP Data Services.   Ability to work with data within structured and unstructured databases, reporting tools, Excel files, flat files as well as experience analyzing data sets or data results.   Exposure and understanding to SAP ETL practices in migrating data from a legacy environment into an SAP greenfield for SAP modules including but not limited to FICO, SD, MM, EAM.   Individual must have business acumen and an ability to deal with ambiguity within data sets.   Excellent problem-solving and root cause identification skills are required, coupled with a strong business orientation and general pragmatism.   Good interpersonal skills are required and the ability to relate well throughout the organization is a necessity.   Ability to set and achieve goals, with strong follow-through.   Ability to build strong relationships with stakeholders across all levels of the organization.   Forward thinking and able to foresee consequences of actions, recognizing risks and opportunities.   Proficiency in Microsoft Office suite of products (Word, Excel, PowerPoint, Visio, Project, SharePoint)."
Big Data Solutions Architect,Dell,https://ca.linkedin.com/jobs/view/big-data-solutions-architect-at-dell-1470644806?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=21&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Provide thought leadership as a senior member of the technical staff in the Big Data and Analytics group.   Work and collaborate with other members of cross-functional teams and business groups on company-wide data intelligence programs. Act as a subject matter expert on Big Data, business intelligence & advanced analytics within the company.   Directly contribute to development of Big Data architecture standards that are important to Dell EMC. Exercise considerable latitude in determining technical objectives, without appreciable direction.   Write functional detailed design specifications as well as responding to requirement documents and system level plans. Significant contributor to organizational goals and objectives.   Lead design, architecture and building of data analytics solutions. Create proposed data design changes/suggestions to processes, exert significant latitude in determining objectives of an assignment.   Independently represent data intelligence and analytics programs, their relevance and expectations to senior staff. Collaborate with leaders from cross-functional teams and business groups that have an affinity to data intelligence.   System Admin experience (RedHat 6 and RedHat 7)   Experience with RedHat Satellite Server   Experience with Ansible, Ansible Tower, Salt Stack   Experience with Hadoop Administration and Configuration   Hands on experience with Kafka, Spark, Ranger, Sentry, Hive, Hbase, Yarn   7-10 years relevant professional experience / Bachelor’s degree (technical degree); or professional equivalence.   Experience with Virtualized, Cloud environment   Scripting using Python, shell etc.   Experience with managing configuring CISCO servers, Networking, Firewalls (Paloalto/ Panoroma)   Experience working in DataCenter   Experience with programming/scripting, statistical analysis, database, ETL and programming languages like /R used in predictive analytics. Expert skills in data visualization and design.   Industry certifications in Big Data, data intelligence & analytics, data science, data governance.   Spring boot"
Principal Data Scientist/Machine Learning Engineer,Jobspring Partners,https://ca.linkedin.com/jobs/view/principal-data-scientist-machine-learning-engineer-at-jobspring-partners-1490330865?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=22&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"5+ Years of Data Science, machine learning.   Working with Python or Scala   Working Experience with XGBoost, PyTorch and/or TensorFlow.   Worked with predictive analytics in supply chain management environments   A passion to learning more about AI!   80% Data Science & Machine Learning   20% Data Engineering   70% Hands On   10% Management Duties   20% Team Collaboration   Competitive Salary: Up to $220K/year, DOE   Statutory Vacation   Holiday Pay"
Senior Data Scientist - Fraud Analytics,BMO Financial Group,https://ca.linkedin.com/jobs/view/senior-data-scientist-fraud-analytics-at-bmo-financial-group-1579473561?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=23&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Influences and negotiates to achieve business objectives.    Recommends and implements solutions based on analysis of issues and implications for the business.    Assists in the development of strategic plans.    Identifies emerging issues and trends to inform decision-making.    Provides strategic input into business decisions as a trusted advisor.    Makes recommendations to senior leaders on strategy and new initiatives, based on an in-depth understanding of the business/group.    Acts as a subject matter expert on relevant regulations and policies.    Networks with industry contacts to gain competitive insights and best practices.    Leads discovery process with stakeholders to identify business requirements and expected outcome and to select relevant sources of data/information.    Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.    Manages resources and leads the execution of strategic initiatives to deliver on business and financial goals.    Helps determine business priorities and best sequence for execution of business/group strategy.    Conducts independent analysis and assessment to resolve strategic issues.    Develops the business case by identifying needs, analysing potential options and assessing expected return on investment.    Recommends business priorities, advises on resource requirements and develops roadmap for strategic execution.    Makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices.    Structures loosely defined and complex business problems; determines new experimentation methods and statistical techniques to design solutions.    Builds effective relationships with internal/external stakeholders.    Ensures alignment between stakeholders.    Acts as the prime subject matter expert for internal/external stakeholders.    Supports data collection, integration, and retention requirements for data.    Develops experimental design approaches to validate findings or test hypotheses.    Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.    Identifies/creates the appropriate algorithm to discover patterns.    Drives analytics innovation; poses open-ended questions, explores new ideas, and chooses appropriate techniques for solving business problems.    Oversees the development and delivery of tools and training for data and analytics.    Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.    Leads change management programs of varying scope and type, including readiness assessments, planning, stakeholder management, execution, evaluation and sustainment of initiatives.    Leads the development of the communication strategy focusing on positively influencing or changing behaviour.    Collaborates across BMO to develop communications strategies and ensure consistency of messaging, in order to positively influence or change behaviour.    Applies innovative and best practices to advanced analytics services to ensure high quality standards.    Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.    Designs and implements policies and procedures around new data sets to ensure data quality, consistency, repeatability, and accuracy of insights.    Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.    Provides advice and guidance to assigned business/group on implementation of analytical solutions.    Works with stakeholders to identify the business requirements, understand the distinct problems, and the expected outcome and models and frames business scenarios which impact critical business processes and/or decisions.    Works with various data owners to discover and select available data sources from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.    Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).    Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.    Summarizes statistical findings and draws conclusions and presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.    Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.    Performs experimental design approaches to validate finding or test hypotheses.    Uses the appropriate algorithms to discover patterns.    Builds effective relationships with internal/external stakeholders.Ensures alignment between stakeholders.    Supports development of tools and delivers training for data analytics and AI.    Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.    Leads/participates in the design, implementation and management of core business/group processes.    Operates at a group/enterprise-wide level and serves as a specialist resource to senior leaders and stakeholders.    Applies expertise and thinks creatively to address unique or ambiguous situations and to find solutions to problems that can be complex and non-routine.    Implements changes in response to shifting trends.    Broader work or accountabilities may be assigned as needed.    Typically 7+ years of relevant experience and/or certification in related field of study or an equivalent combination of education and experience.     Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience.     In depth experience using machin learning algorithms.     Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).     Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).     Seasoned professional with a combination of education, experience and industry knowledge.     Verbal & written communication skills - In-depth / Expert.     Analytical and problem solving skills - In-depth / Expert.     Influence skills - In-depth / Expert.     Collaboration & team skills; with a focus on cross-group collaboration - In-depth / Expert.     Able to manage ambiguity.     Data driven decision making - In-depth / Expert. "
Master Data Analyst,CAPREIT,https://ca.linkedin.com/jobs/view/master-data-analyst-at-capreit-998951926?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=24&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Data Analysis and Reporting on internal KPIs on a weekly and monthly basis, including but not limited to master data, financial reporting, supply chain data exception reporting, etc.   Maintain material master and vendor master changes in accordance to internal governing rules   Assisting in any downstream firefighting or incident resolution initiatives through master data management   Communicating with all levels of internal management, and commitment to top tier performance for communicating with our vendor partners   Mass maintenance to simple and tiered data layers, including pricing, unit of measures, descriptions, and p2p data imperatives (PO data, requisition data, contracts data, workflow data)   Contract role responsibilities may change as the LOB needs change   University Degree or College Diploma in a business or operations discipline   Minimum two years related experience   SAP MM module (P2P cycle) required   Computer proficiency using MS Office applications (Specifically; Word, Excel)   Knowledge of supply chain operations and incident resolution would be a big asset   Ability to standout in fast paced environment   Comfortable speaking to all lines of business   Ability to learn quickly and adapt in a constantly changing environment   Keen attention to detail"
Senior Data Analyst Reporting & Forecasting,jobleads.com - Careers for Senior-Level Professionals,https://ca.linkedin.com/jobs/view/senior-data-analyst-reporting-forecasting-at-jobleads-com-careers-for-senior-level-professionals-1555993903?refId=cfc38b0c-4c14-438e-b465-6a2312bd48a9&position=25&pageNum=6&trk=guest_job_search_job-result-card_result-card_full-click,"Support annual budget and quarterly revenue forecasting through analysis of historical trends and expected shifts in key revenue drivers   Collaborate with cross-functional teams (Marketing, Customer Base Management, Finance, Pricing, Sales) to understand and assess key revenue and market inputs    Produce weekly revenue management reports for executive stakeholders, to deliver clear summary of wireless business results against targets   Understand and share key insights/drivers of revenue performance   Support team with data analysis. Identify, analyze, and interpret trends in complex data sets, to uncover and size new revenue and cost saving opportunities   Proactively search for opportunities for improvement and lead an integrated 4P action plan with a cross-functional stakeholder team   Build presentations for senior executive audiences to provide updates and explain KPI results   Understand business needs and priorities in order to make informed recommendations and present them in non-technical language at different forums/meetings   2+ years of experience in telecom, accounting, consulting, financial services, marketing and/or product/pricing management   Undergraduate degree in Business, Engineering, or any other quantitative domain   Proficient in SQL, with ability to pull, process, analyze and interpret data to inform business decisions   Proficient in Microsoft office (excel, powerpoint)"
Senior Data Scientist - Advanced Analytics,Manulife,https://ca.linkedin.com/jobs/view/senior-data-scientist-advanced-analytics-at-manulife-1512055049?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=1&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Develop and implement models to support divisional strategy and business pillar initiatives   Lead, manage and deliver advanced analytics solutions through consulting type engagements with internal business clients   Perform requirement analysis with business area (understand business problem and generate hypotheses)   Build, test, deploy and iteratively improve models   Calculate model impact/ROI and communicate value added to stakeholders   Implement measurement and documentation framework against all project work   Generate insights for businesses so that they clearly recognize the quantifiable value considering trade-offs between and among choices   Enable those who are not professional data analysts to effectively interpret data through effective communication of results and analytics outcomes   Provide thought leadership around analytics methodology, tools, and measurement   Innovate and find creative ways to source data to support modeling efforts, leveraging structured and unstructured data using Big Data technologies   Peer review other Data Scientists’ work   Advanced degree in Statistics, Math, Computer Science, Engineering or other related discipline (post-grad preferred)   Minimum of 5 years of experience specifically in statistical/data analysis and data mining, predictive modeling, machine learning, optimization   Proficient in Python or R   Working knowledge of SQL, Python, Java   Familiarity with Hadoop ecosystem (e.g. Spark, Hive, Kafka, HBase, Oozie)   Extensive experience in debugging and solving performance issues when dealing with terabytes of data   Demonstrated data transformation and manipulation experience   Insurance/financial Services experience desired   Experience with analysis of unstructured data desired   Proven track record of delivering innovative analytical insights to a variety of customers   Strong commitment to organizational success and teamwork   Adaptable and open to change with strong collaboration and presentation skills   Familiarity with Agile methodologies"
Big Data Hadoop Lead - Brampton,Capgemini,https://ca.linkedin.com/jobs/view/big-data-hadoop-lead-brampton-at-capgemini-1530770999?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=2&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click," Big Data Experience in Hadoop Eco system on AWS or AZURE Experience - 8-10 years    Qualification: 3-7 years (2 years min relevant experience in the role) , Bachelor’s Degree.    Certification: Should have or seeking SE Level 1.    Should be proficient in Package Configuration.    Should have progressing skills in Business Analysis, Business Knowledge, Testing, Architecture Knowledge, Technical Solution Design and Vendor Management"
"Business Data Analyst, Audience Segmentation (English Services)",CBC/Radio-Canada,https://ca.linkedin.com/jobs/view/business-data-analyst-audience-segmentation-english-services-at-cbc-radio-canada-1577897770?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=3&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click," Creating segments in demand.     Analyzing data to suggest segment opportunities.     Researching and identifying new data sources.     Working with the development team to capture data from all sources.     Organizing data in a way that makes sense for the revenue group.     Deliver insights. You will deliver key findings that help drive Media Solutions’ decision making, optimization and prioritization. You will collaborate across teams to develop measurement strategies, learning agendas and roadmaps.     Transform data. You will apply your expertise and use tools to understand the quality of data collection and convert the raw data into consumable analytics for data modelling, machine learning and data mining.     Act as a Business Analyst. You will work across teams with internal stakeholders to understand business objectives and priorities, define data strategy and develop project scope for targeted audience advertising. You will generate and maintain documentation for implementation projects, process and tools.     Execute analyses. You will manage and deliver advertising performance analysis, platform analytics, customer segmentation, performance forecasting, ROI modeling, lifetime value analysis, cross channel analysis, media mix analysis and brand research     Guide the development of daily, weekly, monthly, and seasonal reporting/scorecards to monitor the health of the initiatives, audience retention and acquisition and to share trends, business insights, and recommendations with stakeholders throughout the organization.     Create and translate. You will simplify complicated data scenarios into compelling and straightforward stories for non-data-savvy stakeholders.     Shape DMP roadmap. You will contribute ideas for further expanding and applying the DMP and data in general at CBC/Radio-Canada.     The education. You have a post-secondary degree in e-Commerce, Business Intelligence or Marketing.     The languages. You are fluent in English and have a working knowledge of French.     The expertise. You have 3+ years progressive experience in a deadline driven media or agency environment. You have an in-depth understanding of digital platforms, the advertising industry, and the categorization of content to create audience segments. You are an effective change agent with the ability to envision multiple paths forward.     The knowledge. You are acutely aware of the impact of data analytics on business driven decisions. You can identify opportunities for testing segments and generate reports looking at segment overlaps, affinity scores, trends, advertising effectiveness.     The technical toolkit. You have hands-on experience using:     AdOps technologies, ideally Google AdManager.     A DMP such as Lotame and DMP use cases.     HTTP to inspect code and use proxies to analyze calls.     Diving into 1st and 3rd party cookies.     Basic Information Architecture skills, especially around taxonomies.     The drive. You thrive in an autonomous and ambiguous role where you have the freedom to define what you do. You are curious with an ability to dig for insights, see the big picture and keep up with industry changes     The analytical skills. You are a strategic thinker and can respond quickly to critical circumstances. You can balance multiple projects simultaneously and execute decisions independently.     The relationship building finesse. You can nurture strong two-way relationships with clients, peers, partners and external technological vendors. You thrive in a collaborative environment.     The communication skills. You are skilled at presenting ideas to clients, sales and management. You know how to listen and you understand perspectives. "
Senior Data Scientist - Fraud Analytics,eFinancialCareers,https://ca.linkedin.com/jobs/view/senior-data-scientist-fraud-analytics-at-efinancialcareers-1546326757?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=4&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"In-depth / Expert. Analytical and problem solving skills In-depth / Expert. Influence skills In-depth / Expert. Collaboration & team skills; with a focus on cross-group collaboration In-depth / Expert. Able to manage ambiguity. Data driven decision making In-depth / Expert. We're here to help At BMO we have a shared purpose; we put the customer at the centre of everything we do - helping people is in our DNA. For 200 years we have thought about the future-the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we're changing the way people think about a bank. As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset. To find out more visit us at https://bmocareers.com/ . BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter."
Senior / Intermediate Data Scientist,Workbridge Associates,https://ca.linkedin.com/jobs/view/senior-intermediate-data-scientist-at-workbridge-associates-1266738475?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=5&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"3-5 years of Data Science/Machine learning experience   Extensive experience with SQL   Expert with Python, Scala, R.   Familiar with Big Data technologies   A Computer Science Degree   50% Hands On   25% Management Duties   25% Team Collaboration   Competitive Salary: Up to $120k/year, DOE   Statutory Vacation   Benefits Package – Dental, Medical, Vision   Yearly Bonus   4+ weeks of Vacation   Workbridge Toronto - OSD"
Senior Data Scientist - Natural Language Processing,Thomson Reuters,https://ca.linkedin.com/jobs/view/senior-data-scientist-natural-language-processing-at-thomson-reuters-1535894117?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=6&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Interact with business stakeholders to understand their challenges, develop hypotheses and prototype solutions to real world problems using innovative NLP and machine learning techniques.   Design, implement and validate developed algorithms.   Applicant should be able to quickly spot errors, remove obstacles, and provide guidance when research progress slows.   Demonstrating successful mentorship of junior team members and delegation of tasks to other team members to further plan execution, as appropriate.   Collaborate with engineering and technology teams to move your solutions into production.   PhD or Masters in a data-heavy technical field, such as Computational Linguistics, Computer Science, Engineering, Statistics, Mathematics, or other data-heavy discipline such as Physics or Chemistry or quantitative social science.   3+ years of relevant experience in building machine learning models and/or systems.   Proficient programming skills in a high-level language (e.g. Java, Scala, Python, C/C++, Perl, Matlab, R).   Project-based experience with some of the following tools: Applied machine learning (e.g. libSVM, Shogun, Scikit-learn or similar) Natural Language Processing (e.g., ClearTK, ScalaNLP/Breeze, ClearNLP, OpenNLP, NLTK, or similar) Statistical data analysis and experimental design (e.g., using R, Matlab, iPython, etc.) Information retrieval and search engines, e.g. Solr/Lucene Distributed computing platforms, such as Hadoop (Hive, HBase, Pig), Spark, GraphLab Databases (traditional and noSQL).   Ability to translate the latest technical papers into implementations addressing our use cases.   Experience with statistical data analysis, experimental design, and hypotheses validation.   Must be a self-motivated, lifelong learner, who is passionate about turning new ideas into solutions for clients.   Excellent oral and written communication skills."
"Data Scientist II, Machine Learning Model Validation",TD,https://ca.linkedin.com/jobs/view/data-scientist-ii-machine-learning-model-validation-at-td-1548138682?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=7&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Validate Machine Learning models and AI applications.   Lead validation projects and build a close working relationship with several business units across the Enterprise.   Act as a lead or top technical data scientist and work closely with senior leadership on significant projects.   Develop/implement Machine Learning model validation methodologies and standards. Ensure that the validation methodologies and standards are in line with industry best practice or address regulatory and audit requirements and/or findings in a timely manner.   Develop and apply a variety of statistical tests and modeling techniques to identify/recommend improvements to models and undertake related initiatives. Ensure extensive testing of model sensitivity that help assessing model behavior and risk.   Implement and evaluate external models used for benchmarking internal model performance. Participate in model selection and related due diligence activity.   Actively participate with business partners in internal data management to ensure data integrity and the completeness of data capture for model validation and development purpose.   Maintain full professional knowledge of techniques and developments in the field of Machine Learning and share knowledge with business partners and senior management.   The position involves working effectively with different internal partners such as TD Wealth, TD Insurance, ED&A, PBSA, Layer6 and etc.   Strong quantitative skills with an advanced degree in one or more of the following areas: computer science, mathematics, physics, statistics, machine learning, economics, engineering, and/or actuarial science.   Up to 6 years' experience of working in analytical environments; Technical leadership experience a plus.   Experience with and strong knowledge of Machine Learning theory and predictive algorithms:  Neural Networks/Deep Learning, NLP, Bagging and Gradient Boosting methods, Generalized Additive Models, Graphical Models, Bayesian/probabilistic methods and etc.   Experience or knowledge of Machine Learning Model Interpretation/Explanation, as well as Bias/Fairness assessment, tools and algorithms.   Experience with Big Data analytics tools and environments, such as, Hadoop/Hive, Spark, and H2O.   Ability to research and implement Machine Learning algorithms from academic research papers is a plus.   Obje ct Oriented and Functional programming skills.   Proficient in one or more programming languages such as Java, Scala, Python and/or R.   Knowledge of neural network tools such as Tensorflow/Keras, MXNet and/or PyTorch.   Excellent verbal and written communication skills.   Quick learner who constantly works on improving their skills and expertise.   Good time management and multitasking skills with minimal supervision."
Big-Data Back-end Developer,Collective[i],https://ca.linkedin.com/jobs/view/big-data-back-end-developer-at-collective-i-1522202086?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=8&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"B.S. in Computer Science or related field and industry experience   4+ years of software development experience in a production environment   2+ years of experience in back-end service software development   2+ years of experience in distributed computing   1+ years of experience with Akka (akka-cluster, akka-streams,    akka-http, akka-persistence), Scala, SBT.   Hands on experience: with distributed database management systems, including Cassandra, Redis, and other SQL and NoSQL DBMS; and with Bash and Jenkins   Experience developing unit tests   Experience with agile methodology   Experience with APIs design   Working well with time sensitive delivery deadlines   Comfortable with navigating through ambiguity   Team player mentality   Sense of pride and ownership over the quality of your work   Sense of humor   Experience with Java, Spark, Kafka, Hive, Airflow   Enterprise development experience"
CIND 119 Introduction to Big Data S Hybrid,Ryerson University,https://ca.linkedin.com/jobs/view/cind-119-introduction-to-big-data-s-hybrid-at-ryerson-university-1550934336?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=9&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click," Applicants must have a PhD (or near completion) in Computer Science or a related discipline.    Applicants must have experience in Big Data and Analytics applications.    Applicants must be experienced with or, before course startup, be willing to complete accelerated training in D2L Brightspace (including creation of discussion forums, tests, assignments, chat rooms) and the content management system (Ektron) to edit and modify course content when required.    Applicants must demonstrate their knowledge of best practices for the delivery and management of online courses as adopted by The Chang School, including, but not limited to    Applicants must demonstrate proficiency in all aspects of personal computers that are relevant to this course, including document creation, file management, internet research, and communications, and must have access to the appropriate technology.   a commitment to deliver the prescribed curriculum   demonstrated ability to apply required instructional techniques; and the ability to create a positive learning environment for adults   pedagogy for diverse populations   course management   academic advising   understanding and respect for human rights and diversity   commitment to positive interpersonal skills   Applicants must have a commitment to professional collegial life."
"Manager, Indirect Tax Recovery Data Analyst",EY,https://ca.linkedin.com/jobs/view/manager-indirect-tax-recovery-data-analyst-at-ey-1485268835?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=10&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Project Management - prioritizing and ability to multitask with several client data sets   Effective communication with clients for on-boarding and trouble shooting   Monitor client responses/deadlines and follow-up accordingly   Provide the Recovery Team with, standard reports, non-standard reports and related support issues   Possesses a high level of expertise of applications, software, systems and the client data conversion process   Providing deliverables in a timely manner to Recovery Team   A bachelor's degree in accounting, finance, or technology.   Experience in extracting data from ERP systems such as SAP, Oracle, JD Edwards, etc.   Advanced SQL Server expertise including performance tuning   Advanced Access expertise (debugging, errors, form design, etc.)   Technology experience working with Excel, VBA, .NET and other business or accounting-related programming languages   5 years of progressive, post-baccalaureate work experience in data analytics   An understanding of accounting   Prior experience working in Indirect Tax   Support and coaching from some of the most engaging colleagues in the industry   Learning opportunities to develop new skills and progress your career   The freedom and flexibility to handle your role in a way that’s right for you"
Big Data - Configuration Specialist,Mentortech,https://ca.linkedin.com/jobs/view/big-data-configuration-specialist-at-mentortech-1594169790?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=11&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click, We have a unique hybrid contingent staffing service composed of domestic and international sourcing    We have a 24/7 recruitment cycle due to the fact that Mentor has offices in many different time zones    We work day and night to provide our consultants and employees with best working environment
Data Scientist,Toronto Finance International,https://ca.linkedin.com/jobs/view/data-scientist-at-toronto-finance-international-1579092256?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=12&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Banking:  Optimize transaction processing, personalize wealth management advice, improve risk management and strengthen marketing strategies.   Insurance:  Provide more accurate pricing through real-time analytics.   Finance and Asset Management:  Strengthen predictive capabilities through analysis of patterns and trends.   Architect computing environments and specialized databases.   Build algorithmsand perform data programming and modelling.   Integrateand organizelarge quantities of structured and unstructured datasets.   Applydata mining techniques using sophisticated tools to analyzeanorganization’s data.   Verify the integrity of collected data and analytical findings.   Preparewritten and visual reportsand explain results to both technical and non-technical audiences.   Proposeactionable insights and recommendations that support and drive business decisions.   Improveworkplace efficiency via processautomation.   Apply analytical, technical and math skills to buildingbetter prediction systems that will integrate with an organization’s products to create a better customer service relationship.   Proposeanalytics strategies and solutions thatcan optimizeongoing processes (including working in conjunction with other departments and IT teams in an efficient manner).   Expert-knowledge of data mining, warehousing, processing and reporting (e.g. SAS and Teradata)   Expert-knowledge of statistical and quantitative theories and their applications   Highly skilled in processing and/or reconciliation of information or data   Highly detail-oriented   Analytical Thinking: Problem-solving and reasoning skills   Data Interpretation, Sense-making & Communication Skills: Efficiently communicate complexanalytical findingsto members of the organization and other key stakeholders   Financial analysis skills   Statistical analysis and modelling skills   Previous experience as a Business Intelligence Analyst, Statistician, Data Engineer or Data Analyst   Undergraduate university degree   Graduate degree   Mathematics   Statistics   Computer Science   Data Science   Engineering   Business   Increased Seniority:  You could move into a leadership role, such as Project Manager, Chief Data Scientist, Senior Data Scientist or Lead Data Scientist.   Move to a Related Field:  You may choose to move into a related area of analytics.   Senior Project Manager   Program Manager   Risk Analyst   Risk Modeller   Advances in T echnology :  Continuous learning and skill upgrades will be needed to keep up-to-date with new information database systems and analytic tools.   Lack of Skilled W orkers :  The shortage of qualified talent for Data Scientist roles may impact workloads at different organizations.   Dynamic Financial Markets:  Given the pace at which the business landscape can change, Data Scientists are constantly challenged to stay current or ahead of the curve with respect to business intelligence.   Business C omplexity :  Continued dependence on technology innovation will create ongoing demand for all technology roles in the financial services sector."
Data Engineer - Toronto,Ritual,https://ca.linkedin.com/jobs/view/data-engineer-toronto-at-ritual-1594202027?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=13&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,
Java/Big Data Developer,Procom,https://ca.linkedin.com/jobs/view/java-big-data-developer-at-procom-1566818447?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=14&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"The Treasury Analytics Group is responsible for measurement and management of market risk (interest rate and foreign exchange) for the Bank's retail portfolios.    The team develops financial models and processes required for measuring, transfer pricing, hedging product profitability, and financial management reporting.   The Treasury Analytics Group is embarking on a brand new initiative to build the next generation strategic platform for risk, valuations and analytics to meet the growing and future needs of the department.    This is an exciting opportunity to work on cutting edge technologies including Big Data and NoSQL databases (Hadoop, Hbase, Hive, SPARK and MongoDB) to allow the business to gain advanced insight into their portfolios and valuation metrics.   This role is within the development team to build out the platform and build aggregation services, rules engines and analytics services as well as business functionality to the platform.    These services will be exposed via rest API's to other components of the platform.    The candidate will need to be familiar with optimization and performance tuning to optimize for low latency and very large data sets.    The candidate will be involved in all aspects of the application development lifecycle including gathering business requirements, system design, development, testing and deployment.    Experience in Java - 3 years   Experience in SQL database - 4 years   Experience in developing Restapi - 2 years   Experience in developing multithreading applications - 3 years   Strong communication skills   Linux - 2 years   Big data (Hadoop)   Banking experience   Distributed systems like spark/storm   Kafka"
5000 - Amazon EMR & Big Data Solutions Architect,NorthBay Solutions,https://ca.linkedin.com/jobs/view/5000-amazon-emr-big-data-solutions-architect-at-northbay-solutions-1603594700?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=15&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click," Interface with client project sponsors to gather, assess and interpret client needs and requirements     Develop a data model and Data Lake design around stated use cases to capture client’s KPIs and data transformations     Identify one or more relevant AWS services -- especially on Amazon EMR -- and an architecture that can support client workloads/use-cases; evaluate pros/cons among the identified options before arriving at a recommended solution optimal for the client’s needs.     Be able to explain to the client the tradeoffs among the various AWS options, and why the recommended solution(s) and architecture was chosen as an optimal one for the the client’s needs.     Work closely with the client and broader NorthBay Delivery team to implement in Agile fashion the architecture and chosen AWS services using AWS Best Practices and principles from the AWS Well-Architected Framework     Assess, document and translate goals, objectives, problem statements, etc. to our offshore team and onshore management     Advising on database performance, altering the ETL process, providing SQL transformations, discussing API integration, and deriving business and technical KPIsHelp transition the implemented solution into the hands of the client, including providing documentation the client can use to operate and maintain the solution.     Help NorthBay Solutions with its Continuous Improvement processes to learn from each customer project, including doing project retrospectives and writing up “Lessons Learned”.     Strong Design / Development Experience on Amazon EMR, preferably with Spark (PySpark, Scala)Strong troubleshooting / admin experience with EMR – specific infrastructure (CloudFormation) code, deployment via AWS CLI, and bootstrap actions.     Ability to implement transient infrastructure (e.g. transient EMR clusters) that leverages decoupled storage (S3) and compute. Implement these using reproducible automated mechanisms like AWS CLI scripts, CloudFormation templates, and custom code leveraging AWS SDKs.     Strong experience on one or more MPP Data Warehouse Platforms preferably Amazon EMR (incl. Presto), Amazon Athena, AWS RedShift, PostgreSQL, Teradata or similar Possess in-depth working knowledge and hands-on development experience in building Distributed Big Data Solutions including ingestion, caching, processing, consumption, logging & monitoring     Strong Development Experience on at least one or more event-driven streaming platforms preferably Kinesis, Firehose, Kafka, Spark Streaming, or Apache Flink     Strong Data Orchestration experience using one or more of these tools: AWS Step Functions, Lambda, AWS Data Pipeline, AWS Glue orchestration, Apache Airflow, Luigi or related     Strong understanding and experience with Cloud Storage infrastructure, and operationalizing AWS-based storage services & solutions preferably S3 or related     Strong technical communication skills and ability to engage a variety of business and technical audiences explaining features, metrics of Big Data technologies based on experience with previous solutions     Strong Understanding of at least one or more Cluster Managers (YARN, Hive, Kubernates, Pig, etc)    Strong Data Cataloging experience preferably using AWS Glue or Other     Strong Development Experience on at least one NoSQL OR Document databases     Experience on at least one or More Ingestion Integration tools Like Apache NIFI or Streamset or related     Strong Development Experience on at least one Caching Tool like Amazon Elasticache (with Redis or Memcached) or Lucene     Strong Understanding and experience in Big Data Audit Logging and Monitoring solutions like AWS CloudTrail and CloudWatch.    5+ years of AWS Solutions implementation, professional services experience, prefer Data Analytics space.     A passion for exploring data and extracting valuable insights.     Proven analytical, problem solving, and troubleshooting expertise.     Proficiency in SQL, preferably across a number of dialects (we commonly write MySQL, PostgreSQL, Redshift, SQL Server, and Oracle).     Exposure to developer tools/workflow (e.g., git/github, *nix, SSH)Experience optimizing database/query performance.     Experience with AWS ecosystem (EC2, S3, RDS, Redshift).Experience with business intelligence tools with a physical model (e.g., MicroStrategy, Business Objects, Cognos).Experience with data warehousing.     Exposure to NoSQL-based, SQL-like technologies (e.g., Hive, Pig, Spark SQL/Shark, Impala, BigQuery)    Excellent verbal and written communication skills     Bachelor’s Degree in Computer Science or Equivalent     Minimum five years of Big Data Engineering on AWS experience     AWS Solution Architect     AWS Big data Specialty     Or any Data Centric Certifications "
"business data analyst/ pm, toronto",Randstad Canada,https://ca.linkedin.com/jobs/view/business-data-analyst-pm-toronto-at-randstad-canada-1535393327?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=16&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,
Senior Data Analyst / Consultant,Agoda,https://ca.linkedin.com/jobs/view/senior-data-analyst-consultant-at-agoda-1483707787?refId=efdab159-eff5-40db-9f96-5a2e3d441331&position=17&pageNum=7&trk=guest_job_search_job-result-card_result-card_full-click,"Take ownership of analytical projects end to end from extracting and exploring data, generating hypothesis, building a structured analysis, and rigorously evaluating methods and results   Provide analytical and valuable insights for decision-making support for key projects and management   Work closely with various business functions to identify opportunities, analyze, and interpret trends or patterns in complex data sets using different techniques and tools such as R studio or Tableau   Communicate findings and propose actionable recommendations to address the problems   Bachelor Degree in Computer Science/Statistics/Math or Engineering   At least 3-years in Data Analyst position or otherwise in projects involving big data   Proficient in business intelligence tools and data warehouse i.e. SQL, Tableau and MS Excel   Must be data savvy and love crunching numbers   Strong analytical and statistical analysis skills in order to extract insights and recommendations   Fluent in English with strong communication skills (both written and verbal)   Experience in R studio, data modeling, hypothesis testing is a plus"
Senior Data Science Engineer,Manulife,https://ca.linkedin.com/jobs/view/senior-data-science-engineer-at-manulife-1579274028?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=1&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Support data delivery from both internal and external sources; collaborate with data experts & data sourcing resources.   Thorough understanding of and experience with data gathering, storing, and retrieval methods.   Tactical support of data validation, consolidation and cleansing processes.   Work with Data Scientists to transform business requests into valued works including: data integration, data mapping, modeling and meta-data design; data aggregation; data cleansing & other data-related processes.   Build pipelines to improve turnaround time on data availability and increase efficiencies of machine learning model building and deployment processes.   Responsible for understanding the systems & data environment for Global Wealth and Asset Management   Work closely with Investment Operations, Chief Analytics Officer, and IS teams to collaboratively assess, understand, improve and deliver rich data content for analysis.   Research & use technical documentation in order to gain a holistic understanding of the data domain.   Assist in the development of conceptual/logical data models with appropriate business contexts.   Support researching data structure and/or data content issues and the design of effective data solutions.   Document current and future business processes.   Deliver ad-hoc reporting in order to support Global Wealth and Asset Management initiatives and advanced analytics projects.   Deliver reporting & visualizations to effectively communicate insights to non-technical business users for a variety of audiences.   Employ analytical, conceptual, and creative thinking skills to solve data analysis problems and get business results.   University degree in quantitative based field (e.g. Math, Physics, Engineering, Computer Science).   5+ year of data engineering experience preferred.   Advanced experience with multidimensional and relational databases.   Familiarity with cloud technologies, IaaS, PaaS, SaaS, DaaS.   Advanced experience in Python, SQL, R, .net.   Advanced experience in data management and working with ETL tools.   Advanced experience working with internal business clients to develop analytical insights.   Experience providing data analysis to support management decisions.   General knowledge of data analytics theory & application.   Experience with analytics tools and visualization tools a plus.   Financial services experience desired   Inspires and motivates others.   Role model of ethics and integrity who builds a culture of respect.   Highly effective change agent who embraces change and leads change management.   Provides courageous advice.   Results oriented; highly focused on accountability.   Ability to handle multiple partners   Demonstrates a commitment to delivering excellent service balanced with appropriate risk management.   Strategic perspective.   Highly collaborative working style."
"Volunteer: Shark Research, Education + Conservation Project in South Africa",Global Nomadic,https://ca.linkedin.com/jobs/view/volunteer-shark-research-education-%2B-conservation-project-in-south-africa-at-global-nomadic-1344893408?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=2&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Gain knowledge and practical skills in shark research, education and conservation.   Ideal for volunteers with an interest in science, getting their feet wet, assisting with a dive centre and spreading the word about shark conservation, and there is also a chance to learn how to get GoPro footage of sharks under the water.   Cage-less snorkeling with upto 5 species of shark   Keywords: Scuba, free diving , shark conservation, SCUBA centre, science, research, education"
Hadoop Developer,Roevin,https://ca.linkedin.com/jobs/view/hadoop-developer-at-roevin-1591807365?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=3&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Supporting the data scientist community to create re-useable code templates that can be used by other data scientists and/or    Taking the data scientist’s code and making it “production ready”    Perform in-depth requirement analysis    Bachelor’s degree/Diploma in Computer Science, Engineering, etc.    Hands-on experience with Hortonworks    Full knowledge on Hadoop architecture and HDFS is a must (Scala, Hive, Spark)    Ability to parse raw unstructured data and perform data ingestion using NiFi    Working knowledge of Python or Java    Shell scripting experience    API development experience is an asset    Kafka development experience is an asset    Ability to work with minimal supervision"
Senior Data Scientist - Claims Analytics Centre of Excellence,Manulife,https://ca.linkedin.com/jobs/view/senior-data-scientist-claims-analytics-centre-of-excellence-at-manulife-1550085855?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=4&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Lead and deliver advanced analytics solutions through consulting type engagements with internal business clients   Perform requirement analysis with business area (understand business problem and generate hypotheses)   Build, test, deploy and iteratively improve models   Calculate model impact/Return on Investment and communicate value to partners   Implement measurement and documentation framework against all project work   Generate insights for businesses so that they clearly recognize the quantifiable value considering trade-offs between and among choices   Enable those who are not professional data analysts to effectively interpret data through effective communication of results and analytics outcomes   Provide thought leadership around analytics methodology, tools, and measurement   Innovate and find creative ways to source data to support modeling efforts, using structured and unstructured data using Big Data technologies   Peer review other Data Scientists’ work   Owns and delivers projects of diverse scope.   Oversees the work of more junior data scientists.   Independently provides analysis on datasets of significant complexity   Recommends implementable solutions to (or in collaboration with) business partners   Ph.D. or Masters Degree in a quantitative discipline (Statistics, Applied Mathematics, Computer Science, etc.)   5+ plus years developing of probabilistic models, data mining, and machine learning algorithms including real world experience in model development validation and testing and implementation   Expert in data analysis using Python, R, SQL or SAS   Strong data engineering, and data management expertise with proven data transformation and manipulation experience   Knowledge of Knowledge of big data system, NoSQL systems, Hadoop/map-reduce, Spark, Hbase, etc   Strong commitment to organizational success and team work   Proven ability to exchange ideas and convey complex information clearly and concisely   Experience in sales, distribution, and/or marketing modeling desirable - financial services industry experience preferred   Inspires and motivates others.   Role model of ethics and integrity who builds a culture of respect.   Highly effective change agent who embraces change and leads change management.   Provides courageous advice.   Results oriented; highly focused on accountability.   Ability to handle multiple partners   Demonstrates a commitment to delivering excellent service balanced with appropriate risk management.   Strategic perspective.   Highly collaborative working style."
"Tester (Data, Big Data. SQL / ETL)",Alquemy Search & Consulting,https://ca.linkedin.com/jobs/view/tester-data-big-data-sql-etl-at-alquemy-search-consulting-1538157845?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=5&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," End to end testing    Tools such as unix scripts, hive, SQL    QA project work with reporting/ETL based initiatives    Conduct packages testing and schema testing    - Verify data completeness and transformation rules    - Test referential relations and integrity of data    - Write technical reports of located data errors and recommend solutions    - Process data for testing and analytics after mitigation of data errors    - Enhance/Implemented in-house automated testing scripts   Conducted packagestesting and schema testing.   Verified data completeness and transformation rules.   Testedreferential relations and integrities of data.   Wrote technical reports of located data errors with recommended solutions.   Processed data for testing and analytics after mitigation of data errors."
SITE RELIABILITY ENGINEER (DIGITAL AND DATA SCIENCE),The Globe and Mail,https://ca.linkedin.com/jobs/view/site-reliability-engineer-digital-and-data-science-at-the-globe-and-mail-1566440552?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=6&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Collaborate with Engineers to create a continuous delivery environment and processes   Manage and maintain product platform (Kubernetes cluster)   Instrument and monitor the health and availability of services, with fault detection, alerting, triage and recovery (automated and manual)   Crafting automated installation for our containerized data pipeline   Exploring ways to improve the cost-efficiency of our cloud infrastructure   Improve the Jenkins build pipeline (CI/CD)   Engineering better ways to monitor our infrastructure   Containerizing new data pipeline components via Docker   Implementing automated integration tests   Must have experience with Docker deployments and managing Kubernetes Control Plane    Must have experience with Terraform and Helm Charts for templating the deployments   Experience in shell script and any Unix-based operating system   Experience with any build tools, i.e. Maven, Gradle, SBT, NPM   Solid understanding of computer networking, i.e. subnets, routes, IPs and ports   Experience with securing distributed systems. You understand the purpose of reasonable security techniques and the tradeoff with operational efficiency.   Experience with Prometheus and Jenkins   Capability operating a high load data pipeline and exposure to technologies such as Kafka, Kinesis, Spark, S3 and Redshift   Solid understanding of large system design, streaming big data and performance trade-offs   Demonstrated expertise in cloud computing, preferably AWS    3+ years of experience in software development and/or platform reliability engineering    Bachelor’s/Master’s degree in computer science, or a related field   Strong communication, verbal and written skills   A capacity for constant learning from both success and failure, remaining open to change and continuous improvement"
Int Big Data Developer working with UNIX/Linux and SQL to consume new data sources with Big Data technology for Security Master Financial Data -12657,S.i. Systems,https://ca.linkedin.com/jobs/view/int-big-data-developer-working-with-unix-linux-and-sql-to-consume-new-data-sources-with-big-data-technology-for-security-master-financial-data-12657-at-s-i-systems-1463458864?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=7&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click, Business group: The GWRT Data management group ensures data sources are consumed in new feeds as the bank continues to move toward Cloud and Big Data technologies.    Project: This project will focus on Consuming new data sources with Big Data technology for Security Master Financial Data with Acid Controls within the Capital Markets domain.    Reason for request: Project    The successful candidate will have the opportunity to work with newer technology within the bank as it continues to transform the way data is reviewed.   1 + years’ hands on experience as a  Big Data Developer  working with Big Data tools:  Apache Nifi or Kafka  within  Banking/FI   1 + years’ hands on experience with  Security Controls  for Vendor Framework    5 + years’ experience with  Unix and Shell Scripting     5 + years’ experience with  Linux or Solaris    5 + years’ experience writing  SQL Queries     Recent Capital Markets projects within Security Master Data is a plus    Canadian Securities Course (CSC) is a plus    Experience with Acid Control or Golden Source is a plus 
Programmer/Developer - Big Data Developer,Capgemini,https://ca.linkedin.com/jobs/view/programmer-developer-big-data-developer-at-capgemini-1489947892?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=8&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Qualifications: 1-3 years of experience, Bachelor’s Degree.    Develops program logic for new applications or analyzes and modifies logic in existing applications    Codes, tests, debugs, documents, implements and maintains software applications    Analyzes requirements, and maintains, tests and integrates application components    Ensures that system improvements are successfully implemented    Should have progressing skills in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.    Should have baseline skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design.""   Overall 1-2 years of IT experience. Especially on Big Data/Hadoop technologies   Develops scripts for various use cases to be implemented on big data ecosystem   Understand the high-level design and translates that in executable code   Designs and performs unit testing   Participates in peer review   Good knowledge of best practices in architecture, design patterns   Should have good communication and should be able to report status related to his/her own work.   Minimum 1 year of hands-on experience in ETL Development preferably with Informatica   Proficient in Spark SQL, Python, big data application development.   Experience working with distributed Big Data tools such as MapReduce/Hadoop, Storm, Hive, Flume, HBase is an asset   Unit Testing ETL programs in accordance with quality policy   Self-starter, with excellent communication to both business and technical audience   Ability to work under pressure, often in a self-supervised capacity    Qualifications: 1 – 3 years experience, Bachelor’s Degree.    Develops program logic for new applications or analyzes and modifies logic in existing applications    Codes, tests, debugs, documents, implements and maintains software applications    Analyzes requirements, and maintains, tests and integrates application components    Ensures that system improvements are successfully implemented    Should have progressing skills in Software Engineering Techniques, Software Engineering Architecture, Software Engineering Lifecycle and Data Management.    Should have baseline skills on Business Analysis, Business Knowledge, Software Engineering Leadership, Architecture Knowledge and Technical Solution Design."
"Business Data Analyst, Audience Segmentation",CBC/Radio-Canada,https://ca.linkedin.com/jobs/view/business-data-analyst-audience-segmentation-at-cbc-radio-canada-1562888480?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=9&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Creating segments in demand.   Analyzing data to suggest segment opportunities.   Researching and identifying new data sources.   Working with the development team to capture data from all sources.   Organizing data in a way that makes sense for the revenue group.   Deliver insights. You will deliver key findings that help drive Media Solutions' decision making, optimization and prioritization. You will collaborate across teams to develop measurement strategies, learning agendas and roadmaps.   Transform data. You will apply your expertise and use tools to understand the quality of data collection and convert the raw data into consumable analytics for data modelling, machine learning and data mining.   Act as a Business Analyst. You will work across teams with internal stakeholders to understand business objectives and priorities, define data strategy and develop project scope for targeted audience advertising. You will generate and maintain documentation for implementation projects, process and tools.   Execute analyses. You will manage and deliver advertising performance analysis, platform analytics, customer segmentation, performance forecasting, ROI modelling, lifetime value analysis, cross channel analysis, media mix analysis and brand research   Guide the development of daily, weekly, monthly, and seasonal reporting/scorecards to monitor the health of the initiatives, audience retention and acquisition and to share trends, business insights, and recommendations with stakeholders throughout the organization.   Create and translate. You will simplify complicated data scenarios into compelling and straightforward stories for non-data-savvy stakeholders.   Shape DMP roadmap. You will contribute ideas for further expanding and applying the DMP and data in general at CBC/Radio-Canada.   The education. You have a post-secondary degree in e-Commerce, Business Intelligence or Marketing.   The languages. You are fluent in English and have a working knowledge of French.   The expertise. You have 3+ years progressive experience in a deadline driven media or agency environment. You have an in-depth understanding of digital platforms, the advertising industry, and the categorization of content to create audience segments. You are an effective change agent with the ability to envision multiple paths forward.   The knowledge. You are acutely aware of the impact of data analytics on business driven decisions. You can identify opportunities for testing segments and generate reports looking at segment overlaps, affinity scores, trends, advertising effectiveness.   The technical toolkit. You have hands-on experience using: AdOps technologies, ideally Google AdManager. A DMP such as Lotame and DMP use cases. HTTP to inspect code and use proxies to analyze calls. Diving into 1st and 3rd party cookies. Basic Information Architecture skills, especially around taxonomies.   The drive. You thrive in an autonomous and ambiguous role where you have the freedom to define what you do. You are curious with an ability to dig for insights, see the big picture and keep up with industry changes   The analytical skills. You are a strategic thinker and can respond quickly to critical circumstances. You can balance multiple projects simultaneously and execute decisions independently.   The relationship building finesse. You can nurture strong two-way relationships with clients, peers, partners and external technological vendors. You thrive in a collaborative environment.   The communication skills. You are skilled at presenting ideas to clients, sales and management. You know how to listen and you understand perspectives."
Data Science Team Lead,Loblaw Digital,https://ca.linkedin.com/jobs/view/data-science-team-lead-at-loblaw-digital-1563307978?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=10&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,
RF Engineer/Design Specialist (Data Analytics),TELUS,https://ca.linkedin.com/jobs/view/rf-engineer-design-specialist-data-analytics-at-telus-1393321836?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=11&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Apply your data exploration and manipulation skills to store wireless network data into a useful layout (via ETL, map-reduce, cleanse, feature engineer, etc.). Implement data collection, and storage architectures to support our big data initiatives and data-driven insights.   Apply your data analytics skills in order to perform proof of concepts/prototyping and gain insights from the data (via machine learning, computational statistical analysis, etc.). Create wireless optimization models, platforms and insights for the engineering stakeholders. Bring the science of optimizing a wireless network to new levels.   Apply your data presentation skills in order to make insights available in meaningful ways to key stakeholders (via API, Tableau, web apps, etc.). Understand RF engineering requirements and provide data analytics and web applications to support their work.   Provide expertise in software engineering best practices, insights and guidelines to promote sustainable innovation. Keep up-to-date with data science and wireless technologies.   Acknowledged for your 3+ years of software development experience   Valued for your strong problem solving, big data analytical and mathematical skills   Commended for your passion for automation, data science and machine learning   Recognized for your experience with database design and development: MySQL, SQL Server, Oracle, Hadoop, SPLUNK, Alteryx, Tableau   Skilled in some of the following languages: C++, Java, Structured Query Language (SQL), Python, R, Hypertext Markup Language (HTML), Extensible Markup Language (XML) & JavaScript Object Notation (JSON)   Regarded for your experience with JavaScript frameworks like JQuery, AngularJS, React or others   With a Bachelor’s degree in Computer Science or Engineering   Full stack software development experience   2+ years of experience in the telecom industry for basic understanding of wireless network KPIs, mobile telecommunications technologies, HSPA/LTE/5G   Master’s degree in Computer Science or Engineering"
"Senior Data Scientist - Python, Spark",Workbridge Associates,https://ca.linkedin.com/jobs/view/senior-data-scientist-python-spark-at-workbridge-associates-909944537?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=12&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Experience modeling data and building machine learning applications   Production Python and Spark   Object oriented classification   Bachelor’s degree in Math, Computer Science or Engineering (or related)   100% Python and Spark   80% Hands On   20% Team Collaboration   Competitive Salary: Up to $110K/year, DOE   Statutory Vacation   Holiday Pay   Innovative projects   Team based work   Medical, Dental, Vison   Workbridge Toronto - OSD"
CIND 119 Introduction to Big Data Hybrid online and M,Ryerson University,https://ca.linkedin.com/jobs/view/cind-119-introduction-to-big-data-hybrid-online-and-m-at-ryerson-university-1550932932?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=13&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Applicants must have a PhD (or near completion) in Computer Science or a related discipline.    Applicants must have experience in Big Data and Analytics applications.    Applicants must be experienced with or, before course startup, be willing to complete accelerated training in D2L Brightspace (including creation of discussion forums, tests, assignments, chat rooms) and the content management system (Ektron) to edit and modify course content when required.    Applicants must demonstrate their knowledge of best practices for the delivery and management of online courses as adopted by The Chang School, including, but not limited to    Applicants must demonstrate proficiency in all aspects of personal computers that are relevant to this course, including document creation, file management, internet research, and communications, and must have access to the appropriate technology.   a commitment to deliver the prescribed curriculum   demonstrated ability to apply required instructional techniques; and the ability to create a positive learning environment for adults   pedagogy for diverse populations   course management   academic advising   understanding and respect for human rights and diversity   commitment to positive interpersonal skills   Applicants must have a commitment to professional collegial life."
Data Analyst,Jobspring Partners,https://ca.linkedin.com/jobs/view/data-analyst-at-jobspring-partners-1561489112?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=14&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Handling large data sets   Being able to tell a story with data   Python and SQL skills   Strong in mathematics and stats   Primarily Data analyst responsibilities   80% Hands On   20% Team Collaboration   Competitive Salary: Up to $105,000/year, DOE   3 weeks paid vacation   Statutory Vacation   Holiday Pay"
"Data Scientist, Winter 2020 Co-op Opportunities",eFinancialCareers,https://ca.linkedin.com/jobs/view/data-scientist-winter-2020-co-op-opportunities-at-efinancialcareers-1546327018?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=15&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,
Sr Manager - Data Science,BMO Financial Group,https://ca.linkedin.com/jobs/view/sr-manager-data-science-at-bmo-financial-group-1537150533?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=16&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Manages people and leads a team capable of delivering the desired business results.   Influences and negotiates to achieve business objectives.   Identifies emerging issues and trends to inform decision-making.   Provides strategic input into business decisions as a trusted advisor.   Makes recommendations to senior leaders on strategy and new initiatives, based on an in-depth understanding of the business/group.   Acts as a subject matter expert on relevant regulations and policies.     Networks with industry contacts to gain competitive insights and best practices.   Leads discovery process with stakeholders to identify business requirements and expected outcome and to select relevant sources of data/information.   Manages resources and leads the execution of strategic initiatives to deliver on business and financial goals.   Helps determine business priorities and best sequence for execution of business/group strategy.   Develops the business case by identifying needs, analysing potential options and assessing expected return on investment.   Recommends business priorities, advises on resource requirements and develops roadmap for strategic execution.   Makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices.   Structures loosely defined and complex business problems; determines new experimentation methods and statistical techniques to design solutions.   Acts as the prime subject matter expert for internal/external stakeholders.   Identifies/creates the appropriate algorithm to discover patterns.   Drives analytics innovation; poses open-ended questions, explores new ideas, and chooses appropriate techniques for solving business problems.   Oversees the development and delivery of tools and training for data and analytics.   Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.   Leads change management programs of varying scope and type, including readiness assessments, planning, stakeholder management, execution, evaluation and sustainment of initiatives.   Leads the development of the communication strategy focusing on positively influencing or changing behaviour.   Applies innovative and best practices to advanced analytics services to ensure high quality standards.   Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.   Designs and implements policies and procedures around new data sets to ensure data quality, consistency, repeatability, and accuracy of insights.   Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.    Provides advice and guidance to assigned business/group on implementation of analytical solutions.   Works with stakeholders to identify the business requirements, understand the distinct problems, and the expected outcome and models and frames business scenarios which impact critical business processes and/or decisions.   Works with various data owners to discover and select available data sources from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.   Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).   Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.    Summarizes statistical findings and draws conclusions and presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.   Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.   Performs experimental design approaches to validate finding or test hypotheses.   Uses the appropriate algorithms to discover patterns.   Builds effective relationships with internal/external stakeholders. Ensures alignment between stakeholders.   Supports development of tools and delivers training for data analytics and AI.   Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.   Leads/participates in the design, implementation and management of core business/group processes.   Operates at a group/enterprise-wide level and serves as a specialist resource to senior leaders and stakeholders.   Applies expertise and thinks creatively to address unique or ambiguous situations and to find solutions to problems that can be complex and non-routine.   Implements changes in response to shifting trends.   Broader work or accountabilities may be assigned as needed.    Typically 7+ years of relevant experience and/or certification in related field of study or an equivalent combination of education and experience.   Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience.   In depth experience using machine learning algorithms.   Experience with distributed computing language (e.g. Hive /Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).   Experience with programming languages (e.g. SQL, Python, R,SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).   Seasoned professional with a combination of education, experience and industry knowledge.   Verbal & written communication skills - In-depth /Expert.   Analytical and problem solving skills - In-depth / Expert.   Influence skills - In-depth / Expert.   Collaboration & team skills; with a focus on cross-group collaboration - In-depth / Expert.   Able to manage ambiguity.   Data driven decision making - In-depth / Expert."
Data Analyst (Quality Control) - Toronto,Jam City,https://ca.linkedin.com/jobs/view/data-analyst-quality-control-toronto-at-jam-city-1594214345?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=17&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Unlimited Vacation, Paid Sick Days & Holidays  100% Employee Covered Medical, Dental, Vision Plan Base Plan  Life Insurance, RRSP matching, Flexible Spending Accounts & More  Catered Lunches & Well-stocked Kitchens  Fully catered breakfast, lunch, and snack-filled kitchen  Company Events such as movie night, pub night and more…  You'll be equipped with a high-end laptop, monitor and mobile device  Convenient location in downtown Toronto’s entertainment and technology district  ABOUT THE ROLE  We are currently looking for a   Data Analyst (Quality Control)   to join our Bingo Pop team! You will get the opportunity to work with some of gaming’s top talent, while lending your analytical talents to help us create top-tier mobile games. Our ideal candidate would have a passion for data, the technical knowledge to work across the data pipeline, and the ability to take initiative to improve the quality of our data. Responsibilities  Building reports, dashboards and data visualizations to monitor the health and accuracy of our data.    Monitor the entire data pipeline, proactively identify issues, discrepancies or anomalies.    Create and improve ETL jobs and dashboard scripts, primarily in SQL and Scala.    Constantly validate data to ensure that our product team is working with the correct data, from installs to revenue to game specific metrics such as a new reward type.    Proactively identify discrepancies or anomalies and take ownership in ensuring the problem is fixed.    Debug issues and resolve them, either yourself or by providing detailed information to the appropriate team member, from QA to product to engineering.    Create dashboards, automated reports and alerts to allow developers and QA to easily monitor and quickly identify data quality issues.    Work with product and design to understand new game features and their intent, in order to have the necessary logging to analyze the feature in order to provide actionable insights.    Constantly play the product and monitor KPIs, team and community feedback in order to give context to the data.    Monitor performance and failures in the data pipeline, and understand the priority and resolve or escalate accordingly .    Compare data across multiple sources, such as the app stores and third party analytics providers.    Assist the data engineers in managing billions of rows of data.    Organize and prioritize requests from a variety of stakeholders, including ad-hoc and time sensitive issues. Qualifications  BA/BS degree in Computer Science, Math, Stats or equivalent.    1+ years of experience working with data on a live product.    Strong data analysis skills using SQL and Excel.    Programming experience with R, Python, or Scala.    Ability to create reports and visualize data to provide actionable insights.    Previous startup experience is desirable, comfort in an agile environment.    Strong attention to detail and proven analytical skills.    A curious mindset to identify issues and follow through.    The ability to communicate and present information clearly.    An appetite to learn, grow, and take on increasingly more responsibility.    A strong desire to answer questions that can drive actionable decisions.    Knowledge of the mobile gaming industry in order to provide recommendations on game design.    ABOUT JAM CITY  Jam City is an award-winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience. Led by CEO Chris DeWolfe, former MySpace co-founder and CEO, and COO Josh Yguado, former 20th Century Fox executive, Jam City is the creative powerhouse behind some of the highest-grossing and most enduring mobile games. Jam City’s global franchise Cookie Jam has generated more than half a billion dollars, and Panda Pop has more than 120 million downloads to date. The company also is the go-to studio for Hollywood, having developed immersive, narrative-rich mobile games around iconic entertainment brands. The company’s popular RPG game Harry Potter: Hogwarts Mystery was the #1 game in more than 40 countries at its launch in April 2018. Jam City has nine studios located in Los Angeles (HQ), Berlin, Buenos Aires, Bogotá, Burbank, Cedar Falls, San Diego, San Francisco, and Toronto."
Product Manager - Data Science & Engineering,Shopify,https://ca.linkedin.com/jobs/view/product-manager-data-science-engineering-at-shopify-1377728565?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=18&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Define and evolve the vision of machine learning driven products and machine learning platform across Shopify   Drive product management activities, including: requirements gathering, prioritization, roadmap and strategy planning, product roll-out, product workshops and championing product adoption across Shopify   Communicate with development teams about technical details, understand the implications of certain decisions, and make trade-offs in terms of complexity, depth, and timelines. Participate in conversations when engineers are debating the best way to implement a solution and help your teams more accurately estimate the size of work.   Work with Data Scientists, Developers and other stakeholders/customers to understand their work, their objectives, and their impact on helping the organization achieve their goals.   Create and iterate upon the product roadmap and technical product requirements   Be able to seamlessly distill very technical concepts to business users and vice versa   Prioritize and plan features based on company, and stakeholder, priorities and business values.    Attain internal product-market fit, and widespread product adoption, among data scientists at Shopify   Define and evolve the vision of machine learning driven products and machine learning platform across Shopify   Experience working as a Product Manager, or a Technical Leadership role in Analytics or Data Engineering   Experience shipping products from ideation to launch with clear success metrics to external or internal customers   Manage the expectations of internal, and external, customers by effectively prioritizing, and communicating, your product requirements and vision.    Understand and provide inputs for the trade-offs in launching a product or feature. Collaborate with stakeholders to resolve deadlocks, present feasible options and drive agreement towards a solution. Evangelize your product and be able to effectively drive its adoption across the organization   Ability to understand technical specifications and architectural design docs.   Prior software development experience is key, so that you can facilitate technical product discussion and provide feedback to the technical and architectural design   Understanding of building and productionizing machine learning solutions is a must.    Experience in setting data-driven goals, with objective success metrics, for your projects that you can rally your team behind.   Familiarity with new and upcoming data technologies - including HDFS, Hive, Kafka, Spark, Presto, Docker, Kubernetes, data warehousing solutions, and in-memory databases"
Senior Data Analyst,Rubikloud Technologies,https://ca.linkedin.com/jobs/view/senior-data-analyst-at-rubikloud-technologies-1595577023?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=19&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Liaise between Analytics, Engineering and Data Science teams to support continuous improvement for product analytics including data science models performance and machine learning outputs     Evaluate and measure models’ outputs to ensure client requirements are met     Define and implement metrics and KPIs that will drive business success     Automate internal communication of product and models performance measurement to enable proactive research and improvements     Answer business questions by using appropriate statistical techniques     Support the creation of insights and analysis and their translation into accessible formats     Expertise in SQL, Python a must and hands on experience with cloud infrastructure preferred     Strong analytical and problem solving skills     Bachelor’s degree in any quantitative field or related experience in analytics     Excellent communication skills, ability to clearly explain technical terms to non-technical audience     Experience in retail, e-commerce, or supply chain would be considered an asset "
Senior Big Data Developer,TD,https://ca.linkedin.com/jobs/view/senior-big-data-developer-at-td-1557989413?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=20&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Transform business requirements and research into winning delivery solutions that meet performance goals.   Design and develop Big Data solution and Restful API layer to provide various functions for front-end.    Perform systems administration: monitor, configure, back-up, authenticate, tune.   Aim for best practice, defect-free programming, create and maintain quality code, provide support during testing cycles and post-production deployment, engage in peer code reviews.   Identify issues, develop and maintain processes that address and resolve them, (and be sure to communicate/alert stakeholders as needed).   Configure and develop custom components with technology partners (analysts, developers, designers etc.) to meet requirements and goals.   Ensure applications are free of common coding vulnerabilities (and follow standard security practices).   Complete unit and integration testing per standards and design specs.   Respect TD's technology delivery practices and standards, project management disciplines.   Apply and share technical expertise during incident management life cycle (e.g. analyzes reports and outages, perform impact assessments, facilitate stakeholder communication).   Demonstrate high level of proactivity and strong ownership.   Communicate effectively both inside and outside the team to achieve results and build strong relationships.   Develop a good understanding of intraday liquidity management in the Banking business.   Undergraduate Degree or Technical Certificate.   5-7 years of experience in Java.   5-7 years of experience with Hadoop technologies like Spark, Hive, HBase and/or HDFS.   Experience with building REST API.   Experience with MQ technologies like IBM MQ, Kafka, Rabbit MQ etc. would be a plus.   Experience with Git, Jira, Confluence.   Advanced and extensive knowledge of the business (or organization), technical environment, standards, processes, procedures, programming languages and operating systems.   Solid understanding of SDLC.   Readiness and motivation to address and resolve highly complex and multifaceted development-related issues, often independently.   Strength in coaching and advising clients, partners and project teams.   Commitment to and belief in the quality of your deliverables.   Strong verbal, written, presentation & communication skills.   Proactive, organized, excellent analytical and problem-solving skills.   Works well independently, as well as, within a team.   Inspire a positive work environment and help champion quality, innovation, teamwork and service to the business.   Learn voraciously, stretch your thinking, "
Data Scientist,StaffLink,https://ca.linkedin.com/jobs/view/data-scientist-at-stafflink-1493383582?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=21&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Take a role in shaping the big-data architecture and infrastructure that will enable future technologies and underpin our digital transformation   Choose your own destiny and assist with designing and implementing our data science platform   Analyze, interpret and use machine learning and data mining algorithms on the enormous amount of behavioral and transactional data   Analyze performance statistics at an extremely detailed level and present insights and recommendations to teammates   Recommend new experiments supported by your analysis and research   Dissect customer and operations data to identify opportunities to increase revenues, guest satisfaction and operational improvements   Write code to implement your experiments   Work closely with analysts, engineers and the business to bring your experiments to life   Solve a wide variety of complex problems as they arise that will often require significant analysis of our data, research and deep thinking   Lead brainstorming sessions with your teammates to determine opportunities for improvement and experiments   Strong familiarity with various machine learning & statistical techniques   Self-motivated, strong sense of ownership, and adaptable in a fast-paced environment   Ability to initiate and drive projects to completion with minimal guidance   Strong written and verbal communication skills to describe results of analyses in a clear and effective manner   Proficiency in Python or R or other data manipulation or analysis languages; software development experience is a plus   Experience working with relational data via SQL; experience with NoSQL and big data technologies such as MongoDB, Spark and Hadoop a plus   Ability to work in both Windows and *nix environments   Experience in retail and restaurant analytics is a bonus   Experience using and implementing visualization tools like D3, Tableau or Qlikview is a bonus"
5000 - Amazon EMR & Big Data Solutions Architect,NorthBay Solutions,https://ca.linkedin.com/jobs/view/5000-amazon-emr-big-data-solutions-architect-at-northbay-solutions-1493519135?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=22&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Interface with client project sponsors to gather, assess and interpret client needs and requirements   Develop a data model and Data Lake design around stated use cases to capture client’s KPIs and data transformations   Identify one or more relevant AWS services -- especially on Amazon EMR -- and an architecture that can support client workloads/use-cases; evaluate pros/cons among the identified options before arriving at a recommended solution optimal for the client’s needs.    Be able to explain to the client the tradeoffs among the various AWS options, and why the recommended solution(s) and architecture was chosen as an optimal one for the the client’s needs.   Work closely with the client and broader NorthBay Delivery team to implement in Agile fashion the architecture and chosen AWS services using AWS Best Practices and principles from the AWS Well-Architected Framework    Assess, document and translate goals, objectives, problem statements, etc. to our offshore team and onshore management   Advising on database performance, altering the ETL process, providing SQL transformations, discussing API integration, and deriving business and technical KPIsHelp transition the implemented solution into the hands of the client, including providing documentation the client can use to operate and maintain the solution.   Help NorthBay Solutions with its Continuous Improvement processes to learn from each customer project, including doing project retrospectives and writing up “Lessons Learned”.   Strong Design / Development Experience on Amazon EMR, preferably with Spark (PySpark, Scala)Strong troubleshooting / admin experience with EMR – specific infrastructure (CloudFormation) code, deployment via AWS CLI, and bootstrap actions.   Ability to implement transient infrastructure (e.g. transient EMR clusters) that leverages decoupled storage (S3) and compute. Implement these using reproducible automated mechanisms like AWS CLI scripts, CloudFormation templates, and custom code leveraging AWS SDKs.   Strong experience on one or more MPP Data Warehouse Platforms preferably Amazon EMR (incl. Presto), Amazon Athena, AWS RedShift, PostgreSQL, Teradata or similar Possess in-depth working knowledge and hands-on development experience in building Distributed Big Data Solutions including ingestion, caching, processing, consumption, logging & monitoring   Strong Development Experience on at least one or more event-driven streaming platforms preferably Kinesis, Firehose, Kafka, Spark Streaming, or Apache Flink   Strong Data Orchestration experience using one or more of these tools: AWS Step Functions, Lambda, AWS Data Pipeline, AWS Glue orchestration, Apache Airflow, Luigi or related    Strong understanding and experience with Cloud Storage infrastructure, and operationalizing AWS-based storage services & solutions preferably S3 or related   Strong technical communication skills and ability to engage a variety of business and technical audiences explaining features, metrics of Big Data technologies based on experience with previous solutions    Strong Understanding of at least one or more Cluster Managers (YARN, Hive, Kubernates, Pig, etc)   Strong Data Cataloging experience preferably using AWS Glue or Other    Strong Development Experience on at least one NoSQL OR Document databases   Experience on at least one or More Ingestion Integration tools Like Apache NIFI or Streamset or related    Strong Development Experience on at least one Caching Tool like Amazon Elasticache (with Redis or Memcached) or Lucene   Strong Understanding and experience in Big Data Audit Logging and Monitoring solutions like AWS CloudTrail and CloudWatch.   5+ years of AWS Solutions implementation, professional services experience, prefer Data Analytics space.   A passion for exploring data and extracting valuable insights.   Proven analytical, problem solving, and troubleshooting expertise.   Proficiency in SQL, preferably across a number of dialects (we commonly write MySQL, PostgreSQL, Redshift, SQL Server, and Oracle).   Exposure to developer tools/workflow (e.g., git/github, *nix, SSH)Experience optimizing database/query performance.   Experience with AWS ecosystem (EC2, S3, RDS, Redshift).Experience with business intelligence tools with a physical model (e.g., MicroStrategy, Business Objects, Cognos).Experience with data warehousing.   Exposure to NoSQL-based, SQL-like technologies (e.g., Hive, Pig, Spark SQL/Shark, Impala, BigQuery)   Excellent verbal and written communication skills   Bachelor’s Degree in Computer Science or Equivalent   Minimum five years of Big Data Engineering on AWS experience   AWS Solution Architect    AWS Big data Specialty    Or any Data Centric Certifications "
Senior Data Engineer,Michael Page,https://ca.linkedin.com/jobs/view/senior-data-engineer-at-michael-page-1450012108?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=23&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click,"Be a part of one of the most dynamic teams within the organization   Build, Tutor, Lead and Grow   Create and maintain optimal data pipeline architecture,   Assemble large, complex data sets that meet functional / non-functional business requirements.   Build large-scale batch and real-time data pipelines using the latest technologies.   Help drive transformation by continuously looking for ways to automate existing processes and testing and optimize data quality.   Apply design thinking and an agile mindset in working with other engineers, data scientists and business stakeholders to continuously experiment, iterate and deliver on new initiatives.   Leverage best practices in continuous integration and delivery.   Explore new capabilities and technologies to drive innovation.   Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.   Work with data and analytics experts to strive for greater functionality in our data systems.   Experience leveraging big data technologies (one or more of Hadoop, Spark, Kafka, Cassandra, ElasticSearch) to build data products   Knowledgeable about containers and orchestration (e.g. Docker, Kubernetes, Mesos);   Experience building APIs and exposing services through APIs   Experience writing clean and concise code using Java/Scala/Python   Experience with public cloud environments   A passion for simplifying and automating work, making things better, continuous learning, open-ended problems, efficiency and helping others   Knowledgeable about data modeling, data access and data storage techniques.   Understanding of machine learning fundamentals"
Big Data Solution Architect,Mentortech,https://ca.linkedin.com/jobs/view/big-data-solution-architect-at-mentortech-1594163858?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=24&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click, We have a unique hybrid contingent staffing service composed of domestic and international sourcing    We have a 24/7 recruitment cycle due to the fact that Mentor has offices in many different time zones    We work day and night to provide our consultants and employees with best working environment
Analytics Solution Architect,"Hitachi Solutions, Ltd.",https://ca.linkedin.com/jobs/view/analytics-solution-architect-at-hitachi-solutions-ltd-1584031622?refId=23532d83-bc36-4275-bcbb-11a2b5c34e72&position=25&pageNum=8&trk=guest_job_search_job-result-card_result-card_full-click," Hands-on experience with the Azure Data Platform (Data Factory, Data Lake, Data Warehouse, Blob Storage, SQL DB, Analysis Services)    Data quality (profiling, cleansing, enriching)    Data Modeling – including design from conceptual to logical to physical data models    Considered to be an expert in T-SQL    Hands-on experience with MPP database technologies such as Azure SQL DW, Teradata Netezza, etc.    Knowledge of Cap Theorum and Distributed Database Management Systems    Opportunity for a career path into a Data Scientist role if desired    Nice-to-have:    Power BI including DAX    Database migration from legacy systems to new solutions    DevOps    Interpreted languages (i.e. python, C-sharp, Java, Scala, etc.)    Databricks    LogicApps    PowerApps    HDInsight    D365FO / CE experience as it pertains to data extraction    Proven ability to engage customers at all levels to understand customer challenges and needs to develop technical solutions    Experience with leading a project team on one to many projects    Strong delivery experience and application of best practices to deliver complex Analytical solutions for Clients    Proven experience architecting all levels and areas of the solutions    Proven experience of architecting Azure services into a solution platform on Microsoft Azure for Analytics OR a strong level of technical experience on a competing cloud platform (i.e. AWS, GCP) with a desire to grow into an expert role on the Azure platform    Hands on development experience with ELT/ETL using MS SQL Servicer, Oracle or similar RDBMS Platform (minimum 7 years)    Experience or desire to coach, mentor and provide leadership to team members    Familiarity with data visualization tools (e.g. PowerBI, Tableau etc.)    Post-secondary degree/diploma in Business, Computer Science or a related discipline;    Prepared for domestic and US travel as required whilst recognizing the goal is to service local customers whenever possible    Nice-to-have:    Project management experience    Databricks and Spark SQL    Previous Consulting experience"
Senior Data Analyst (Fraud Team) - BKK Office,Agoda,https://ca.linkedin.com/jobs/view/senior-data-analyst-fraud-team-bkk-office-at-agoda-1485292761?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=1&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Apply your expertise in quantitative analysis, data mining, and the presentation of data to understand fraud, how it relates to Agoda’s strategy and products, and how to prevent it.   Build advanced predictive models to understand the impact of specific fraudulent behaviors, trends and patterns.   Work closely with cross-functional teams of data and backend engineers, analysts, user researchers, product managers and designers who are passionate about Agoda’s success   Build and analyze dashboards, reports and key datasets to empower operational and exploratory analysis of fraud.   Understand how user fraud affects other consumers of our data, including insights and feature teams, and work across the data landscape to minimize impact and drive influence wherever possible.   Communicate data-informed insights and recommendations to key stakeholders, engineering and product partners.   Bachelor’s Degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline   Previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made.   Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)   Data visualizations such as Tableau or your weapon of choice.   Knowledge of machine learning algorithms including classifiers, clustering algorithms, and anomaly detection a plus   Strong analytical and statistical analysis skills in order to extract insights and recommendations   Fluent in English with strong communication skills (both written and verbal)"
Intermediate Data Analyst to provide deep technical analysis using Python & R Programming for a Data Management initiative. - Toronto,S.i. Systems,https://ca.linkedin.com/jobs/view/intermediate-data-analyst-to-provide-deep-technical-analysis-using-python-r-programming-for-a-data-management-initiative-toronto-at-s-i-systems-1600395869?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=2&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Working with SME's to understand the data , identify issues and validate it with the SME's.      80% will focus on using R and cleaning the data and putting it into Hadoop, 20% will be tweaking code and cleansing data.       Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.    Conduct ETL, SQL and DB performance tuning, troubleshooting, support, and capacity estimation to ensure highest data quality standards with the business and technical SME’s.    Helps with the process of profiles data and ETL logic for documenting end to end data flow and lineage from capture at source, to storage, to delivery and its business intent at each stage (i.e. capture, transformation, fragmentation, editing)    Profile and analyze source data to determine the best reporting structures to build.    Design and develop ETL pipelines using multiple sources of data in various formats according to business requirements.    Conduct dimensional modelling, metadata management, data cleaning and conforming, and warehouse querying.    Use sound agile development practices (code reviews, testing, etc.) to develop and deliver data products    2+ years’ experience working as a   Data Analyst/Data Engineer      Proficiency with   Python & R Programming       2+ years working within   Hadoop & Hive      Strong proficiency in   SQL      Proficient in a variety of languages including:  Scala, Java, Javascript        Data modelling  and   warehousing   experience would be a plus      API  development experience    Experience working in an   Agile  team environment"
Project Manager - Big Data,Procom,https://ca.linkedin.com/jobs/view/project-manager-big-data-at-procom-1580049281?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=3&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"The general accountabilities of this role include, but are not limited to the following:   Lead the delivery of System Upgrade or Application Development projects or assigned work packages from Initiation to Implementation   Manage multiple project stakeholders from cross-functional teams, as well as interfacing with project leaders, technology specialists, professional staff, vendors and consultants.   Engage executive sponsor to ensure active participation on project initiatives   Effectively manage stakeholder expectations related to project cost, time, and scope of deliverables   Establish effective project oversight and other governance bodies, and engages the correct levels to support the direction for the project   Provide on-going communication to key stakeholders, including the Project Sponsor, Program Manager and Portfolio Director to ensure they are aware of significant changes to the project status in a timely manner   Communicate project summary, status, financials, etc. to appropriate parties involved in the governance of the project   Collaborate with the appropriate partners to ensure required resources are assigned to the project for successful delivery   Assess and ensure that customer experience / stakeholder expectations are appropriately managed   Build consensus and relationships with project team and business   Manage and track cash view of all project financials (forecasts and actuals)   Build and manage project schedule, obtaining input from all project stakeholders to gain buy-in and acceptance of milestones and target completion dates for all project deliverables   Maintain project RAID log, tracking and managing risks, issues, actions and decisions through to completion by owners   Adhere to established project management processes ensuring approved scope deliverables are completed   Oversee scope of the project and collaboratively adjusts scope when necessary, ensuring adherence to established project change management processes   Adhere to enterprise project gating and governance controls to ensure that projects meet all the performance, quality and compliance standards and conforms to appropriate methodology   Strong knowledge of the Project Management Life Cycle (PMLC) utilizing the Project Management Body of Knowledge (PMBOK) by PMI   Solid understanding of the Software Development Life Cycle (SDLC) and how it integrates with the PMLC   Thorough knowledge of project management principles, practices, techniques, and tools   Experience executing projects using different approaches, like Waterfall, Iterative, or Agile   Experience working in a large matrix organization with a mature EPMO governance support structure   Excellent leadership skills, with the ability to lead and inspire a team to perform, maximize the contributions of all team members and communicate effectively, with confidence   Strong collaboration skills to help uncover stakeholder needs and motivations, influence and secure the cooperation of key resources, resolve conflicts and negotiate positive outcomes for the project   Logical and analytical. Comfortable making decisions under pressure. Able to balance the level of data required to make a decision with the importance of the outcome   The ability to understand and learn the dynamics of relationships in an organization to identify decision makers and influencers, and to predict how new events or situations will affect the organization   Resilient under pressure and tight timelines   Adaptable to a variety of situations, individuals or groups. Understands and appreciates different and opposing perspectives   Project Management Professional (PMP) Certification by the Project Management Institute (PMI) is a requirement   Knowledge of productivity and PM tools (MS Office PC software applications - Excel, Word, PowerPoint, Project, Visio)   Relevant university degree or equivalent work experience   Strong Data Background; specific domain expertise related to the data portfolio (e.g. basic knowledge of Data Governance, Database/Business Intelligence, ETL process and data linage etc.)   8-10+ years of relevant project management experience, with at least 5 - 7 years managing Data related Technology projects   Knowledge of and experience working with the Agile methodology is an asset   Experience in the Financial Services sector is an asset   Knowledge of the Clarity PPM application is an asset"
Data Analyst / Data Heavy BSA,Alquemy Search & Consulting,https://ca.linkedin.com/jobs/view/data-analyst-data-heavy-bsa-at-alquemy-search-consulting-1346792785?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=4&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Facilitate discussions with business clients, document business requirements and service level agreements.    Turn business requirements into data model and generate source to target mapping and other technical documentation (data transformations, design and operational support documentation).    Analyze data in Hadoop Big Data environments and structured/semi-structured/ unstructured data from various sources.    Ensure compliance with all applicable data regulations and policies.    Apply a variety of analysis tools to interpret data and identify patterns.    Works with key stakeholders within all business functions to align technology solutions with business strategies    Gathers requirements from business units and translates those to programmers and developers    Demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities    Works on multiple projects as a project team member    Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs         5-7 years of experience as a Data Analyst/ Information Analyst/ Business Systems Analyst required    Must have extensive knowledge and experience with SQL    Nice to have – SAS, experience with Big data/Hadoop technologies    Ability to create business solutions that increase competitive advantage    Ability to exercise good judgment in selecting methods and techniques for obtaining solutions    Project management skills in order to handle diverse projects, often times simultaneously, and meet aggressive deadlines    Excellent problem solving and analytical skills, and be capable of multi-tasking and managing concurrent tasks and initiatives    Ability to solve technical problems/ processes and understand complex details    Ability to increase operating efficiency with produce high quality technical solutions    A high level of interpersonal and verbal communication skills necessary to relate to other people at their systems knowledge level    Ability to analyze complex situations and problems and do the necessary research using multiple sources of information to arrive at innovative solutions"
USER EXPERIENCE DESIGNER (DIGITAL AND DATA SCIENCE),The Globe and Mail,https://ca.linkedin.com/jobs/view/user-experience-designer-digital-and-data-science-at-the-globe-and-mail-1573048326?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=5&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Create and own a well thought-out design system and cohesive product UI for our web applications that can scale as the company grows.   Work within a very talented team to prototype design patterns and user journeys that answer the needs of our growing clientele.   Evaluate all qualitative and quantitative research and identify where and how to optimize design patterns to provide an engaging and enjoyable user experience.   Share your great work and your learnings internally and externally, growing your professional self by teaching others.   A strong desire to do innovative, ground-breaking, and impactful work.   A positive attitude that embraces diversity in the workplace.   A history of championing best practices and collaborating with your peers.   A track record of demonstrable user experience improvements that you have made to responsive websites   Comfortable facilitating meetings and explaining abstract ideas in presentations.   A strong understanding of data analytics and a proven ability in translating both qualitative and quantitative improvements to the user experience.   Open-minded and a mature willingness to improve your skill set and work through constructive feedback.   Have worked on web applications which encompass a lot of data visualization.   Have experience extracting user experience behaviour through analytics platforms.   Have experience using design & prototyping tools like Sketch, Figma or Invision.   A good understanding of business practices and strategies in content publishing.   An understanding of Customer Journey Mapping and determining customer's pains and gains.   Have experience working with and delivering successful results within Agile development teams."
Data Analyst - Toronto,Jam City,https://ca.linkedin.com/jobs/view/data-analyst-toronto-at-jam-city-1594197616?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=6&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Unlimited Vacation, Paid Sick Days & Holidays  100% Employee Covered Medical, Dental, Vision Plan Base Plan  Life Insurance, RRSP matching, Flexible Spending Accounts & More  Catered Lunches & Well-stocked Kitchens  Fully catered breakfast, lunch, and snack-filled kitchen  Company Events such as movie night, pub night and more…  You'll be equipped with a high-end laptop, monitor and mobile device  Convenient location in downtown Toronto’s entertainment and technology district  ABOUT THE ROLE  We are currently looking for a   Data Analyst  to join our Bingo Pop team! You will get the opportunity to work with some of gaming’s top talent, while lending your analytical talents to help us create top-tier mobile games. Our ideal candidate would have a strong appetite to learn, inquire and apply their knowledge to give informed proposals on the design of our game. Responsibilities  Building reports, dashboards and data visualizations that are used everyday by team leads and executives.    Developing new metrics and player cohorts to unlock insights into player behavior.    Assisting in the design of new game features.    Helping to manage billions of rows of data along with our data pipeline.    Responding to ad-hoc requests from the executive, financial or marketing teams when insights into our data are needed. Qualifications  BA/BS degree or equivalent.    1+ years of experience working with data on a live product.    Strong data analysis skills using spreadsheets and querying databases.    Previous startup experience is desirable, comfort in an agile environment.    Strong understanding of SQL or Redshift and proficiency in data visualization.    Strong attention to detail and proven analytical skills.    The ability to communicate and present information clearly.    An appetite to learn, grow, and take on increasingly more responsibility.    A strong desire to answer questions that can drive actionable decisions.    Knowledge of the mobile gaming industry in order to provide recommendations on game design.  NICE TO HAVE  Experience working on a free to play mobile game.    ABOUT JAM CITY  Jam City is a leader in mobile entertainment, providing unique and deeply engaging games that appeal to broad global audiences. Jam City was founded in 2009 by MySpace co-founder and CEO Chris DeWolfe and former 20th Century Fox executive Josh Yguado. Jam City is the creative powerhouse behind some of the highest grossing and most enduring social gaming franchises for mobile, including Cookie Jam (Facebook “Game of the Year” winner) and Panda Pop. Jam City is the go-to studio for Hollywood, having developed immersive, narrative-rich mobile games around iconic entertainment brands including Harry Potter, Family Guy, and Marvel Avengers. Jam City has eight studios around the globe including Los Angeles (HQ), Burbank, San Francisco, San Diego, Toronto, Bogotá, Berlin, and Buenos Aires. The Jam City team is known for its creative excellence and technological innovation in key areas including storytelling, data science, and audience insights."
Data Science Marketing Team Lead,Loblaw Digital,https://ca.linkedin.com/jobs/view/data-science-marketing-team-lead-at-loblaw-digital-1563308814?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=7&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,
Big Data Developer,Jobspring Partners,https://ca.linkedin.com/jobs/view/big-data-developer-at-jobspring-partners-1486278199?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=8&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Hadoop   Hive   Spark   Scala   Kafka   Machine Learning   Competitive Salary: Up to $120K/year, DOE   Comprehensive benefits package (medical, dental, vision)   Vacation"
Senior Data Scientist,Bank of Montreal,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-bank-of-montreal-1594028590?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=9&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Use case identification:    Expand on the currently identified use cases by partnering with the existing model development groups and the business partners and identify other types of models/applications where ML and AI can add value. This will cover areas such as credit risk, economic capital, AML and market risk.    Structure above identified use cases, define operating model, manage delivery and provide    Data collection and manipulation    Collect data for model development purposes by identifying new candidate variables and predictive variables.    Analyze and summarize data to identify outliers and assess data quality.    Perform data imputation using advanced statistical techniques (multiple imputation, machine learning estimations).    Transform and prepare the data for developing AI models.    Predictive models development    Fully understand the existing version of the models where applicable, their limitations and all the underlying assumptions made.    Use the prepared data to build machine learning predictive models using advanced regression techniques such as random forests, neural networks, boosted trees, deep learning, logistic regressions, NLP etc...    Rank and compare the candidate models to select the best fitting models.    Use statistical tests to ensure the stability and robustness of the candidate models.    Identify new opportunities to apply machine learning in the current model development process.    Reasonableness assessment    Ensure that the models developed make business and intuitive sense by participating in sessions with the model owners, lines of businesses and including their feedback in the model.    Design a process to explain the output of the models on a consistent basis to understand why the models are producing these decisions.    Documentation    Document the process along the way by capturing the details around all assumptions made.    Keep record and detailed notes about the thought process. The models developed will serve as a proof of concept for future ML & AI models in credit risk.    Master or PhD candidate in Engineering, Statistics, Mathematics, Computer Science or related quantitative field.    5-10 years of experience in AML, risk management and machine learning and AI techniques    Familiarity with risk management processes and methodologies, ideally AML    Familiarity with Bank credit instruments and product structures    Familiarity with systems management and data architecture principles    Experience with statistical model development and data mining    Proven experience using SAS, R or Python to build machine learning models    Strong theoretical knowledge of machine learning techniques and advanced regression methods and data imputation techniques    Well-developed relationship management skills.    Excellent influencing and negotiation skills    Strong problem solving skills and capacity to turnaround analysis in short period of time    Comfortable in a challenging environment with tight timelines    Excellent written and verbal communication skills    Capacity to cope with a high degree of ambiguity and change    Ability to work both independently and as part of cross-functional teams    Prior industry experience or academic projects with machine learning and advanced programming is preferred.    High-level of competency with MS Office suite of tools"
Data Engineer,Workbridge Associates,https://ca.linkedin.com/jobs/view/data-engineer-at-workbridge-associates-909943681?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=10&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Degree in a Math/ Technical field   3+ years of working with data mining (clean, train, build)   Excellent problem-solving skills   Experience with Spark, ArcGIS, Postgres GIS   50% Development   50% Analysis   70% Hands On   30% Team Collaboration   Competitive Salary: Up to $140K/year, DOE   Statutory Vacation   Holiday Pay   Workbridge Toronto - OSD"
"Manager, Data Scientist (2 year contract)",eFinancialCareers,https://ca.linkedin.com/jobs/view/manager-data-scientist-2-year-contract-at-efinancialcareers-1546332238?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=11&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,
Machine Learning Scientist,TD,https://ca.linkedin.com/jobs/view/machine-learning-scientist-at-td-1525302291?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=12&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Join a world-class team of machine learning researchers with an extensive track record in both  academia and industry.   Research, develop, and apply new techniques in the intersection of deep learning and personalization to  further advance our industry leading product.   Work with diverse real-life datasets that range from banking transactions, to predictive health  applications, to audio/video consumption.   Collaborate closely with the engineering team in a fast paced startup environment and see your  research deployed in production with very short turnaround.   PhD degree in Computer Science, Statistics, Operations Research, Mathematics or related field.   Strong background in machine learning.   5+ years of research experience with publication record.   Proven track record of applying machine learning to solve real-world problems.   Experience with deep learning and/or collaborative filtering.   Hands on experience in software systems development and SaaS applications.   Experience with one or more Java, Matlab, Scala, Tensorflow and MXNet   Experience using GPUs for accelerated deep learning training   Familiarity with AWS   Entrepreneurial and inclusive culture   Excellent health coverage   Four weeks paid vacation   Catered lunches twice a week over machine learning talks   Opportunities to collaborate with faculty at the Vector Institute"
CIND 719 Big Data Analytics Tools F Hybrid,Ryerson University,https://ca.linkedin.com/jobs/view/cind-719-big-data-analytics-tools-f-hybrid-at-ryerson-university-1550932930?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=13&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Applicants must have a PhD (or near completion) in Computer Science or a related discipline.    Applicants must have experience in Big Data and Analytics applications.    Applicants must be experienced with or, before course startup, be willing to complete accelerated training in D2L Brightspace (including creation of discussion forums, tests, assignments, chat rooms) and the content management system (Ektron) to edit and modify course content when required.    Applicants must demonstrate their knowledge of best practices for the delivery and management of online courses as adopted by The Chang School, including, but not limited to    Applicants must demonstrate proficiency in all aspects of personal computers that are relevant to this course, including document creation, file management, internet research, and communications, and must have access to the appropriate technology.   a commitment to deliver the prescribed curriculum   demonstrated ability to apply required instructional techniques; and the ability to create a positive learning environment for adults   pedagogy for diverse populations   course management   academic advising   understanding and respect for human rights and diversity   commitment to positive interpersonal skills   Applicants must have a commitment to professional collegial life."
Senior Information Technology Business Consultants,Iris Software Inc.,https://ca.linkedin.com/jobs/view/senior-information-technology-business-consultants-at-iris-software-inc-1595614605?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=14&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," The role will lead the quantitative and analytic modelling for the following products: OTC derivatives (Interest rates, equity Derivative, commodity, foreign exchange and CDS.), mortgages, cards and loans.     Exposure to some of the techniques like:Potential exposure, Collateralized Potential Exposure, and Credit loss Projection.     Experience in providing thought leadership AND experience in being part of the risk group think tank in addition to people management and complex project management.     Confer with clients to identify and document requirements     Conduct business and technical studies     Design, develop, integrate and implement information systems business solutions     Provide advice on information systems strategy, policy, management, security and service delivery     The successful candidate should be familiar with banking risk management policy and regulatory requirement.     Professionals should come from Credit Risk background ideally with  Quant Modelling  knowledge. They should have CVA domain expertise in CCAR, Basel and VAR. Background in implementation and testing new features for VAR Calculation Service application module.     Leadership and managerial skills: This includes Strategic thinking, collaborating, problem solving and decision making, planning, meeting management, delegation and communications.     Experience Using Agile methodology (SCRUM) for developing new features for risk application, with each SPRINT lasting for 2-3 weeks. Active Involvement in analysis, specification, design, implementation and testing phases of Software Development Life Cycle (SDLC).     1 0 plus years of Quantitative Risk Management, Capital Markets, & Credit Risk experience     The successful candidate should have experience in managing a diverse and dynamic team consisting of quant professionals located in three to four centers worldwide consisting of data scientist, Machine learning experts.     Expert knowledge and a minimum of 10 years’ experience in Object oriented programming for Capital Markets.     Experience working on distributed system and handling & processing of large scale data(trades, risk, market data etc)     Experience working with in-memory caching solutions (in-house built) or vendor-based products     Able to troubleshoot problems in multiple environments in a stack with diverse technology     Minimum 5 years of experience working and coordinating with diverse global teams consisting of quant developers, data scientist and machine learning experts.     Experience Using Complex algorithms Monte-Carlo simulation, historical simulation for enhancing and developing new features for risk application using relevant technology and language     Experience in two or more programming languages like Python.     Exposure to Big Data technologies/Hadoop technologies.     Knowledge and experience working with Apache Hadoop, Spark, Hive, HBase, Sqoop and/or any related vendor-based big data products such as Pivotal Hawq/Greenplum, Cloudera Impala     Knowledge and experience of working in Python using scientific and data analysis libraries. "
Talent Management Data Analyst,Agoda,https://ca.linkedin.com/jobs/view/talent-management-data-analyst-at-agoda-1592392933?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=15&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Support business initiatives and ensures good coordination and collaboration between the teams in various Agoda’s departments and within the CEG organization to achieve projects milestones and goals   Improve scalability, stability, accuracy, speed and efficiency of our existing data analytic projects and establish projects based on extracted data insight   Work with tech and data teams to identify and build tools to support or automate data analysis/reporting tasks   Understand and report to your team and senior management on business performance   Drive data analysis projects aiming at improving and maintaining operational KPIs such as service-level agreement (SLA) / response time, customer satisfaction (CSAT), net promoter score (NPS), quality of service, productivity KPIs, costs, etc.   Provide efficient and automated regular reporting to management   Analyze issues, identify risks, report accordingly to management, and propose solutions to be implemented in efficient and effective communication   5+ years of experience working as a Data Analyst, strong Business Intelligence/Data Visualization experience preferably in the field of HR   Bachelor’s in a quantitative degree   Experience with BI/reporting software in terms of building dashboards – Tableau in particular   Expert Excel user: ability to understand and build complex spreadsheets; ability to efficiently extract data from large and complex database   Quick learner, proactive/forthcoming attitude, problem-solving aptitude, effective prioritization, attention to detail   Strong “story-teller” that can communicate insights and recommendations effectively   Excellent problem solving and comprehension skills as well as strong business sense   Excellent communication skills: ability to communicate with people of differing levels of seniority and analytical understanding   Project management: able to initiate and drive projects, liaise with stakeholders and manage resources to reach objectives and deliver product   High level of organization: ability to manage multiple, competing priorities and deliver results under tight deadlines and pressure   Excellent communication skills in written and spoken English   Experience working with relational databases (MSSQL, Postgress, MySQL, etc…)    Experience working with SaaS (Workday, Greenhouse.io) platforms and APIs in any programming language (Python, C#, Java, etc.…)   Be part of a dynamic and exciting data-driven multinational team in a successful and fast-growing tech company   A career path will help you to continuously develop your skills   The chance to propose ideas to improve operations based on data and have an impact on the customer experience   Competitive compensation package (relocation support for successful overseas candidates)   International and domestic health insurance   Annual performance bonus"
Intermediate Data Engineer to Build a Fintech within North America's Fastest-growing Private Equity Company,S.i. Systems,https://ca.linkedin.com/jobs/view/intermediate-data-engineer-to-build-a-fintech-within-north-america-s-fastest-growing-private-equity-company-at-s-i-systems-1524421030?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=16&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Working on collecting, storing, processing, and analyzing data sets to support business needs, including the build-out and maintenance of data models   Designing, building, and maintaining the business’s ETL pipeline and data warehouse   Optimizing data warehouse performance to enable visual analytics tools such as Tableau   Applying automation and innovation on data platforms and any new development projects/initiatives aligned to business or organizational strategies;   Collaborating with various technology/business/project teams to understand business data and provide analysis and requirements to ensure the data design/development initiatives are in line with the planned design and standards   3+ years of  data engineering  /  development  experience, designing  data models  and performing data  integration   3+ years of experience in  custom ETL design, data warehousing  implementation and maintenance;   Experience deploying  SQL  databases across various  cloud platforms  (Amazon, Azure, etc.);   Experience within the  financial investment  industry    You have worked at a start-up / technology / private equity firm leading the charge to be more data driven.    Python, Java, SQL skills   Dashboard tools like Tableau    Private equity experience"
"Audit Manager, Audit Analytics - Data Scientist",BMO Financial Group,https://ca.linkedin.com/jobs/view/audit-manager-audit-analytics-data-scientist-at-bmo-financial-group-1554404029?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=17&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Acts as a trusted advisor to assigned business/group.     Influences and negotiates to achieve business objectives.     Recommends and implements solutions based on analysis of issues and implications for the business.     Assists in the development of strategic plans.     Identifies emerging issues and trends to inform decision-making.     Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.     Builds effective relationships with internal/external stakeholders.     Ensures alignment between stakeholders.     Supports data collection, integration, and retention requirements for data.     Develops experimental design approaches to validate findings or test hypotheses.     Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.     Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.     Applies innovative and best practices to advanced analytics services to ensure high quality standards.     Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.     Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.     Provides advice and guidance to assigned business/group on implementation of analytical solutions.     Works with stakeholders to identify the business requirements, understand the distinct problems, and the expected outcome and models and frames business scenarios which impact critical business processes and/or decisions.     Works with various data owners to discover and select available data sources from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.     Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).     Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.     Summarizes statistical findings and draws conclusions and presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.     Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.     Performs experimental design approaches to validate finding or test hypotheses.     Uses the appropriate algorithms to discover patterns.     Builds effective relationships with internal/external stakeholders. Ensures alignment between stakeholders.     Supports development of tools and delivers training for data analytics and AI.     Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.     Leads/participates in the design, implementation and management of core business/group processes.     Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.     Provides specialized consulting, analytical and technical support.     Exercises judgment to identify, diagnose, and solve problems within given rules.     Works independently and regularly handles non-routine situations.     Broader work or accountabilities may be assigned as needed.     Typically between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.     Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience     Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).     Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).     Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms.     Deep knowledge and technical proficiency gained through extensive education and business experience.     Verbal & written communication skills - In-depth.     Collaboration & team skills - In-depth.     Analytical and problem solving skills - In-depth.     Influence skills - In-depth.     Data driven decision making - In-depth "
DIGITAL ANALYTICS IMPLEMENTATION SPECIALIST (DIGITAL AND DATA SCIENCE),The Globe and Mail,https://ca.linkedin.com/jobs/view/digital-analytics-implementation-specialist-digital-and-data-science-at-the-globe-and-mail-1545404147?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=18&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Develop custom JavaScript code for web platforms as well as assist in deploying and testing of this code on 3rd party sites   Prepare a client-side data layer, tracking and SDK implementation guides for websites and mobile applications    Conduct end-to-end data QA on a regular and ad-hoc basis and identify issues with analytics pipeline and tracking   Expert knowledge of JavaScript with knowledge of various browser rendering engines and ability to troubleshoot code on older platforms   Strong understanding of HTML and CSS   Strong SQL skills, including but not limited to PostgreSQL   Proven ability to quickly and efficiently diagnose data issues   Knowledge of version control systems, GIT preferred   3+ years experience implementing web analytics tools such as Snowplow (preferred), Google Analytics, Adobe Analytics or Piwik with proven experience in designing and implementing custom analytics tagging from the ground up   1+ years of experience in web data analytics with experience in preparation of custom reports   Experience with iOS and Android SDKs for mobile platform analytics deployment   Testing experience including network debugging tools and HTTP Proxies   Strong communication skills and collaborative attitude   Familiarity with at least one Tag Management Solution such as Google Tag Manager, Adobe Dynamic Tag Manager, Ensighten, Signal, Tealium or TagMan   Knowledge of Python and Elasticsearch Queries   Experience with automated testing, task runners and module bundlers   Experience with the Command Line/Terminal    Knowledge or experience with Docker   Experience working on diverse Agile teams"
Portfolio Director - Big Data,Procom,https://ca.linkedin.com/jobs/view/portfolio-director-big-data-at-procom-1596874077?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=19&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Manager Upcoming PTO:None    Supplier Call: No - Manager was given the option    Distribute Requisition: Nov 1st    Halting: Nov 5th    Shortlist De-Brief: Nov 5th    Target interview: Nov 6th    Interview de-brief: subsequent to Interviews    Owns successful end-to-end delivery of programs and projects within the portfolio ensure that they deliver the expected business objectives in terms of scope, cost, quality and schedule.    Builds and maintains strong working relationships with all Executive Sponsors and all delivery leads involved in Portfolio delivery    Use negotiation and influencing skills to build consensus amongst diverse stakeholder groups to ensure portfolio deliverables are met.    Build teams with Project Delivery talent and capabilities through effective leadership, coaching, mentoring, on the job experience opportunities and formal training.    Responsible for resolution of issues and risks effectively within the portfolio and if required ensures timely escalation of the issues and risks.    Communicates portfolio status effectively to executive sponsors and stakeholders.    Oversees overall portfolio financials and benefits realization.    Key Leader that works closely with other Portfolio Directors, the Practices & Governance Director and the AVP, CBDC DSS to establish and mature the shared services PMO organization.    Governs the team to ensure they create and maintain comprehensive project management artifacts as required by project governance standards.    Considered as a subject matter expert on practices, procedures and principles of project management.    Outstanding record of Program management success preferably in Big Data & Analytics,    Expert in execution using Agile methodology.    Logical and analytical thinker who can proactively anticipate and recommend solutions to address trouble/issues.    Self Driven and motivated to constantly strive to find innovative ways to simplify the solution, reduce costs and continuously improve.    Solid organizational skills including attention to detail and multi-tasking skills    Excellent written and verbal communication skills    Pro-active in developing and implementing strategies that significantly mitigate delivery risk.    Demonstrates superior inter-personal skills, conflict resolution, and negotiating skills.    10+ years experience in a program delivery role    Certified Agile Coach and Scrum Master preferred    Strong working knowledge of project management techniques and tools including JIRA and Confluence.    Proven ability to lead organizational change management activities on a project.    Experience in a large complex/matrix organization    Demonstrated leadership ability.    Flexible and able to quickly adapt to unfamiliar, ambiguous or changing conditions.    Excellent analytical, problem solving, relationship management skills    Ability to work on multiple concurrent projects as and when required    University degree or equivalent    PMP, PMI-ACP, CSM or CSP designation preferred    Managing and Building Teams    Program Delivery    Banking industry    University degree or equivalent    Big Data & Analytics"
Full Stack Engineer (Big Data),Alquemy Search & Consulting,https://ca.linkedin.com/jobs/view/full-stack-engineer-big-data-at-alquemy-search-consulting-1527399976?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=20&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click," Software design, development, in agile, devops and dynamic environments     Promoting development standards, code reviews, mentoring, knowledge sharing     Product and feature design, scrum story writing     Data Engineering and Management     Product support & troubleshooting     Implement the tools and processes, handling performance, scale, availability, accuracy and monitoring     Liaison with Client to ensure that requirements are correctly interpreted and implemented. Liaison with Testers to ensure that they understand how requirements have been implemented – so that they can be effectively tested.     Participation in regular planning and status meetings. Input to the development process – through the involvement in Sprint reviews and retrospectives. Input into system architecture and design.     Peer code reviews.     3rd line support.     Experienced in Java is must. Java development and design using Java 1.7/1.8. Advanced understanding of core features of Java and when to use them     Sound knowledge on working Unix/Linux Platform     Building microservices and restful api     Experience with time-series/analytics db's such as Elasticsearch or no SQL database.     Exposure to Agile Project methodology but also with exposure to other methodologies (such as Kanban)     Understanding of data modelling techniques using relational and non-relational techniques     Coordination between global teams     Experience on Debugging the Code issues and then publishing the highlighted differences to the development team/Architects"
Data Scientist,Integrate.ai Inc,https://ca.linkedin.com/jobs/view/data-scientist-at-integrate-ai-inc-1568902646?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=21&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Using your data science super-powers to advise clients on everything from use case development to solution design to performance measurement   Collaborating with other Data Scientists on the team to problem-solve and develop best practices   Consistently delivering quality work as a member of our client engagement team, while keeping client love and trust at the forefront of all your work   Principally delivering data ingest for our client data, including cataloguing the data and mapping it to our proprietary data schema   Collaborating with our business team to create polished data visualizations and pull high level business insights from client data   Working closely with our machine learning team in the early stages of statistical/machine learning model development to identify valuable patterns and information in the data   Collaborating with our solutions engineers to translate complex business logic into our proprietary data schema   Supporting solutions engineers to do systems integration work with our clients   Sending feedback to our platform engineering and product teams to develop requirements for our product roadmap - specifically our ingest, structuring, and integration capabilities   5+ years in a lead Data Science role, including experience providing strategic guidance to clients and fellow Data Scientists   An appreciation for the beauty of data. You love a challenge, and you’re excited about bringing a narrative to complex business problems using what you learn from a dataset   Worked directly with clients and understand the importance of prioritizing client needs   A bachelor’s degree in computer science or a related discipline   Strong technical abilities, creative problem solving skills and high adaptability   Extraordinary interpersonal, organization and communications skills   Experience working directly with business users to build reports and answer business questions with data   Experience working with big data structures and ETL tools and other big data technologies (Hadoop/Spark, Hive SQL, etc.) to uncover meaningful business insights   A good understanding of statistical modeling and you’re passionate about deriving insights from large datasets   Programming experience with Python, R, or SAS   Adaptability and interest in working with a dynamic, early stage company"
Big Data Engineer,Jobspring Partners,https://ca.linkedin.com/jobs/view/big-data-engineer-at-jobspring-partners-1486277172?refId=46ede0e2-ac89-4922-b6d3-9a958087201e&position=22&pageNum=9&trk=guest_job_search_job-result-card_result-card_full-click,"Previous experience with Java-/Scala   Working with Scala, Hive, HDFS, Hive, Pig, Akka!   A huge plus is any involvement with AWS, Kubernetes, and DevOps   For more Lead/Architect positions previous experience is required!    A passion for continuous learning of the most cutting edge technologies, and open to learning about Machine Learning is a plus!   100% Big Data Development   60% Hands On   40% team collaboration   Competitive Salary: Up to $150K/year, DOE   Statutory Vacation   Holiday Pay"
"Senior Data Scientist, Natural Language Processing",Ontario Teachers'​ Pension Plan,https://ca.linkedin.com/jobs/view/senior-data-scientist-natural-language-processing-at-ontario-teachers-%E2%80%8B-pension-plan-1576817192?trk=guest_job_details_job-result-card_result-card_full-click,"Maintain, monitor and improve NLP ecosystem: data pipeline, statistical model development and/or business applications   Maintain and further develop and refine existing NLP algorithms with new techniques or alternative data   Develop new Machine Learning algorithms as needed   Analyze and interpret complex sets of structured/un-structured data to identify patterns and potential opportunities   Visualize data, metrics, and patterns to produce insightful analytics and collaborate with business teams on implementation   Assist with Data Engineering activities and data preparation.   Implement best practices related to ML algorithms including model development, validation, monitoring and re-fit   Champion good coding practices: documentation, version control and code review practices   Share/coach/train others in building a well-managed model development practice within the organization   Stay up-to-date with current technology and industry trends   Explore and experiment new techniques, capability and new data sources, and make sound recommendations to business   Share knowledge and learning with broader team   Lead the ongoing management of NLP related systems and models in a matrix management style   Develop positive relationships and demonstrate effective partnership in the analysis and generation of insights   Support the team in delivering key reports, insights, models and visualizations per priorities set by the business   Continuously research and identify improvement opportunities for NLP model/infrastructure, alternative data source, modelling techniques   Decision making on necessary practices, maintenance, required technology and appropriateness of NLP related technology/data use   Bachelor’s degree in a quantitative discipline   Master/PhD degree in a quantitative discipline with data science/statistical modelling focus preferred   Canadian Securities Course or demonstrated equivalent experience is considered an asset   Good coding habits: documentation, version control, code review, etc.   Ability to quickly learn/adopt to new technology and approaches   Ability to independently research on potential solutions from both industry and academic resources   Ability to articulate thoughts / ideas to effectively collaborate with business and IT partners   Strong analytical skills working in a team-based environment   Expert knowledge of mathematical and statistical modelling   Expert knowledge of machine learning applications, data science and other advanced analytic techniques   Particular focus in the areas of Natural Language Processing and related techniques and technologies   Strong knowledge of new AI technologies and industry trends (commercial software and open-sourced solutions)   2+ years of NLP experience and 7+ years of experience in data science/machine learning   Experience in mathematical and statistical model development to support predictive decision making   Proficient programming skills in Python / R /Spark or other open source programming languages and how to leverage related libraries   Proficient SQL skill in mining complex and multi-sourced data environment   Practical NLP model development and maintenance experience is required   Experience with current NLP techniques and libraries in key phrase extraction, topic modelling and sentiment analysis   Experience in both on-premise and cloud computing environment   Analyzing large sets of data for patterns and correlations using visualization tools. E.g. Tableau / Power BI / D3.js   Proficient with Git workflow   Previous experience in Capital Markets is an asset   Pay for performance environment that offers competitive salary and incentives   Numerous opportunities for professional growth and development   Comprehensive employer paid benefits coverage, including a Health Spending Account   Guaranteed retirement income through a defined benefit pension plan   Competitive time off   Discount programs including Edvantage and Perkopolis   Degreed: a digital platform that helps you quickly and easily discover, share, and track ALL kinds of learning resources — from courses to videos to articles and more."
Senior Data Scientist,WW Canada (Formerly Weight Watchers),https://ca.linkedin.com/jobs/view/senior-data-scientist-at-ww-canada-formerly-weight-watchers-1537500887?trk=guest_job_details_job-result-card_result-card_full-click," Partner with stakeholders across the organization to identify high-impact opportunities to leverage our extensive data to better serve our members.     Develop predictive and other machine-learned models to enhance and optimize user engagement and experience.     Perform exploratory and targeted analyses to understand the data, the problem, and to generate insights, such as novel features, that can be fed into our models.     Work with the rest of the team, and with our consumers and partners in dev and product, to implement and ship production-level code.     Explore and assess utility and potential of additional data sources, APIs, and methods (spanning areas such as statistics, deep learning, and natural language processing).     Motivate and mentor other data scientists to grow their skills and careers.     Peer review other data scientists’ contributions.     3+ years of experience building and implementing machine-learned models in industry, ideally dealing with problems relevant to behavior change, community, product, and/or marketing.     Ability to scope and (self-)manage machine learning modeling projects.     Advanced Degree (Ph.D./MS) in data science, statistics, or a related quantitative discipline.     Experience with advanced modeling techniques, such as collaborative filtering and content-based recommenders, matrix factorization, time series analysis, classifiers, natural language processing, and ensemble methods.      Experience in deep learning for images or text (fast.ai, PyTorch, Tensorflow)     Expert knowledge of Python and SQL, or similar industry standard tools used for large-scale data analysis and modeling (e.g. sklearn, gensim, pandas).     Experience with Google Cloud Platform (Dataflow, Beam, BigQuery) and other big data technologies a plus.     Recent experience with a digital company a plus.     Mentor other data scientists     Self-motivated, results oriented, enthusiastic, and a creative thinker.    Competitive compensation and profit sharing plan   Tuition reimbursement and online courses to help you reach your career aspirations   Commuter benefits   Yearly well-being allowance for your physical, financial, social and emotional well-being   Free WW membership for you plus 3 free WW memberships for your friends and 3 for your family   Free fruit, snacks and coffee to get you through your day   Summer Fridays, happy hours, and company outings"
Senior Data Scientist,Amazon,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-amazon-1433695369?trk=guest_job_details_job-result-card_result-card_full-click," Bachelor's degree in Statistics, Engineering, Computer Science, Applied Math, or a related field.    5+ years of experience using SQL, ETL, Tableau, and databases in a business environment with large-scale, complex datasets.    Proficient with data analysis and modeling software such as R.    Proficient with using scripting language such as Python.    Demonstrated ability in data modeling, ETL development, and data warehousing.    Familiarity with statistical models and data mining algorithms    Experience with AWS Big Data technologies: RedShift, S3, Glue, Athena, Data Pipeline.    Strong verbal/written communication and data presentation skills.    Advanced degree in a relevant field.    Experience with Eider, Data Craft, and Sage Maker.    Experience with implementing supervised and unsupervised machine learning models.    Familiarity with Data Science techniques such as clustering, anomaly detection, etc."
Data Scientist,Arobas Personnel,https://ca.linkedin.com/jobs/view/data-scientist-at-arobas-personnel-1529810353?trk=guest_job_details_job-result-card_result-card_full-click,"Effectuer des recherches de pointe pour développer, mettre en œuvre et perfectionner des algorithmes PNL destinés au traitement de texte / langage / parole et à l'analyse des sentiments   Application de techniques quantitatives à de vastes ensembles de données du marché pour obtenir des informations exploitables et les exécuter en temps réel   Collaboration avec des experts internes en exécution de transactions, acquisition de données et recherche quantitative pour créer un moteur de négociation de nouvelle génération   Constituer une équipe d'experts de calibre mondial selon les besoins; s'efforcer d'atteindre des objectifs ambitieux quantifiables à long terme, tout en présentant des réalisations intermédiaires   Être une autorité de premier plan au sein de l'entreprise; rester à la pointe des dernières technologies, des prototypes et être proactif dans les communautés ML   Offrez du mentorat à vos pairs.     Posséder plus de 5 ans d'expérience    Avoir de préférence une expérience dans le secteur financier avec une bonne connaissance des concepts d'investissement   Avoir une compréhension experte des techniques d'apprentissage machine; connaître les paquets comme Tensorflow, Pytorch, Keras, Scikit Learn, Mat-plotlib, XGBoost   Avoir une bonne connaissance de l'apprentissage en profondeur et des algorithmes d'apprentissage machine plus traditionnels   Avoir de l'expérience avec les méthodes d'immersion, d'apprentissage par transfert et d'interprétabilité   Posséder une connaissance pratique de l'informatique en nuage telle qu'AWS et Google Cloud   Avoir la capacité de construire, valider, déployer et surveiller des modèles prédictifs avancés de manière itérative   Posséder d'excellentes compétences en script et en programmation (telles que Python, SQL)   Avoir de l'expérience dans la conduite de projets ML / NLP   Avoir une attitude positive, axée sur l'équipe et de fortes compétences de collaboration   Posséder d'excellentes compétences en rédaction et en communication pour présenter des résultats complets et cohérents   Avoir la capacité de produire des arguments clairs, logiques et convaincants et d'expliquer simplement des idées complexes"
Data Analyst,Metrolinx,https://ca.linkedin.com/jobs/view/data-analyst-at-metrolinx-1573680369?trk=guest_job_details_job-result-card_result-card_full-click,"Develops and implements data management strategies.    Develops and implements data collection systems, including relational databases with retrieval optimized for statistical efficiency, data quality and in support of evidence-based decision making.    Imports, cleans, transforms, validates and models data to improve data quality and ensure data is accurate and relevant and fosters understanding of operational, business and system issues and trends.    Advises on data issues including quality, availability and usability.    Identifies, analyses, and interprets trends or patterns in complex data sets using Data Definition Language or Data Manipulation Language commands for data gathering and analysis activities.    Produces ongoing and ad hoc reports and dashboards that identify issues, provide insight into results and outline recommendations for process improvements to resolve operational, business and system issues.       Presents data in various formats including dashboards, charts, graphs and/or tables.    Builds, designs and maintains online applications, such as data input and data collection screens, to capture and present meaningful information/data for use by management, internal business units and stakeholders for reporting, analysis and presentation purposes in to identify and implementing process improvements.    Develops and maintains a comprehensive and up-to-date knowledge of internal and external data sources relevant to operational, business and systems data to design and build meaningful centralized databases for internal stakeholders to access.      Completion of a University degree in Mathematics, Economics, Computer Science, Information Management, Statistics, or a related discipline, or a combination of education, training and experience deemed equivalent.    Minimum four (4) years’ experience in a Data Analyst or similar role, with a background in analytics, technology, information management, relational database design and development, business intelligence, data mining or statistics.    Knowledge of relational database concepts, database management software and tools, and computer applications including MS Office Excel and SQL queries.    Technical expertise in the use and application of data modelling, database design, development, investigative and data mining methods and techniques.    Data quality assurance processes, methodology and tools, quality assurance testing and implementation methods and practices to ensure the integrity of data and to identify data inefficiencies.    Analytical and problem solving skills to collect, organize, analyze, and disseminate significant amounts of information with strict attention to detail and accuracy.    Critical-thinking skills to identify trends in data and provide insight into results and outline recommendations.    Creativity to determine format of reports and to translate a range of diverse data/information into meaningful reports that support internal and external requirements.    Interpersonal and relationship management skills to liaise with stakeholders and business units to identify/manage data/information requirements.    Verbal and written communication skills to prepare reports, update and brief management; provide information and explanations of a technical nature to a range of internal stakeholders.    Ability to learn new software and tools in an efficient manner.    Experience with development in .NET and XML would be an asset.    Experience developing dashboards with business intelligence tools such as Tableau would be an asset. "
Senior Machine Learning Researcher,Microsoft,https://ca.linkedin.com/jobs/view/senior-machine-learning-researcher-at-microsoft-1449521133?trk=guest_job_details_job-result-card_result-card_full-click,"Master’s or PhD degree in Computer Science or related field.   Expertise in deep learning techniques (RNN’s, CNN’s, GAN’s, reinforcement learning)   Strong Computer Science knowledge and ability to understand and implement complex algorithms   Experience with TensorFlow, Caffe, Torch and/or CNTK   Familiarity with Python research stack (Numpy, Matplotlib, Jupyter, OpenCV) is a plus   Familiarity with C++ is a plus"
Data Scientist,RS Energy Group,https://ca.linkedin.com/jobs/view/data-scientist-at-rs-energy-group-1559470632?trk=guest_job_details_job-result-card_result-card_full-click,"Collaboration and Teamwork-  You thrive in an environment that supports effective team work and collaboration by earning the trust and respect of those around you.   Job Knowledge-  You have the drive to be the best at what you do. RSEG will support your professional growth as well as encourage you to share your knowledge with your team.   Quality of Work-  You are passionate about what you do and every detail counts.   Customer Centric- You prioritize the needs of your internal and external clients. You are constantly thinking “How will this affect the customers I work with?”   Communication-  You recognize that active listening is just as important as clearly communicating your message. This is key to our collaborative and transparent environment.   Respect –  You believe respect is the basis of all relationships both inside and outside of RSEG.   Reliability – You are someone your team can rely on to finish what you start.   Integrity - You are honest and ethical in all of your relationships and decisions   Build products that solve complex business problems that span multiples discipline (economics, physics, engineering, geoscience, mathematics)   Develop prototypes and productize advanced predictive modeling and machine learning tools, including artificial intelligence.   Work together with Data Engineers and Software Developers to evaluate the technical trade-offs of tools to build simple, yet robust, data science pipelines.   Applying machine learning and statistics to solve everyday business problems.   Developing data products using Python (NumPy, pandas, scikit-learn).   Demonstrated ability to conduct independent research utilizing large data sets.   Minimum 3 years related professional experience or equivalent graduate level education developing ML or AI models.   Quantitative background with advanced degrees (Master +) in Statistics, Computer Science, Informatics, Data Science, Mathematics or Operations Research or equivalent experience.   Prior consulting or software engineering experience.   Experience building large scale data science pipelines.   Familiarity with Spark or Dask.   Experience with geospatial or geometric problems.   Implementing optimization methods or deep learning.   Health and dental benefits that start day one with a HCSA/Wellness option   Generous Annual RRSP Matching Program   Maternity top-up benefits   Competitive time off package   Tuition reimbursement   Professional Development (think monetary coverage for things like certifications, professional memberships or tech conferences)   Bi-weekly massages (not kidding!)"
Senior Data Scientist,BCG GAMMA,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-bcg-gamma-1520602497?trk=guest_job_details_job-result-card_result-card_full-click,"Have deep technical and Data Science expertise: The successful candidate will have a wealth of experience with applying advanced analytics to a variety of business situations, such that they can efficiently and effectively advise multiple teams on the best path to uncovering critical insights for clients    Are an autonomous self-starter with a passion for analytics and problem solving. You will help build new Analytics service offerings that grow our portfolio of products and will captures proprietary content, and support the creation of proposal/selling documents    Are comfortable managing engagements, client relationships, and acting as a “thought Leader.”  Strong presence, strong collaborator and leadership skills and ability to operate effectively in a matrix organization are a must    Love building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)    Have significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data; as well as a deep understanding of modern machine learning techniques and their mathematical underpinnings, and are able to translate this into business implications for our clients    Have strong project management skills    Master’s Degree with significant relevant experience providing advanced analytics solutions, or relevant PhD in computer science, applied mathematics, statistics, machine learning, or a related data centric field.    Demonstrated deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues    Strong record of professional accomplishment and leadership    Fluency in at least one scripting language (e.g. Python, R)    Fast-paced, intellectually intense, service-oriented environment    Position is located in Toronto or Montreal    Expect up to 40 - 75% of time spent traveling    Est à l'aise dans la relation avec le client, et a l'ambition de diriger des équipes    Peut retranscrire des résultats ou des processus complexes en visualisations simples et claires    Est capable d'expliquer des concepts complexes de science des données d'une manière simplifiée    Aime construire des solutions et est à l'aise avec les outils de développement modernes et l'écriture de code en équipe (une expérience en développement logiciel ou DevOps est un plus)    Possède une expérience significative en analyse avancée dans diverses situations d’entreprises    A une capacité éprouvée à synthétiser des données complexes ainsi qu'une maîtrise approfondie des techniques modernes d ' apprentissage automatique et de leurs fondements mathématiques, et est en mesure de les traduire en répercussions commerciales pour nos clients    A de fortes compétences en gestion de projet    Master récent en informatique, en mathématiques appliquées, en statistiques, en apprentissage automatique ou dans d’autres disciplines en lien avec les sciences des données, avec des stages ou jusqu’à cinq ans d’expérience professionnelle pertinente dans le secteur des solutions d’analyse avancées    Solide parcours d'activités parascolaires, de réalisations professionnelles et de leadership    Expérience avec les méthodes analytiques de base telles que la modélisation prédictive, la segmentation / le regroupement des clients, l'analyse de réseau, l'optimisation de la chaîne d'approvisionnement, etc.    Maîtrise d'au moins un langage de code (Python ou R)    Un environnement dynamique, intellectuellement intense et orienté service    40 à 75% de déplacement à prévoir "
Chief Data Scientist,[24]7.ai,https://ca.linkedin.com/jobs/view/chief-data-scientist-at-24-7-ai-1532998216?trk=guest_job_details_job-result-card_result-card_full-click,"Lead the Data Sciences teams in the development and delivery of big data, predictive technologies/models with specific focus on Natural Language Processing (NLP), Natural Language Understanding, Conversational Models , Personalization, Speech Recognition, Text, Digital Signal Processing, Data Mining, Sentiment Analysis and Online targeting.   Define and articulate the AI vision, R&D roadmap and develop standardized industry-specific solution components to accelerate our customer delivery time and scale within the vertical.   Incorporate Data Standardization across channels, models and journeys .   Work jointly with products on architecting and developing the next generation conversational platform to allow extension of existing form based chatbot interfaces to fully conversational systems.   Work closely with clients providing strategic leadership and direction, analyzing current metrics and funnels, developing roadmaps for optimization, and improving their KPIs for automation / uplifts.   Responsible for meeting and exceeding financial targets for billable utilization, ACV, and TTR   Responsible for meeting and exceeding client business objectives for optimizing CSAT, NPS, self-service rates, and sales conversion targets   Actively support Sales and Marketing in responding to RFPs, supporting sales calls, delivering presentations, fielding questions from analysts, leading webinars, and traveling onsite to support sales meetings.   Responsible for sizing new sales opportunities developing the LOE for delivery, estimating expected containment rates for self-service and conversion rates for sales, providing timelines for delivery   Responsible for working with Finance on billing metrics and reports ensuring Finance has the data and support they need   Responsible for working with Legal reviewing contracts and ensuring outcome based formulas and associated containment / conversion rates are numbers the team can deliver   High level of travel is required. Both International (~20%) and Domestic travel (within US) (>35%) is required. Significant support for sales meetings and onsite support at client sites for QBRs, kickoffs, escalations.    Responsible for hiring top talent and building teams leading the next generation AI solutions   PhD in STEM (SAS is a plus) with emphasis in Machine Learning.   10+ years industry experience developing machine learning models at scale owning from inception to deployment with proven business impact.   10+ years industry experience leading and managing client engagements and meeting targets for TTR, SSR, RPC, FCR, NPS, and AOV.   Proven track record of leading high-performance teams with 5+ years’ experience successfully managing large cross-geo teams in Data Sciences and Professional Services.   Strong publication record (ACM, IEEE and top leading journals in the field ) and experience presenting at peer-reviewed industry conferences.   Demonstrated customer skills and excellent presentation skills.   A doer with the ability to be hands-on, designing processes and systems, digging into the details and operating comfortably in a cross-geo environment."
Data Engineer,Aviva Canada,https://ca.linkedin.com/jobs/view/data-engineer-at-aviva-canada-1527351406?trk=guest_job_details_job-result-card_result-card_full-click,"An educational background in Computer Science/Engineering.    5+ years of experience in a data-driven      software engineering environment.    A proven track record in building and      maintaining a reliable, high performance data pipeline that processes a      large amount of structured data from various sources.    Strong understanding of Data Warehouse      concepts, ETL strategies and best practices.    A deep understanding of SQL and relational      database schema design.    A minimum of 3 years of programming      experience in Python and SQL.    An appetite for problem solving with a      creative and resourceful approach to finding the right solution for the      job.    Strong communication and collaboration skills    Experience working in the Insurance      industry.    You are a self-motivated and outgoing      person who can work closely with business and IT stakeholders.    You understand the relationship between      data and business outcomes and can focus on long term strategies for data.    Proficiency with PostgreSQL, Teradata,      Hadoop and Cloudera is an asset.    You have experience working as part of      an Agile Team. "
Data Scientist,Perpetua,https://ca.linkedin.com/jobs/view/data-scientist-at-perpetua-1492483222?trk=guest_job_details_job-result-card_result-card_full-click,"Interact with Product Managers to translate customer business requirements into technical specifications.   Partner with software engineers on common areas of scalability, data quality management, data delivery management and performance optimization.   Track success criteria, communicate results with senior leaders, support adhoc requests, bridge technical and business program metrics   Design and implement metrics, data storage, and reporting mechanisms   Analyze customer data in order to improve the core strategies that power Perpetua’s advertising engine   Develop core features for Perpetua’s backend infrastructure   Work on advertising algorithms and large scale data pipelines   Work in a fast-paced, scaling start-up building software that is truly impactful   Degree in Computer/Software Engineering or Computer Science   3+ Years of Software Engineering Experience   2+ Years of Data Science Experience   Proficient in Python (Pandas, SciPy Stack); Google BigQuery and Dataflow a plus   A design thinking methodology coupled with quick and independent decision-making   Ability to solve problems in new and innovative ways   Self starter who takes initiative; owning a project from start to finish   Strong analytical and problem-solving skills   The ability to communicate complex technical issues in a clear and concise manner   Flexibility to adjust to changing priorities, requirements, and schedules   Experience working in a fast-paced, agile environment   Ability to understand the big picture   Previous experience with a fast scaling start-up   Experience with B2B or business insights and analytics   Master's Degree in Computer/Software Engineering or Computer Science   Relevant personal projects and open source work   Experience in the marketing or advertising space   Experience with PyTorch and/or Keras   Impactful work that will help lay the foundation for future projects   Meaningful equity at an early stage company   Ground floor opportunity   Paid-for meals   Unlimited snacks and drinks   Full benefits plus a health spending account   Top of the line technology to help you build your own workspace   Flexible time off policy"
"Senior Analyst/Associate, Data Analyst, Data and Advanced Analytics",CPP Investment Board,https://ca.linkedin.com/jobs/view/senior-analyst-associate-data-analyst-data-and-advanced-analytics-at-cpp-investment-board-1573928785?trk=guest_job_details_job-result-card_result-card_full-click,"Diverse and inspiring colleagues and approachable leaders   Stimulating work in a fast-paced, intellectually challenging environment   Accelerated exposure and responsibility   Global career development opportunities   Being motivated every day by CPPIB’s important social purpose and unshakable principles   A deeply rooted culture of Integrity, Partnership and High Performance   Support internal business partners (Investment Departments and Core Services) in the development and execution of new data capabilities.   Perform analysis and transformation of various internal and external data sets.   Leverage data visualization tools to represent the data in a business-friendly manner.   Help conduct and coordinate proof-of-concepts with external vendors alongside multiple internal stakeholders   Test and integrate APIs from external vendors.   Provide ongoing support for Data Governance capabilities such as metadata management, data quality and data stewardship/reporting.   Pro-actively communicate and collaborate with internal business clients to analyze functional requirements and deliver the appropriate artifacts as needed: business requirement documents, functional specifications, data specifications, use cases, workflow analysis, metrics, reports and user-interface layouts and designs.   Ensure that new enhancements address immediate business needs, while ensuring system alignment with data strategy and roadmaps.   Graduate or undergraduate degree in business and finance or other quantitative discipline (e.g. applied mathematics, financial economics, statistics, physics, engineering or computer science)   Solid programming experience in several of the following technologies: SQL, Python, Hadoop / Hive, Spark, Excel/VB, Unix scripts.   Experience with data visualization tools such as Tableau, Qlik or Power BI.   Experience working with AWS, Microsoft Azure or GCP considered an asset.   Experience in analyzing, manipulating, transforming, and interpreting large and complex datasets including time series and panel data.   Experience with market data vendors including Bloomberg, IDC, Refinitiv and alternative data vendors an asset.   Experience that demonstrates data knowledge across the following domains: Securities: listed securities and derivatives, market indices, alternative assets Pricing: market available pricing and evaluated pricing Corporate actions and associated lifecycle events Legal entities: parties, investment vehicles Reference data: asset classifications, geographic designations, industry classifications Data used in the investment process: fundamentals, estimates, industry KPIs, economic indicators, alternative data sets.   Excellent interpersonal skills with ability to work individually as well as in a team environment   Demonstrated knowledge of the data lifecycle, including experience with data modeling and data quality   Proven interest in financial and capital markets; enrolment in CFA program is considered an asset.   Commitment to CPPIB’s guiding principles of integrity, partnership and high performance"
Data Scientist,Contobox,https://ca.linkedin.com/jobs/view/data-scientist-at-contobox-1522640676?trk=guest_job_details_job-result-card_result-card_full-click,"Analyzing factors affecting user preferences and motivating them to engage, learn about and buy brand's products   Evaluating the relationship between different creative versions and user audience buckets and optimizing dynamic creatives in real-time   Producing models that will forecast the performance of advertising campaigns    Visualizing paths to conversions based on various KPIs and providing automated recommendations    Marketing analysis of brand audiences and  data activation on both proprietary and third-party DMPs (Data Management Platforms) and CDPs (Customer Data Platforms)   Bachelor's degree or equivalent experience in a quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)   At least 1 - 2 years' of experience in quantitative analytics or data modeling   Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms   Fluency in a programming language (Python, SQL, GoLang)   Familiarity with Big Data frameworks and visualization tools (Hadoop, Spark), database technologies (Amazon Redshift, Athena, MySQL, NoSQL), and cloud platforms (AWS, Google Cloud).   Working in an online advertising/marketing company or recommendation systems is a valuable asset.   play ping-pong;   have soccer tournaments on Xbox;   consume snacks, enjoy coffee and drink beer;   have office lunches and engage in different team activities."
Data Scientist,Jumio Corporation,https://ca.linkedin.com/jobs/view/data-scientist-at-jumio-corporation-1523682180?trk=guest_job_details_job-result-card_result-card_full-click,"Work with an international and strong team where each and every member’s opinion matters   Have flexible working hours, home office and learning & development opportunities   Build up our fast-growing team in downtown Montreal (team size increased 5x over a year)   Perform advanced data analysis   Develop statistical modelling and machine learning algorithms    Closely work with the product and engineering teams to ensure high impact products   Drive research projects to enable future product development   Strong experience in Machine Learning   Strong background in Statistics   Experience with scikit-learn, pandas   Experience with Tensorflow, Keras, or other frameworks   Published ML/statistics articles and ability to implement published papers   Data-driven mindset   Think further than the solution appears to require and go the extra mile   Excellent analytical, conceptual and communication skills in spoken and written English   Fast learner, high capacity for abstract thinking and structured approach to work   Hands-on mentality and international mindset   The will to learn new things and bring in new ideas"
Data Engineer,Lift & Co.,https://ca.linkedin.com/jobs/view/data-engineer-at-lift-co-1509131818?trk=guest_job_details_job-result-card_result-card_full-click,"Conduct insightful analysis using internal and external data to derive insights that will drive business decisions   Automate the software continually deployment pipeline   Build large-scale batch and real-time data pipelines with data processing frameworks   Implement Machine Learning and NLP algorithms for recommendations, sentimental analysis, etc.   Strong programming skills: SQL, Python, Java, Javascript   Familiar with Git, CI/CD, DevOps tools, e.g. Jenkins, Ansible, Docker.   Work experience in building ETL pipelines and design database modelling.   Work experience with relational database systems: MySQL, Postgres, etc.   Familiar with NoSQL data stores: MongoDB, Elasticsearch, is a plus.   Familiar with classic Machine Learning and NLP algorithms is a plus.   Bachelor's degree in Statistics, Mathematics, Computer Science or related fields from an accredited college or university.     Competitive base salary   Competitive Benefits package   Casual and fun office environment with work from home options, pet-friendly office and fun social events"
Senior Data Scientist - IoT,Samsung Electronics,https://ca.linkedin.com/jobs/view/senior-data-scientist-iot-at-samsung-electronics-1527385327?trk=guest_job_details_job-result-card_result-card_full-click,"Be responsible for user experience data analysis and create dynamic visualizations which may include but not limited to Sunburst chart, Heatmap, Sankey chart, Network diagram, Clickstream diagram, Dendrograms, etc.   Analyze customer review data and create meaningful topic chains using Topic Modeling etc.   Analyze process data to identify key process improvement areas and prepare for meaningful and memorable reports for executives   Collaborate with other groups worldwide to assist in product and user experience research   Be responsible for data analysis projects, design and automate data visualization to build data products   Be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data   Analyze data and prepare appropriate data visualization and find meaningful insights to present to managemen   acumen   Experienced with Graph Database   Experienced with dynamic data visualization using D3, etc.   Hands on with React, Javascript, Python development   Experience with ETL techniques   Hadoop echo system knowledge (Hadoop, Hive, Pig, Spark, R)   NLP technologies and other machine learning experience   Experience with AWS technologies (EC2, EMR, S3)    Please visit Samsung membership to see Privacy Policy, which defaults according to your location. You can change Country/Language at the bottom of the page. If you are European Economic Resident, please click here ."
Data Analyst,500px,https://ca.linkedin.com/jobs/view/data-analyst-at-500px-1532934661?trk=guest_job_details_job-result-card_result-card_full-click,"Interpret data and turn it into information which can offer ways to improve a business, thus affecting business decisions through gathering information from various sources and interpreting patterns and trends   Conduct complex queries on our data warehouse to help teams get the data they need, and maintain key reports and dashboards to track operational and business metrics   Build and maintain dashboards and reports that enable the Senior Leadership, Product, and Marketing teams to: drive business decision-making, drive performance and answer business questions in a measurable and actionable manner   Tell data stories to stakeholders by drawing insights from data analysis, bringing insights together to formulate the story and making recommendations for actions   Help your cross-functional team with data reports and data discovery by optimizing self-serve BI solutions and providing SQL support   Develop data collection plans and ensure the integrity of data collected   Perform exploratory data analysis to uncover patterns of user features and activities   Analyze trends in image usage via image metadata, sales reports, categories and keywords   Work with the technology team to identify, implement and maintain the systems we need to collect, verify, and analyze behavioural data   Define standards for data quality, and support the technology team in meeting those standards   Communicate and distribute data insights, tailoring presentations and findings to audiences across all levels of the organization   A Bachelor's or Master’s degree in statistics, computer science, math, physics, or a related quantitative field.   Minimum 2 years of experience specifically in statistical/data analysis and data mining, predictive modeling, machine learning, optimization.   Knowledge of advanced data analysis topics such as: causal inferences, data simulation, or correlated data analysis (e.g., survival analysis, longitudinal analysis, time series analysis and forecasting   Proficient in Python or R.   Expert knowledge of MySQL and PostgreSQL   1-2 years professional experience of consultation to internal groups or departments   Excellent analytical skills including cohort analysis, funnel analysis, AB testing, and lifetime value analytics   Extensive experience in debugging and solving performance issues when dealing with terabytes of data   Adaptable and open to change with strong collaboration and presentation skills   Experience with community based platforms   Experience with commercial licensing an asset   Knowledge of third party tools like Optimizely, Google Analytics, Amplitude, and Braze   Working experience with python libraries for data wrangling, visualization, mining and modelling (e.g., Pandas, NumPy, Matplotlib, Seaborn, Statsmodels, SciKit-Learn, NLTK)   Working experience with R packages for data wrangling, visualization and modelling (e.g., reshape2, dplyr, stringr, lubridate, ggplot2, car, forecast, randomforest, Caret, survival)   Knowledge of business intelligence tools such as Tableau, Quicksight, Sisense or any other BI tool   Knowledge of data warehousing and ETL "
Senior Data Scientist,Hatch,https://ca.linkedin.com/jobs/view/senior-data-scientist-at-hatch-1542261766?trk=guest_job_details_job-result-card_result-card_full-click," Understand the business need for analytics model, and determine, define and deploy predictive/prescriptive analytic solutions to meet business objectives;     Provide guidance in the selection of best fit methods, define algorithms, validate and deploy data analytics models to achieve business results;     Work with a team of data scientists in the development and deployment of data analytics tools;     Use machine learning methods to model and predict business outcomes, such as classification of errors;     Use advanced mathematical techniques (correlation, regression, time series analysis, analysis of variance, etc.) to forecast business outcomes;     Evaluate model fit and performance using a series of techniques (e.g. RMSE, RMSEA, MAE, MSE, MAPE, Accuracy, Recall, Precision, Etc.);     Develop high level and automated data visualizations to capture time series trends and summarize burn down of data exceptions;     Create recurrent summary reports of data exception metrics, trends, outliers, etc..     Bachelor's degree in Engineering (preferably Chemical, Systems, Mechanical, Civil or Electrical), Computer Science, Mathematics or equivalent from an accredited University and 5+ years of related work experience, or (preferred) a postgraduate degree with 3+ years of related work experience, or an equivalent combination of education and experience;     Solid knowledge and experience with a range of ML methods (e.g., multivariate analysis, cluster analysis, decision trees, random forest, SVM, neural networks, logistics regression)     Experience developing and applying innovative data analytics solutions in industrial and business settings.     Experience with business case analysis (problem identification, quantitative modeling and problem solving).     Hands-on experience with R, Python or equivalent tools to manipulate and transform data;     Exposure to Data visualization tools and techniques;     Exceptional skills and abilities to clearly communicate to customers through graphical representation / visualizations, reports, algorithms, models, and dashboards.     Experience with deep learning frameworks (Keras, TensorFlow, PyTorch) and cloud technologies (AWS, GCP, MS Azure) is desirable.     Experience working with databases (Teradata, Oracle, SQL, NoSQL dbs, etc.) and interpreting data;     Experience developing software user interfaces     Knowledge and/or experience applying mathematical optimization methods (linear programming, nonlinear programming and/or mixed-integer linear programming)     Keenly interested in solving very challenging client problems;     Willingness to take technological risks involved in creating innovative solutions;     Demonstrated ability to work both collaboratively and independently when appropriate;     Ability to build relationships and effectively influence colleagues, clients and stakeholders;     Excellent communication, interpersonal and teamwork skills in complex and changing environments. "
Pricing Data Analyst,CDW,https://ca.linkedin.com/jobs/view/pricing-data-analyst-at-cdw-1511122683?trk=guest_job_details_job-result-card_result-card_full-click,"Validate end user eligibility; enter associated costs and discounts based on the terms and conditions of bid programs within AS400. Validations must be determined within set time frames.   Shop and negotiate with individual partners to obtain optimal pricing for specific end user opportunities.   Address basic bid processing issues as they arise from sales via email, phone, or bid text.   Minimize “write-off’s” and escalate issues as necessary to the appropriate partner representative.   Identify areas of opportunity for process improvements and system enhancements and make associated recommendations to increase efficiencies.   Maintain key programs within the channel, primarily those of CDW Diamond Partners.   Provide Sales with the highest level of service.   Assist in projects related to departmental initiatives and goals.   Understand rebate collection process and how it pertains to daily processing; work directly with accounting department to resolve any discrepancies regarding bid pricing.   Multi-task between multiple bid programs   Create and maintain relationships with partners to work effectively with partners to implement new pricing programs for Sales.   The information in this position description is intended to convey information about the key responsibilities and requirements of the position. It is not an exhaustive list of the skills, efforts, duties, responsibilities or working conditions associated with the opportunity. Responsibilities are subject to change.   3 years working in a purchasing role or 2-years CDW experience   Experience with high volume order processing or other administrative processing experience.   Strong attention to detail and accuracy.   High school diploma or equivalent   Working knowledge of AS400.   Experience in Data Metrics and Analysis.   Proficient in Microsoft Office applications.   Excellent verbal and written communication skills.   Strong time management skills   Deadline driven   Demonstrated analytical skills   Strong time management skills   Proven ability to multitask and balance multiple priorities simultaneously.   College Diploma or Bachelor’s degree.   Customer Service or Sales experience."
Lead Data Scientist,BCG GAMMA,https://ca.linkedin.com/jobs/view/lead-data-scientist-at-bcg-gamma-1520604019?trk=guest_job_details_job-result-card_result-card_full-click,"7+ years of relevant industry work experience providing advanced analytics solutions, or 5+ years consulting experience    PhD or other Advanced degree required in a field linked to business analytics, statistics or geo- statistics, operations research, geography, applied mathematics, computer science, engineering, or related field    Looking for individuals with deep technical and data science expertise, acute strategic and analytical skills, ability to lead and persuade, drive and energy, and desire to work in a project based environment on strategic issues.    Strong record of professional accomplishment and leadership.    Demonstrated ability to lead and manage projects and teams.    Experience in core analytics methods     Familiarity with a broad base of analytics tools     Experience in applied analytics for business problem solving     Analytical and Conceptual thinking     Fast-paced, intellectually intense, service-oriented environment    Position is located in Toronto and Montreal    Expect up to 40 - 75% of time spent traveling    Plus de 7 ans d'expérience professionnelle dans le secteur des solutions d'analyses avancées, ou plus de 5 ans d'expérience dans le conseil     Doctorat ou autre diplôme supérieur dans un domaine lié à l'analytique, aux statistiques ou à la géostatistique, à la recherche opérationnelle, à la géographie, aux mathématiques appliquées, à l'informatique, à l'ingénierie ou à un domaine connexe    Personne possédant une expertise technique et data approfondie, ainsi que de fortes compétences stratégiques et analytiques, une capacité à diriger et à persuader    Solide bilan de réalisation professionnelle et de leadership    Capacité démontrée à diriger et gérer des projets et des équipes.    Expérience dans les méthodes d'analyse de base (une ou plusieurs des méthodes suivantes)     Familiarité avec une large base d’outils d’analyse (un ou plusieurs des éléments suivants)     Expérience dans l’analyse appliquée pour la résolution de problèmes clients     Un environnement dynamique, intellectuellement intense et orienté service    Le poste est situé à Toronto, Montréal, Boston ou Los Angeles    40 à 75% de déplacement à prévoir "
